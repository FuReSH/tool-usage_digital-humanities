
Abstract 

Tinder’s Future of Dating Report released in 2021 and purportedly incorporating a survey of 2000 single individuals from India, unequivocally asserted that AI-enabled digital dating had radically altered conversations around consent during the pandemic. Incidentally only a year earlier in 2020, India had been outraged by the Bois Locker Room i ncident: wherein an Instagram group chat created and disseminated by 27 teenage school students, all male, had circulated nude photos of their female classmates without their consent, along with offensive comments, including mentions of gang rape and other heinous sexual offenses. While igniting heated—albeit short-lived—debates about the ethical and social responsibilities of algorithmically governed platforms these conversations failed to acknowledge how algorithmic cultures and structurations have become embodied in our desiring selves and gendered lives. Therefore, sweeping simplifications about the nature of consent in India emerging from an organization that monetizes desire through an AI-enabled platform environment—where users’ agency is operationalized only within the boundaries of that platform—requires an urgent interrogation into both the lack of transparency within such algorithmic systems as well as the concomitant fallacy of stripping algorithmic outcomes from their local specificities and contexts. Particularly in India where (postcolonial) masculinities exist within an irreconcilable field of binaries, between the histories of colonial emasculation and the current hypermasculine machinations of a neoliberal nation (Roy 2021), the algorithmic identities of users while masked under apparent technologized objectivity, are always inflected by complex socio-historical realities (Motihar 2017). 

While digital outlets to dating in Global South contexts (like India) should seemingly offer agency to female subjectivities in Gen Z (18–25-year-olds), there is unfortunately little proof that virtual sites of intimacy like Tinder challenge the heteronormative patriarchy and regressive gender roles legitimized through offline social traditions. We chose Tinder’s Future Dating Report (2021) as an initial point to dive into the algorithmic lives, afterlives, and harms of digital dating platforms for two primary reasons. Firstly, the report contextualises users’ engagement with the dating application amidst the Covid-19 pandemic with a particular focus on consent, which the report posits as having become "more commonplace." (Tinder, 2021). Secondly, we operationalize this report as a primer to interrogate the purported premise about the next “decade of [algorithmic] dating” which is posited to be "more honest and authentic." (Tinder, 2021). As gendered subjects of the digital age from the Global South, we found this assertion provocative and a particularly useful entry point into the complex history of gender relations and masculinities in the Indian subcontinent. 

In operationalizing the Critical Participatory Inquiry methodological framework (Orlando Fals-Borda 2001) through snowball sampling, based on informed consent, we explore the experiences, fear, and apprehensions of eight Indian respondents in the age group 19-28 regarding digital dating on algorithmically governed platforms. In Indian context, it can be challenging for people to talk about dating experiences. Due to the intimate nature of the research and data, such a sampling method made it easier for respondents to share this data simultaneously allowing us to traverse experiences with greater depth. We analyze the responses received being particularly alive to the socio-economic, class and gendered contexts of our respondents, which thereby inform our discussion into the gendered and intersectional dimensions of algorithmic harms. 

Bookended by Global South masculinity studies on one end (Srivastava ; Dasgupta; Kabesh; Roy) and algorithmic accountability scholarship on the other (Acemoglu; Hoffman; Katell et.al; Metcalf et. al), this pilot project explores how AI based digital dating platforms mediate the troubling legacies of hegemonic masculinity in postcolonial spaces, while simultaneously erasing both the gendered anxieties and the human biases from the constituent algorithmic processes. Finally, in a polemic conclusion, we discuss the potential of our project to be an exemplar of critical and decolonial methodologies for examining algorithmic harm and propose paths forward for democratizing conversations around algorithm-driven platforms. 


# notes

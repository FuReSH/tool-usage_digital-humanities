Nr.;Titel;Story;Perspektive;Perspektive;Perspektive;Perspektive;Schlagwörter;Schlagwörter;Schlagwörter;Schlagwörter;TA 1;TA 2;TA 3;TA 4;TA 5;TA 6;4Memory Website URL;Notiz;MaxQDA-Codings;MaxQDA-Codings;MaxQDA-Codings;MaxQDA-Codings;MaxQDA-Codings;MaxQDA-Codings;MaxQDA-Codings;MaxQDA-Codings;MaxQDA-Codings;MaxQDA-Codings;MaxQDA-Codings;MaxQDA-Codings;MaxQDA-Codings;MaxQDA-Codings
1;"Transformation ""wild"" gewachsener Datenbestände, nichts ist FAIR";Mein Aufgabenschwerpunkt an einem Lehrstuhl der Geschichtswissenschaften ist die Konzeption unserer digitalen Projekte (vorrangig digitales Publizieren, digitale Wissensvermittlung) sowie die Koordination von deren Umsetzung durch unterschiedliche Teams. Seit Ende 2019 befassen mich die Daten einer vor einigen Jahren begonnenen Erschließung eines umfangreichen und sehr heterogenen Korrespondenzbestandes von Ende des 18. Jh./Anfang des 19. Jh. Ursprüngliches Ziel war, den Materialbestand mit einer ersten Roherschließung der Metadaten zu dokumentieren als Grundlage für eine Antragstellung auf Förderung einer digitalen Edition der Korrespondenzen. Das zu Beginn der Arbeiten vorrangig inhaltliche Interesse und eine stark editorische Sichtweise auf die Korrespondenzen haben Fragen des Forschungsdatenmanagements nicht weitreichend genug berücksichtigt. In der Folge wurden Rohdaten erhoben und in einer für die weitere Datenbe- und -verarbeitung nicht geeigneten Form dokumentiert. Das Ende des Dienstverhältnisses des Hauptbearbeiters führte dazu, dass das ursprüngliche Projektziel des Antrags auf Förderung einer digitalen Edition nur noch mit geringen Bordmitteln von verschiedenen BearbeiterInnen, die etwas Zeit erübrigen konnten, betrieben wurde. Formale Erfassungsstandards wurden nicht mehr konsequent angewendet bzw. nachgehalten und haben am Ende zu einer umfangreichen, aber qualitativ äußerst heterogenen Datenlage geführt. 2019 wurde meinem Vorschlag zugestimmt, das ursprüngliche Projektziel umzudefinieren und anstelle einer digitalen Edition die erhobenen Daten aufgrund ihres Umfangs und Potenzials in Form eines Metadatenkatalogs recherchierbar und nachnutzbar zu machen. Ich habe die Rolle der Datenkuratorin übernommen und in Zusammenarbeit mit der ansässigen Bibliothek, einer digitalen Expertin und wiss. MitarbeiterInnen ein erweitertes Datenmodell entwickelt, habe den ersten Teil der Rohdaten in Excel standardisiert und transformiert für die Übernahme in ein neues Datenbanksystem und koordiniere das Team, das den weiteren wiss. Abgleich der Datensätze bzw. Metadaten am Material vornimmt.</br>Das alles wäre im Nachhinein deutlich weniger mühsam und ressourcenaufwändig, wären die Rohdaten zumindest in einer nachnutzbaren Struktur dokumentiert gewesen. Aus meiner Sicht sind zwei Dinge unbedingt erforderlich: Projekte, in denen Daten generiert werden, brauchen von Anfang an professionelle Begleitung durch Infrastrukturpartner, die sich auch als Dienstleister der WissenschaftlerInnen verstehen wollen. Wir brauchen AnsprechpartnerInnen im IT-Bereich. Parallel dazu müssen die historisch arbeitenden GeisteswissenschaftlerInnen selbst ausreichende Kompetenzen im Umgang mit Forschungsdaten entwickeln, um überhaupt sprechfähig zu sein: Welche Daten erheben wir, welche Fragen haben wir am Ende an die Daten und welches Datenmodell brauchen wir dafür, welche Datenstandards müssen wir berücksichtigen, um Auswertung und Nachnutzung zu ermöglichen? In welchen zeitlichen Dimensionen bewegen wir uns? Was soll am Ende mit den Daten passieren? Das können und sollen uns InfrastrukturpartnerInnen nicht abnehmen.;datacollection;dataprocessing;datapublication;datareuse;heterogene Datenlage;Datenmanagementplan;Kooperation Wissenschaft-IT;0;1;2;3;4;;;https://4memory.de/problem-stories-overview/1-transformation-wild-gewachsener-datenbestande-nichts-ist-fair/;;Datentypen;;;Kompetenzen;;Langzeitverfügbarkeit;;;Methoden;Modellierung;Qualität;Ressourcen;;Standards
2;Linked Data ja, aber wie?;Als Forscher an einer fachwissenschaftlichen Einrichtung bin ich an einem kunsthistorischen Projekt beteiligt, das sich mit außereuropäischem Material beschäftigt. Wir möchten gerne Kunstwerke inhaltlich klassifizieren, aber die bestehenden (oft eurozentrischen) Vokabulare (IconClass, Getty) decken unser Material nicht ab. Wir brauchen also ein eigenes Vokabular, das aber möglichst (da, wo es Überschneidungen gibt) Cross-Links zu bestehenden Vokabularen bietet. Dafür steht an unserer Einrichtung keine Software bereit, und die typischen Lösungen (wie z.B. VocBench) sind kompliziert aufzusetzen.</br>Noch schwieriger wird es bei komplexeren Datenstrukturen, wie z.B. historischen Gazetteers, deren Modell noch etwas komplizierter ist als das eine Thesaurus. Hier bestehen z.B. mit LinkedPlaces gute Referenzformate, aber keine Tools, um komplatible Daten nutzerfreundlich zu erstellen.</br>Neben dem Editor für die Vokabulare selbst ist es für LinkedData natürlich auch notwendig, stabile URIs zu verwenden. Und auch wenn diese als Identifier nicht unbedingt auf eine tatsächliche Ressource verweisen müssen, ist es doch gute Praxis, dass die URIs auflösen und auf menschen- sowie maschinenlesbare Dokumentation verweisen. Unsere Einrichtung selbst kann dafür nicht die Gewähr der Dauer bieten. Also wäre ein Handle-System sowie ein System zur Generierung von Dokumentation für Vokabularen zusätzlich nützlich.;datacollection;datapublication;0;0;Linked Open Data;Gazetteer;Permanent Identifier;0;1;2;3;;;;https://4memory.de/problem-stories-overview/2-linked-data-ja-aber-wie/;;;;;;Kuration;Langzeitverfügbarkeit;;;;Modellierung;;;Softwarepflege;Standards
3;Archiv-Metadaten in XML-Format verfügbar machen;Metadaten in Archivportalen bzw. in den Online-Findmitteln der Archive liegen als strukturierte Daten in den dahinter liegenden Datenbanken. Die Struktur der Metadaten folgt meistens dem internationalen Erschließungsstandard ISAD(G) mit dem dazu korrespondierenden Metadatenschema EAD. Dennoch lassen sich Archiv-Metadaten meistens nicht in strukturierter Form als XML-Datei, bspw. im EAD-Format, herunterladen und weiter verwerten, z.B. in ein Literaturverwaltungsprogramm einfügen: 1. weil die erforderliche Funktion von den Archivportalen/Online-Findmitteln nicht bereit gestellt wird, 2. weil die Literaturprogramme das EAD-Format nicht unterstützen. Auch die denkbare datenbankgestützte Auswertung dieser Metadaten hat entsprechend ihre Grenzen. Derzeit lassen sich in manchen Archivportalen/ Online-Findmitteln die Archiv-Metadaten als PDF-Dokument ausdrucken.</br>Zielstellung: strukturierte Archiv-Metadaten lassen sich in Literaturverwaltungsprogramme importieren, am besten zusammen mit einem verfügbaren Digitalisat. Erforderlich sind dazu aber nicht nur Metadaten zu dem Objekt selbst, sondern auch die Kontextinformationen sowie die Metadaten zu dem Digitalisat selbst.;datareuse;0;0;0;Archiv;EAD;Literaturverwaltungsprogramm;0;1;;3;;;;https://4memory.de/problem-stories-overview/3-archiv-metadaten-in-xml-format-verfugbar-machen/;;Datentypen;;Internationalität;;;Langzeitverfügbarkeit;;;Methoden;;;;;Standards
4;Wie kann unser Portal mit wertvollen Forschungsdaten in zehn Jahren noch benutzt werden?;Als Verantwortlicher für die digitale Bereitstellung der Forschungsergebnisse in einer außeruniversitären Forschungseinrichtung bin ich für das langfristige Angebot, die Bereitstellung und Verfügbarkeit der Daten verantwortlich. Wir bieten online Themenportale mit Forschungsdaten an, die in der Regel über eine Suchmaske und einen Index erschlossen sind und z.B. auch im Kontext einer Karte angezeigt werden können. Wir möchten sicherstellen, dass die Daten auch noch in zehn oder 20 Jahren verwendet werden können, und zwar mit den Verknüpfungen und Querverweisen, die wir über die bei der Bereitstellung verwendeten Software erzeugen. Zwar nutzen viele Projekte inzwischen XML kodierte Daten nach dem TEI Standard, aber die Software zu Bereitstellung der Daten und einer benutzerfreundlichen Umgebung muss permanent gepflegt und angepasst werden, um z.B. Sicherheitsupdates in der verwendeten Software oder den Programmiersprachen zu gewährleisten. Zudem bestehen vielfältige Abhängigkeiten zwischen den verwendeten Programmpaketen. Teilweise werden die Daten auch unter Verwendung von Content Management Systemen angeboten oder sind darin eingebettet. Wie können wir sicherstellen, dass unsere Themenportale, die teilweise Ergebnisse jahrzehntelanger Forschungsarbeit präsentieren und bereitstellen, auch in Zukunft für Forscherinnen und Forscher mit einem individuell zum Thema passenden und die spezifische Datenstruktur abbildenden Interface nutzbar sind?;datapublication;0;0;0;Themenportale;Langzeitverfügbarkeit;Präsentation;0;;;3;;;;https://4memory.de/problem-stories-overview/4-wie-kann-unser-portal-mit-wertvollen-forschungsdaten-in-zehn-jahren-noch-benutzt-werden/;;;;;Kompetenzen;;Langzeitverfügbarkeit;;;;;;;Softwarepflege;Standards
5;Sicherung der Nachhaltigkeit von MyCoRe-Daten;An meiner Institution baue ich seit 2012 ein umfangreiches Informationssystem im MyCoRe System auf. Um das System dauerhaft nutzbar zu halten, ist in den nächsten Monaten dringend ein systemtechnisches Update des Informationssystems nötig, d.h. es müsste auf die nächste Version von MyCoRe übertragen werden.</br>Hierzu sind Mittel in Höhe einer halben Informatikerstelle für ein halbes Jahr nötig, Kapazitäten, die weder bei mir am Lehrstuhl noch im Rechenzentrum unserer Universität vorgehalten werden. Nun ist MyCoRe in Deutschland recht gebräuchlich, es kommt in rund 70 Anwendungen zum Einsatz, wo wahrscheinlich ähnliche Bedarfe anfallen. Meine Frage ist, ob hier nicht in punkto Finanzierung, Aufbau einer Koordinationsstelle und technische Umsetzung eine anwendungsübergreifende Lösung bereitgestellt werden könnte, die es den individuellen Projektleitern auf einfachere Weise ermöglichen würde, diese Updates durchzuführen.;datareuse;datapublication;0;0;Nachnutzbarkeit;Systempflege;anwendungsübergreifende Lösungen;0;;;3;;;6?;https://4memory.de/problem-stories-overview/5-sicherung-der-nachhaltigkeit-von-mycore-daten/;;;;;;;Langzeitverfügbarkeit;;;;;;Ressourcen;;
6;Archivische Forschungsdaten massenhaft mit zukunftsfähigen Normdaten anreichern;Als Archiv stellen wir massenhaft Erschließungsinformationen zu Archivgut im Sinne von primären Forschungsdaten im Internet bereit. Diese und weitere, noch nicht online veröffentlichte digitale Erschließungsinformationen liegen in sehr großer Zahl und unterschiedlicher Datenqualität vor. Eine Herausforderung ist die nachträgliche Anreicherung mit zukunftsfähigen Normdaten im Interesse einer vernetzten Recherche. Dabei bestehen zwei weisentliche Herausforderungen: </br>1. Benötigt werden Tools zur nachträglichen, automatisierten Anreicherung von Erschließungsinformationen in Archivinformationssystemen und den daraus zu exportierenden Onlineressourcen. </br>2. Während für Personen mit der GND ein anerkanntes Normdatensystem bereits institutionenübergreifend anerkannt ist, fehlt hinsichtlich von Geografika, Regional- und Gebietseinheiten noch eine vergleichbare Verbindlichkeit (z.B. GND, Amtliche Gemeindeschlüssel, Georeferenzierung).;datapublication;datareuse;0;0;Archiv;Normdaten;Datenanreicherung;0;1;2;3;;;;https://4memory.de/problem-stories-overview/6-archivische-forschungsdaten-massenhaft-mit-zukunftsfahigen-normdaten-anreichern/;;Datentypen;;;Kompetenzen;;Langzeitverfügbarkeit;;;Methoden;;;;Softwarepflege;Standards
7;Lizenzen;Als Lehrstuhl einer Hochschule forschen wir auch mit und an Werkzeugen aus dem Bereich der automatisierten Auswertung von Datenbeständen. Ein wesentlicher Teil der Datenbestände sind digitalisierte Textkorpora, die zumeist in einem Textformat, wie beispielsweise XML, vorliegen, die aber für die Analysen in andere Dateiformate konvertiert werden müssen. Einige der Korpora unterlagen und unterliegen einer Lizenzpflicht. Dies bedeutet, sie dürfen nur dann von einer Person benutzt werden, wenn deren Institution (zum Beispiel über die UB) oder sie selbst eine kostenpflichtige Lizenz erworben hat. Die Lizenzen sind meist zeitlich begrenzt.</BR>Um die Analyseergebnisse der automatisierten Auswertung der Textbestände nach den FAIR-Prinzipien langfristig zur Verfügung zu stellen, ist es notwendig, die Rohdaten, also die Korpora selbst, einzubeziehen. Es ist für uns schwer nachvollziehbar, welche praktischen Konsequenzen § 60d Urheberrechtsgesetz, speziell Absatz 3, für die Ausgestaltung dieser Prinzipien bei Textkorpora hat, die einer Lizenzpflicht unterlagen oder noch unterliegen. Einerseits soll das Korpus und dessen Vervielfältigungen nach Abschluss der Forschungsarbeiten gelöscht werden, andererseits darf es von den in den §§ 60e und 60f genannten Institutionen dauerhaft aufbewahrt werden. Zu den in 60f benannten Bildungseinrichtungen gehören laut Definition in § 60a Absatz 4 beispielsweise auch Hochschulen. Nach dieser Lesart dürften die Korpora und deren Vervielfältigungen auf hochschuleigenen Servern dauerhaft gespeichert werden. Das Aufbewahren an sich ermöglicht jedoch noch nicht den Zugang, da dieser nur über eine Bezahlschranke möglich ist. Ohne eine gültige Lizenz darf der Zugang zu den Rohdaten nicht gewährt werden.</br>Es erscheint insgesamt fragwürdig, wie die Qualität wissenschaftlicher Forschung bei automatisierten Analyseverfahren überprüf- und nachnutzbar gehalten werden kann, wenn ein wesentlicher Bestandteil der Forschung, die Rohdaten selbst, nicht zugänglich gemacht werden darf bzw. bei Nachnutzung durch den Erwerb einer Lizenz erst „hinzugekauft“ werden muss.;0;0;0;0;0;0;0;0;1?;;;;5;6?;https://4memory.de/problem-stories-overview/7-lizenzen/;Rechte;Datentypen;;;;Kuration;Langzeitverfügbarkeit;Lizenzen;;Methoden;;Qualität;;Softwarepflege;Standards
8;Anonymisierung qualitativ-empirischer Daten;Als Nachwuchswissenschaftlerin bin ich bereits bei der Antragstellung von Drittmittelanträgen zur reflektierten Darstellung meines Forschungsdatenmanagements angehalten. Gewünscht wird eine nachnutzbare Aufbereitung und Aufbewahrung meines empirisch-qualitativen Datenmaterials, dass sowohl Interviews als auch Notizen aus teilnehmender Beobachtung umfasst. Gern bin ich bereit, mein Material zur Nachnutzung unter gewissen Umständen zur Verfügung zu stellen. Allerdings lassen sich vor allem in Audio-/Videodateien personenbezogene Angaben kaum anonymisieren. Damit kann bei der Bereitstellung des Materials auch kein Datenschutz der Informant*innen garantiert werden, wodurch ich meine Integrität zweifelhaft würde.;datapublication;0;0;0;Anonymisierung;empirisch-qualitativ;Datenschutz;0;;;;;;;https://4memory.de/problem-stories-overview/8-anonymisierung-qualitativ-empirischer-daten/;;Datentypen;;;;Kuration;Langzeitverfügbarkeit;Lizenzen;;Methoden;;;;;
9;Archivquellen - Zusammenarbeit mit vielen unterschiedlichen Archiven;"In einem größeren Forschungsprojekt arbeite ich mit Quellen ganz unterschiedlicher Provenienz, z.B. aus Zeitungsdatenbanken (Online-Archive von ""Der Spiegel"", ""Die Zeit"", aber auch Zeitungen aus dem Ausland; daneben Fernseh- und Rundfunk-Archive, das Bundesarchiv etc. Ich werte Zeitungsartikel, Protokolle von Bundestagsreden, Akten aus verschiedenen Ministerien, Fernsehserien u.v.m. als Quellen aus, und zwar qualitativ. Wie kann ich daraus einen Quellenkorpus machen, der so einheitlich ist, dass er sich irgendwie zur Nachnutzung aufbereiten lässt? Und wie kann ich die Archive, die ja die Rechteinhaber sind, mit ins Boot holen? Meine Idealvorstellung wäre ein E-book, in dem alle Quellenangaben in den Fußnoten ""klickbar"" sind, d.h. man kommt mit einem Klick zum Original.";datapublication;0;0;0;Zusammenarbeit Archive;Unterschiedliche Qualität der Quellen;0;0;1;2;;;;;https://4memory.de/problem-stories-overview/9-archivquellen-zusammenarbeit-mit-vielen-unterschiedlichen-archiven/;;;;;;Kuration;Langzeitverfügbarkeit;;;Methoden;;Qualität;;;
10;Erstellung und Mapping von Referenzvokabularen;Als Spezialbibliothek erzeugen wir mit OCR Volltexte unserer digitalisierten Quellen für die Forschung. Mit digitalisierten und auf Lemma-Ebene erschlossenen Fachlexika (19. Jh) verfügen wir über zeitspezifisches Vokabular. Bislang fehlt es an Kapazitäten, dieses Vokabular als Gazetteer oder Ontologie aufzubereiten und für die automatische Analyse der Volltexte zur Verfügung zu stellen, also Vokabulare als Forschungsdateninfrastrukturleistung zu entwickeln. Weder für die Infrastrukureinrichtung (Bibliothek) noch für Wissenschaftler*innen existieren günstige Rahmenbedingungen (Finanzierung, wissenschaftliche Anerkennung) für solche fachlich spezialisierte Infrastrukturleistungen an der Schnittstelle zwischen historischer Subdisziplin, Informationswissenschaft und Data Science.;datacollection;datapublication;0;0;Thesaurus;Ontologie;Vokabular;Infrastruktur;;2;3;;;;https://4memory.de/problem-stories-overview/10-erstellung-und-mapping-von-referenzvokabularen/;;;;;;;Langzeitverfügbarkeit;;;Methoden;;;Ressourcen;;Standards
11;Adaption des IIIF-Standards für Audio-, Video- und 3D-Daten;Die anbieter- und systemunabhängige Nutzung digitaler/digitalisierter Quellen in der eigenen Forschungsumgebung wird durch die IIIF-Standards unterstützt. Als Bibliothek würden wir gerne auch unsere digitalisierten Audio-, Video-, und 3D-Daten ebenso wie die text-/bildbasierten Quellen über IIIF anbieten können. Für eigene großangelegte Standard- und Softwareentwicklungen fehlen aber die Kapazitäten an unserer Einrichtung ohne Entwicklungsabteilung. Wir brauchen einen Rahmen, in dem wir uns mit Anforderungen aktiv in die Standard- und Softwareentwicklung einbringen können und zugleich eine starke Partnereinrichtung, die in der Lage ist diese Arbeiten auch auszuführen.;datapublication;datareuse;0;0;Software;Schnittstelle;IIIF;;;2;3;;;6?;https://4memory.de/problem-stories-overview/11-adaption-des-iiif-standards-fur-audio-video-und-3d-daten/;;Datentypen;;;;;;;;Methoden;;;;Softwarepflege;Standards
12;FactGrid und das fehlende breitenwirksame Wikibase-Frontend;Wir erfassen mit dem FactGrid Daten und helfen Partnern auf der Plattform. Die Software erweist sich dabei als so attraktiv, dass Mitspieler des In- und Auslands zurzeit von selbst an uns herantreten, um bei uns Datensätze in Wikibase laufen zu lassen.</br>Unsere zentralen Probleme liegen im Moment in der Bedienung der Software, die für Wikidata ein unmittelbar auf die Dateneingabe und das Datamining ausgerichtetes Interface nutzt. </br>Verbesserungsbedürftig ist einerseits die Dateneingabe: Es müsste möglich sein, Open Refine serverseitig laufen zu lassen und auf die mitdenkende Software hin zu arbeiten, die noch vor der Eingabe großer Datenmengen auf bereits vorliegende Informationen (etwa bei deckungsgleichen Verwandtschaftsbeziehungen)verweist, und die so die Arbeit mit der vorhandenen Information erleichtert.</br>Wichtiger noch ist für uns im Moment der Schritt in eine dezidierte Datenpräsentation.</br>Magnus Manske’s „Reasonator“, Markus Krötzschs „Squid“, zeigen das Potential der Software auf, mit der sich eine Wikibase-Datenbank bis an den Punkt nutzen lässt, an dem sie Wikipedia Konkurrenz macht – mit dem Vorteil, dass dabei plötzlich eine einzige multilingual verwaltete Datenlage in verschiedenen Sprachen nutzbar wird. Es ist dies ein Entwicklungsweg, den Wikimedia nicht prioritär verfolgt und auf dem wir uns derzeit mit Partnern wie der DNB bewegen.</br>In der bis auf Weiteres misslichen Lage sprechen wir Nutzer derzeit nur sehr provisorisch mit exemplarischen, modifizierbaren Suchangeboten an, von denen aus sie sogleich in die bearbeitbaren Datensätze geleitet werden – so im aktuellen Projekt, das Thüringens Pfarrerbuch bei uns verfügbar macht: https://blog.factgrid.de/archives/1923. Das Ziel sind Nutzeroberflächen wie Uwe Jung sie für die FH-Potsdam im Umgang mit Wikidata erarbeitete (https://blog.factgrid.de/archives/1215).</br>Hier befinden wir uns in Gesprächen mit Partnern, die auf dieselbe Software setzen sowie mit Wikimedia, mit dem Ziel einer open source Lösung, von der alle Wikibase Plattformen profitieren würden. Die Vernetzungsangebote des NFDI-Prozesses sind dabei von fast noch größerem Interesse als Entwicklungsetats.;dataprocessing;datapublication;datareuse;0;Datenpräsentation;Dateneingabe;0;0;;;3;;;;https://4memory.de/problem-stories-overview/12-factgrid-und-das-fehlende-breitenwirksame-wikibase-frontend/;;;;;;;Langzeitverfügbarkeit;;Mehrsprachigkeit;Methoden;;;;Softwarepflege;
13;Anreize schaffen für Datenpublikationen?;"Als Projektverantwortliche im Bereich ""Dateninfrastruktur und Digital Humanities"" ist es Teil meiner Aufgabe, aber auch mein Wunsch, meine Kolleginnen und Kollegen beim Erstellen und Veröffentlichen von Datenpublikationen zu ermutigen. Momentan gestaltet sich das vor allem deswegen schwierig, weil wir erstens immer noch nach den richtigen Formaten suchen, aber zweitens auch, weil Anreizstrukturen fehlen. Datenpublikationsformate werden insbesondere in der Geschichtswissenschaft noch nicht mit der gleichen Anerkennung versehen wie traditionelle Formate. Vielleicht würde hier eine Community-weite oder zumindest Community-unterstützte Plattform helfen, solche Anreiz- und Anerkennungsstrulturen zu schaffen. Vielleicht könnte man auch an Workshops oder dergleichen denken.";datapublication;0;0;0;Publikationsformate;Anreizstrukturen;0;0;;;3;;5;;https://4memory.de/problem-stories-overview/13-anreize-schaffen-fur-datenpublikationen/;;;;;Kompetenzen;;;;;;;;;Softwarepflege;
14;Fehlende Angaben, wie Fotos genutzt werden können;Ich leite eine historische Beratung für Autorinnen und Autoren. Daher arbeite ich viel mit Online-Bilddatenbanken aus der ganzen Welt. Gerade bei den deutschen Datenbanken fällt mir auf: Es wird zwar fleißig digitalisiert und ins Netz gestellt. Ob man diese Bilder aber nutzen kann, z.B. in einem Roman, einem Bildband oder einer Dissertation veröffentlichen kann, steht nicht direkt am Bild. </br>Man muss für jedes Bild einzeln nachfragen. Oft landen die Anfragen an einer anderen Stelle, die die Digitalisierung nicht durchgeführt hat (info). Wenn gleich AM BILD jedesmal eine Angabe zu Creative Commons-Grad stehen würde, könnten alle Seiten - Nutzer und bildgebende Institution - viel, viel Zeit sparen.;datareuse;datapublication;0;0;Fehlende Creative Commons-Angaben - Publikation möglich oder nicht?;0;0;0;1;;;;5?;;https://4memory.de/problem-stories-overview/14-fehlende-angaben-wie-fotos-genutzt-werden-konnen/;;Datentypen;;;Kompetenzen;;;;;Methoden;;;;;
15;"Markup language for biographical information about ""ordinary people""";We are editing 19th century migrant letters that are physically located in German and American archives. In order to be able to reconstruct migration patterns and migrant networks, we would like to mark persons with a unique identifier. Since these are “ordinary people”, we do not find them in existing Authority Files such as GND, LoC or Wikidata. How should we reference the existing biographical information and which markup language should we use so that the biographical information that we retrieve from the letters and from archives can easily be enhanced by future biographical research? Should we transfer our data into the Integrated Authority File (GND) and if yes, how can we do this? Secondly, we would like to store and document all biographical details (baptism, marriage and death records, census records, pension records, emigration records, ship lists) as well as additional information gathered from the letters such as occupation, places of living and family events, contacts between migrants, their families, old and new neighbors, friends and acquaintances, in order to map and visualize the migration and mobility networks. Which service and platform should we use for cooperative research data management and the long-term preservation of our research data? Which digital tools should we use for GIS mapping and network visualization?;dataprocessing;datacollection;0;0;Personenidentifikation;Visualisierung;Werkzeuge;0;1;2;3;;;;https://4memory.de/problem-stories-overview/15-markup-language-for-biographical-information-about-ordinary-people/;;Datentypen;;;;;;;;Methoden;;;;Softwarepflege;Standards
16;Digital Literacy am Projektstart;An der Akademie der Wissenschaften und der Literatur, Mainz bin ich tätig im Projekt Regesta Imperii und als Projektleiter von DFG-Projekten.</BR>Dabei kommen immer wieder andere DFG-Projekte mit der Bitte auf mich zu, beim digitalen Start zu helfen. Fragen drehen sich z.B. um </BR>Welche Programme für die Datenaufnahme ?</BR>Welche Datenmodellierung kann genutzt werden ?</BR>Wo können die Daten gespeichert werden ?</BR></BR>Wie sieht unsere Datenmodellierung konkret aus ?</BR>Meist finden wir gemeinsam schnell eine Lösung, mit der das Projekt starten kann. Nach einigen Monaten gibt es nochmal ein Treffen um weitere Fragen zu klären.</BR>Eigentlich benötigt jedes DFG-Projekt welches nicht eine eigene IT-Stelle beantragt hat oder keinen Zugriff auf institutionelle Unterstützung hat eine solche Anfangsbetreuung, die auch finanziell vergütet werden sollte.</BR>Vielleicht könnte man einen Anteil des Overheads in Form von Beratungsgutscheinen an die Projekte geben, die diese dann gegen diese Dienstleistung eintauschen könnten.;datacollection;dataprocessing;datapublication;0;Data Literacy;Finanzierung;0;0;;;;4;;6?;https://4memory.de/problem-stories-overview/16-digital-literacy-am-projektstart/;Finanzierung;;;;Kompetenzen;;;;;;;;Ressourcen;;
17;Sonden in die entstehende Konsumgesellschaft: Hamburger Importzolldeklarationen, 1736-1798;"Aus Hamburg sind aus den Jahren 1736-1798 für 36 Jahre total 180.000 individuelle Importzolldeklarationen aus dem seeseitigen Handel erhalten. Die Deklarationen enthalten u. a. die Namen der Importkaufleute, Bezeichnungen der verzollten Waren, eine Schätzung von deren Wert, Herkunftsort der Schiffsreise und Datum. Es handelt sich um einen der umfangreichsten und wichtigsten Bestände zur deutschen Handelsgeschichte des 18. Jahrhunderts. Es eignet sich zur Analyse der Anfänge der Konsumgesellschaft in Deutschland, der Verbreitung des Konsums von Kolonialwaren, der aggregierten Entwicklung der deutschen Außenwirtschaft sowie (allerdings nur selektiv) der Aktivitäten individueller Kaufleute. Das Material wurde im Rahmen des Projekts zur Historischen Statistik Deutschlands erhoben und unterschiedlich aggregiert publiziert (Schneider et al. 2001). Um sie analysierbar zu machen, wurden die Daten in eine MS-Access-Datenbank eingebettet, die insbesondere Handelsgüter nach Güterklassen bzw. Herkunftsorte nach Ländern und Regionen zusammenzufassen erlaubt. Die Datenbank zirkuliert informell in verschiedenen Fassungen und hat bisher wenigstens zwei Publikationen zur Grundlage gedient. Das Erkenntnispotential des Korpus ist damit längstens nicht erschöpft. Die problem story kreist damit um die Herausforderung, diese wichtige Datenbank Forscher*innen leicht zugänglich zu machen. Hierzu muss (1) die Datenbank noch weiter geputzt werden, was Aufgabe der damit Arbeitenden (unter Einschluss des Schreibenden) ist. (2) müssen die existierenden Datenbankabfragen zu einem geschlossenen Interface ausgebaut werden, wozu ein gewisser Beratungsbedarf besteht, da die Kompetenz wenigstens des Schreibenden im Bereich der Entwicklung von Datenbankanwendungen begrenzt ist. (3) muss ein Datenarchiv gefunden werden. (GESIS hat die Annahme historischer Forschungsdaten eingestellt.) (4) eignen sich zentrale, aggregierte Zeitreihen für eine historische Statistik. Einschlägig wäre HISTAT, aber GESIS hat die Weiterentwicklung von HISTAT eingestellt. Benötigte Services sind somit: (i) Einschlägiges Datenarchiv; (ii) Unterstützung bei der Aufbereitung einer Datenbank für ein Datenarchiv; (iii) Weiterentwicklung von HISTAT.";datapublication;datareuse;0;0;Datenarchiv;Nachnutzung relationaler Datenbanken;historische Zeitreihen;0;1;;3;4;;;https://4memory.de/problem-stories-overview/17-sonden-in-die-entstehende-konsumgesellschaft-hamburger-importzolldeklarationen-1736-1798/;;;;;Kompetenzen;Kuration;Langzeitverfügbarkeit;;;Methoden;;;;;
18;Erfassung, Geo-Lokalisierung und Visualisierung von handschriftlich verfassten Massendaten;Seit einiger Zeit arbeite ich mit einer kleinen Gruppe an der Zusammenstellung von Glockengussdaten. Dabei handelt es sich um Informationen, die 1940/41 anlässlich der bevorstehenden Einschmelzung der Glocken auf Karteikarten gesammelt wurden, insgesamt etwa 20.000. Für uns von Interesse sind Standort der Glocke (1940/41) und Zeitpunkt des Glockengusses (z.T. zurück bis ins 11. Jh.). Da Glocken fast nie den Standort wechseln, soll im Endergebnis eine Art dynamische Heatmap über die Jahrhunderte gezeigt werden, wann wo besonders viele oder wenig Glocken gegossen wurden. In Ermangelung wirtschaftsstatistischer Daten wäre das eine Art Proxy-Variable für wirtschaftliche Konjunkturen (das ist jetzt alles sehr grob vereinfacht). Alle Karteikarten liegen in digitalisierter Form vor. Unser erstes Problem betrifft die Übertragung der relevanten Daten (v.a. Standort und Glockengussdatum) von der handgeschriebenen Karteikarte in eine Tabelle. Wo finden wir Informationen darüber, welche Software sich für das Einlesen relativ standardisierter, aber eben handgeschriebener Daten eignet? Wieviel Nachkorrekturen sind ungefähr nötig? Um zweitens eine Glocke mit vertretbarem Aufwand georeferenzieren zu können, benötigen wir eine Zuordnung des Ortsnamens von 1940/41 zu einer Geo-Position. Wo finden wir eine Übersicht über entsprechende Datenbanken? Erschwerend kommt hinzu, dass 1940/41 selbständige Gemeinden heute nur noch Stadtteile oder unselbständige Teilgemeinden sind. Drittens schließlich stellt sich die Frage der Visualisierung. Die politischen Grenzen haben sich vom 11. Jahrhundert bis 1941 immer wieder geändert. Gibt es historische Karten, die es erlauben würden, auf der dynamischen heatmap die korrekten jeweiligen Grenzverläufe zu visualisieren (etwa in 50-Jahres-Abständen)?;dataprocessing;datacollection;0;0;Handschriftenerkennung;Georeferenzierung;Karten;0;1;2;3;4;;;https://4memory.de/problem-stories-overview/18-erfassung-geo-lokalisierung-und-visualisierung-von-handschriftlich-verfassten-massendaten/;;Datentypen;;;;;;;;Methoden;;;Ressourcen;Softwarepflege;Standards
19;Digitale Quellenkritik bedenken;"Vor dem Hintergrund meiner Erfahrungen als Hochschullehrerin scheint es mir so zu sein, dass die Geschichtswissenschaften digitale Ressourcen noch kaum als neuen und auch relevanten Lehrinhalt etabliert haben. Das bringt auch mit sich, dass die Quellenkritik bspw. zu digitalisierten und ""born digital"" Quellen noch zu wenig in der Fachkultur verankert ist. Das bringt Probleme für die Lehre mit sich, wenn es darum geht, Studierenden die Komplexität der digitalen Quellenkritik zu vermitteln, Fragen von Authentizität, Qualität usw. zu diskutieren. Da hilft der reine Bezug auf formale Standards nicht viel weiter. Es braucht einen im Fach verankerten, kritischen Diskurs. Das schließt auch ein viel aktiveres Rezensionswesen ein, als dies bspw. für digitale Quellensammlungen (auch Forschungsdatenpublikationen) bislang der Fall ist. Aber vermutlich müsste das Fach dann auch über die Reputation von digitalen Publikationen und den Aufwand, diese adäquat zu besprechen, diskutieren.";datareuse;0;0;0;Digitale Publikationen;Lehre;Verwendung von digitalen Ressourcen für Forschung und Lehre;0;;;;4;5;;https://4memory.de/problem-stories-overview/19-digitale-quellenkritik-bedenken/;;;;;Kompetenzen;Kuration;Langzeitverfügbarkeit;;;Methoden;;Qualität;Ressourcen;;Standards
20;Inhaltsanalyse preußischer Regierungsberichte aus dem Rheinland;In einer kleinen Forschergruppe wollen wir die Berichte der rheinischen Provinzialregierungen an den preußischen König in den ersten Jahrzehnten nach der Annektion untersuchen. Uns interessiert dabei, welche Themen die im Aufbau befindliche Verwaltung hatte, wie sie diese Themen an den König herantrug und ob es dabei unterschiede zu den alten preußischen Provinzialverwaltungen gab. Um die große Textmenge bearbeitbar zu machen und um möglichst unvoreingenommen an die Quellen heranzutreten wollen wir eine Inhaltsanalyse mit einem Topicmodell vornehmen. Das erste Problem, das sich dabei stellt ist natürlich die Digitalisierung großer handschriftlicher Textmengen. Dieses Problem lässt sich mit dem Programm Transkribus jedoch schon sehr gut lösen. Als weiteres Problem erweist sich die Frage, wie die Daten gespeichert werden sollen. Auf der einen Seite sollten für die Berechnung des Topicmodells einzelne Textabschnitte als mit Metadaten (Regierungsbezirk, Jahr, Monat) versehene Variablen vorliegen. Auf der anderen Seite sollten die Daten auch in Ihrer Dokumentenstruktur gespeichert und mit einer XML-TEI Auszeichnung versehen werden, um sie als Editon zu veröffentlichen. Hier braucht es eine flexible Datenbanklösung, die mehrere Zuordnungen erlaubt. Zuletzt stellt sich die Frage, mit welchem Programm das Textmining vorgenommen werden soll. Konventionelle Statistikprogramme wie STATA und R sind dazu in der Lage. Der Zugang zu diesen Programmen stellt aber sicherlich für Viele im Fach eine Hürde da. Hilfreich wäre es ein webbasiertes Tool zu haben, das intuitiv zu bedienen ist. Zwar existieren auch hier schon entsprechende Webseiten (bspw. Voyant-Tools, Lexos). Diese sind aber stärker auf die Literaturwissenschaft ausgerichtet und haben für die historische Arbeit einige Nachteile. So ist die Arbeit mit Metadaten (Zeitinformationen) schwierig, außerdem wird der Arbeitsstand auf Fremdservern gespeichert und eine Dokumentation der einzelnen Arbeitsschritte ist nicht vorgesehen. Eine speziell auf das historische Arbeiten zugeschnittene Lösung, die die hier skizzierten Nachteile umgeht wäre sicherlich hilfreich. Grade auch, um die Methoden des Textminings breit im Fach zu verankern.;dataprocessing;datapublication;0;0;Textmining;Topic Modell;Inhaltsanalyse;0;;;3;4;;;https://4memory.de/problem-stories-overview/20-inhaltsanalyse-preusischer-regierungsberichte-aus-dem-rheinland/;;Datentypen;;;;;Langzeitverfügbarkeit;;;Methoden;Modellierung;;;Softwarepflege;Standards
21;Georeferenzierung innovativer Regionen in den deutschen Staaten;In einer Forschergruppe erheben wir Informationen zu den in den Deutschen Staaten erteilten Patenten im Zeitraum 1840-1877. Die Daten erhalten reichhaltige Informationen zur patentierten Technologie, den Berufen der Patentinhaber und deren Wohnorten. Letztere ermöglichen eine Landkarte innovativer Orte/Regionen über einen langen Zeitraum zu zeichnen und beispielsweise Fragen der Persistenz zu adressieren. Als Blocker erweist sich dabei, dass wir uns mühsam die Geodaten der erfassten Orte beschaffen müssen, erschwerend kommt außerdem hinzu das viele kleine Orte mittlerweile eingemeindet wurden oder - in den östlichen preußischen Provinzen - Ortsnamen gewechselt haben. Eine historische Datenbank, die Gebietsveränderungen über die Zeit nachvollzieht und den Orten Geodaten zuordnet wäre hier sehr hilfreich.;dataprocessing;datacollection;0;0;Georreferenzierung;0;0;0;;2;3;;;;https://4memory.de/problem-stories-overview/21-georeferenzierung-innovativer-regionen-in-den-deutschen-staaten/;;Datentypen;;;;;;;;;;;;;
22;Nutzung eines außerhalb der akademischen Forschung entwickelten Standards in der akademischen Forschung;Unser bürgerwissenschaftlicher Verein hat ein Ortsverzeichnis entwickelt, das mit Bezug auf Deutschland und viele andere Länder Ortsnamen (in variierenden Schreibweisen), kirchliche und staatliche Zugehörigkeiten im Zeitverlauf sowie geographische Koordinaten erfasst. Die Abdeckung auf Ebene der Siedlungsplätze (also unterhalb der Gemeinden) beträgt für das späte Kaiserreich bereits etwa 80%. Das Verzeichnis liegt als Open Data vor und ist über einen Webservice abrufbar. Im bürgerwissenschaftlichen Bereich haben wir damit einen Standard gesetzt. Wie können wir erreichen, dass dieses System sich auch im akademischen Bereich als Standard etabliert?;datareuse;0;0;0;Geodaten;Normdaten;0;0;;2;3;4;;;https://4memory.de/problem-stories-overview/22-nutzung-eines-auserhalb-der-akademischen-forschung-entwickelten-standards-in-der-akademischen-forschung/;;Datentypen;;;;;Langzeitverfügbarkeit;;;;;;;;Standards
23;Selbstentwickelte Tools als Open Source veröffentlichen;Für eine private Website habe ich einen Verwandtschaftsrechner programmiert, der auf den eigenen Datenbestand auf der privaten Seite zugreift und für je 2 beliebige Personen zeigt, wie sie verbunden sind. Wie kann ich dafür sorgen, dass das Tool auch von anderen benutzt werden kann?;dataprocessing;datapublication;0;0;Softwareentwicklung;Softwarepublikation;0;0;;;3;4;;;https://4memory.de/problem-stories-overview/23-selbstentwickelte-tools-als-open-source-veroffentlichen/;;;;;;;Langzeitverfügbarkeit;;;Methoden;;;;Softwarepflege;
24;Familienanzeigen archivieren;Ich verwalte als Privatperson einen großen Bestand von einigen Millionen Familienanzeigen (vor allem Todesanzeigen) aus Tageszeitungen des 20., z.T. auch 19. Jahrhunderts. Die Daten liegen einerseits als Digitalisate, andererseits als partielle Texterfassungen (Name des Verstorbenen, Ort, Datum) vor. Da die in den Anzeigen benannten Hinterbliebenen zu großen Teilen noch leben, greifen für die Weitergabe und Verarbeitung der Daten Datenschutzbestimmungen. Wie kann der Bestand rechtlich sauber für die Forschung bewahrt werden? Ich möchte den Bestand nicht weiter als Privatperson verantworten.;datapublication;0;0;0;Datenschutz;0;0;0;;;3;;5;6?;https://4memory.de/problem-stories-overview/24-familienanzeigen-archivieren/;Rechte;Datentypen;;;;;Langzeitverfügbarkeit;Lizenzen;;Methoden;;;;;
25;Online-Publikation unveröffentlichter Hochschulschriften und anderer Manuskripte;Wenn ich im Zuge meiner Forschung auf unveröffentlichte Arbeiten anderer stoße (Beispiel: eine ungedruckte Dissertation einer Verwandten), wie kann ich für eine dauerhaft zugängliche und zitierfähige Online-Publikation sorgen? Ist die Digibib des Vereins für Computergenealogie dafür geeignet, bzw. wie kann man dafür sorgen, dass sie diesen Status bekommt?;datapublication;0;0;0;Onlinepublikation;0;0;0;1;;3;;;;https://4memory.de/problem-stories-overview/25-online-publikation-unveroffentlichter-hochschulschriften-und-anderer-manuskripte/;;;;;;;Langzeitverfügbarkeit;;;;;;;;Standards
26;Wenn ich Forschungsergebnisse auf einer Website veröffentliche, wie ist dann die Langzeitverfügbarkeit zu sichern?;Eine mögliche Strategie der Datensicherung und verbreitung besteht darin, sie auf einer Website selbst zu veröffentlichen und auf dauerhafte Zugänglichkeit z.B. über das Internet Archive zu hoffen. Eine Website scheint die beste Form zu sein, um die Auffindbarkeit zu garantieren - aber wie steht es mit deren Langlebigkeit? Ein Blog scheint die beste Form zu sein, um den Prozesscharakter von Forschung deutlich zu machen – aber wie verhindere ich einerseits, dass Daten, die ich aus guten Gründen (noch) nicht in klassischer Form veröffentlicht habe, von anderen ohne Quellenangabe übernommen oder als sicherer Befund missverstanden werden, und andererseits dass sie dann doch mit der Website für immer gelöscht werden? Kann ein Prozess formal beschrieben werden, der private Websites inhaltlich so erschließt, dass sich aus dieser Erschließung eine Entscheidungsgrundlage für die Webarchivierung (etwa im Rahmen des Webharvesting der DNB) ergibt?;datapublication;0;0;0;Websitearchivierung;0;0;0;1;;3;;5;;https://4memory.de/problem-stories-overview/26-wenn-ich-forschungsergebnisse-auf-einer-website-veroffentliche-wie-ist-dann-die-langzeitverfugbarkeit-zu-sichern/;;;;;;;Langzeitverfügbarkeit;;;;;;;;
27;Praxisempfehlung für den digitalen genealogischen Nachlass;Viele Menschen steigen erst nach Abschluss des Arbeitslebens in die familiengeschichtliche Forschung ein und machen sich dann von Anfang an Gedanken darüber, dass ihre Forschertätigkeit endlich ist. Daraus ergibt sich ein starkes Interesse an der Frage, wie man seine Ergebnisse über die eigene Lebensdauer verfügbar hält. Dafür scheinen drei Medientypen geeignet: (a) die Archivierung der Forschungsdaten (wenn nicht auf Papier im Staatsarchiv, dann digital in einem Datenarchiv), (b) die Selbstpublikation der Ergebnisse im Internet oder auch im Druck, (c) die „zitierfähige“ Publikation, wiederum im Internet (mit persistenter URL) oder auch als Verlagspublikation (mit ISBN). Hier stellt sich zunächst die Frage, wie die Forschungsdaten denn sortiert, gestaltet, gekennzeichnet sein müssen, damit sie überhaupt für eine Archivierung in Frage kommen, und ob es einen bestimmten Umfang, eine zeitliche Tiefe oder Qualitätsmaßstäbe gibt, die erreicht werden müssen. Gibt es eine Strategie für klar definierte große Bestände einerseits, weniger strukturierte Sammlungen in einem noch aufzubauenden durchsuchbaren Zufallsfundrepositorium andererseits? Wie geht man damit um, dass bestimmte Datenbestände zum Wegwerfen zu schade, aber zum Veröffentlichen nicht sicher genug erscheinen?;datareuse;0;0;0;Digitaler Nachlass;Datenarchivierung;0;0;1;;;;;;https://4memory.de/problem-stories-overview/27-praxisempfehlung-fur-den-digitalen-genealogischen-nachlass/;;Datentypen;;;Kompetenzen;Kuration;Langzeitverfügbarkeit;;;;;Qualität;;;Standards
28;Gibt es wissenschaftliche Standards für die Ahnenforschung?;Ich steige als Privatmann gerade in die Ahnenforschung ein. Ich sehe die Ahnenforschung allerdings nicht nur als Selbstbeschäftigung, auch andere sollen etwas von den Forschungsergebnissen (und -Wegen) haben und sie bestmöglich selbst vollständig nachvollziehen können. Gibt es wissenschaftliche Standards die ich anwenden kann, um dies zu garantieren? Könnte das Forschungsdatenmanagement nicht nur die Forschungsdaten managen, sondern über den gesamten Prozess, wie man solche Daten – z.B. eben über die Vorfahren – zusammenstellt, so klar informiert, schult und berät, dass auch Anfänger den verstehen?;datacollection;0;0;0;Schulung;wissenschaftliche Standards;0;0;1;;;4;;;https://4memory.de/problem-stories-overview/28-gibt-es-wissenschaftliche-standards-fur-die-ahnenforschung/;;;;;Kompetenzen;;;;;;;;;;Standards
29;Aufbau einer integrierten Datenbank zu familiären Beziehungen;"In unserem familienkundlichen Verein wird seit den 1990er Jahren immer wieder der Wunsch laut, dass eine gemeinsame Familiendatenbank aufgebaut wird, an der alle Mitglieder gleichzeitig mitarbeiten können. Ziel wäre es, dass eine Person jeweils nur einmal in der Datei auftaucht, und dass sowohl die Originalquellen (z.B. Kirchenbücher oder Volkszählungslisten) als auch die Kontaktdaten der Bearbeiter transparent angegeben werden. Grundlage wären nicht die laufenden, sondern die jeweils bereits abgeschlossenen Forschungen, wobei allerdings auch Datenbestände unterhalb der Ebene eines abgeschlossenen Ortsfamilienbuchs genutzt werden sollen. Gesucht werden erstens Verfahren der eindeutigen Identifikation von Personen über Normdaten, zweitens Verfahren und Standards der Datenkuratierung, drittens Techniken der Programmierung von Webinterfaces, die eine niederschwellige Pflege und Abfrage der Daten ermöglichen. Eine andere Variante dieser Problematik stellt sich dort, wo verschiedene regionale Familiendatenbanken bereits existieren und nicht von einem ""Schwarm"", sondern von Einzelnen verantwortet werden. Einer der beteiligten regionalen Vereine hat z.B. eine Familiendatenbank mit etwa einer halben Million Personendatensätzen erstellt, die ungefähr den Raum eines ganzen Bundeslandes für die Zeit ab ca. 1700 erfasst. Ein anderer Verein strebt an, einen an das niederländische (dort von einem Verbund von Archiven getragene) Portal https://www.wiewaswie.nl/en/ angelehnten Verbund aus bereits publizierten Ortsfamilienbüchern zu schaffen. Ein langfristiges Ziel des Vereins für Computergenealogie besteht darin, die für etwa 800 Orte separat geführten Online-Ortsfamilienbücher mit zusammen über 10 Millionen historischen Personendatensätzen untereinander zu verknüpfen. In jedem Fall stellt die Verknüpfung über Normdaten ein Problem dar, weil personenbezogene Normdaten erst über Verfahren der Record Linkage hergestellt werden müssen. Hier käme es darauf an, dass eine Best Practice zur Konstruktion personenbezogener Normdaten erarbeitet würde.";datacollection;dataprocessing;datapublication;0;Familienrekonstitution;Record Linkage;Normdaten;0;1;2;3;;;;https://4memory.de/problem-stories-overview/29-aufbau-einer-integrierten-datenbank-zu-familiaren-beziehungen/;;Datentypen;;;;Kuration;;Lizenzen;;Methoden;;;;;Standards
30;Ohne Rechte und Incentives? Probleme der Auswertung und Publikation personenbezogener Daten in der multilingualen Tagebuchforschung;Aus der Praxis meiner Arbeit mit in verschiedenen Ländern verstreuten und in unterschiedlichen Sprachen verfassten historischen Quellen zu einem geschichtspolitisch kontroversen Thema gibt es v.a. drei Problemfelder: Rechte, Erfassung/Auswertung, Nutzung. Auch wenn mir Daten zur wissenschaftlichen Auswertung bereitgestellt werden, haben mir fast alle Rechteinhaber, darunter Archive sowie Privatpersonen, die elektronische Publikation (z.B. auf meinem Forschungsblog) oder die Weitergabe der Daten an Dritte untersagt. Jegliche Publikation der Daten kann daher nur bruchstückhaft bleiben. Dadurch entsteht eine erhebliche Schieflage des Erkenntnisgewinns, da ich nur solche Quellen allgemein zugänglich machen kann, deren Rechteinhaber ein - manchmal zweifelhaftes - Interesse an ihrer Publikation haben. Die vergleichende Auswertung der Daten wird in meinem Fall dadurch erschwert, da ich neben deutsch- und englischsprachigen Quellen auch mit japanisch- und chinesischsprachigem Material arbeite. Mir ist keine technische Infrastruktur bekannt, in der sich z. B. systematische Übersetzungsvergleiche durchführen ließen zwischen Quellen, die in mehreren lateinischen und nicht-lateinischen Schriften vorliegen. Die Schaffung und Bereitstellung solcher Infrastrukturen, die auch nicht-lateinische Schriften berücksichtigt, sind wesentlich für die Integration von Forschungsergebnissen aus den area studies in die Fachdisziplinen. Abschließend stellt sich für mich die Frage, warum ich zeit- und kostenintensiv zusammengetragenes, schwer zugängliches historisches Quellenmaterial ohne „incentives“ anderen Forschern zur Verfügung stellen sollte. Abhilfe könnte eine Übereinkunft schaffen, wonach Erstnutzer oder „Entdecker“ solcher Quellen, die einen erheblichen Beitrag zur Erschließung und Bereitstellung geleistet haben, in Arbeiten anderer Wissenschaftler genannt werden müssen und dies in der Forscher-Community als bedeutsame Forschungsleistung (ähnlich der Grundlagenforschung in Naturwissenschaften) Anerkennung findet. Das geschieht bisher nicht oder nur unzureichend. Stattdessen können sich etablierte Wissenschaftler mit besserem Zugang zu Publikationsoptionen bei der „Grundlagenforschung“ Anderer unbeschränkt bedienen, ohne dass dies als Plagiat geahndet wird, weil es sich um frei zugängliche Primärliteratur handelt. Hier müsste es an der Antrags- oder Publikationsschwelle (Verlage, Forschungsförderorganisationen etc.) einen Mechanismus geben, der dies verhindert und geisteswissenschaftliche Grundlagenforschung honoriert.;datapublication;dataprocessing;0;0;Rechte;incentives;Grundlagenforschung;0;1;;3;;5;6?;https://4memory.de/problem-stories-overview/30-ohne-rechte-und-incentives-probleme-der-auswertung-und-publikation-personenbezogener-daten-in-der-multilingualen-tagebuchforschung/;Rechte;;;;;;Langzeitverfügbarkeit;Lizenzen;Mehrsprachigkeit;Methoden;;;;;
31;Geo-Referenzierung von Orten und historischen Entitäten;Unsere Arbeitsgruppe führt eine semi-automatische prosopgraphische Auswertung durch, in welcher wir spätmittelalterliche Gelehrtenkarrieren untersuchen. Geeignete Quellen hierfür liegen bereits in digitalisierter Form vor, teilweise sind sie mit TEI oder vergleichbaren Formaten ausgezeichnet. Die Daten sind entweder über eine Schnittstelle abfragbar oder als Data-Dump verfügbar. Innerhalb der entsprechenden Texte werden verschiedene Orte genannt, deren Ortsnamen durch die mittelalterlichen Schreiber der Texte in einer nicht normierten latinisierten Schreibweise aufgezeichnet wurden. Dadurch können wir die genannten Orte aktuell noch nicht automatisch referenzieren. Zur Identifikation der Orte haben wir nach einer georeferenzierte Ortsnamen-Datenbank gesucht, welche die historischen Schreibweisen eines Ortsnamen in lateinischer und deutscher Sprache enthält. Dabei stießen wir auf die Ortsnamen-Datenbank der Monumenta Germaniae Historica (http://www.mgh.de/dmgh/imgh/geo/), die für die darin enthaltenen Orte die entsprechenden Geo-Daten und deren unterschiedlichen lateinischen Schreibweisen bereit stellt. Allerdings mussten wir feststellen, dass die MGH-Datenbank nur einen Bruchteil der in unseren Texten aufgeführten Orte enthält. Zudem stellte sich bei unserer Arbeit heraus, dass die Datenbank die darin enthaltenen Namensformen für Suchanfragen nicht expandiert, d.h. die Suche erfolgt nur in den ausgeschriebenen Namensformen und nicht in Namensformen, die mit einer abweichenden Wortendung angegeben sind. In einem zweiten Schritt wollten wir dann den Teil der durch die MGH-Datenbank referenzierten Orte auf einer Karte abtragen. Dabei mussten wir feststellen, dass es hierfür kein geeignetes historisches Kartenmaterial in digitalisierter Form vorhanden ist. Soweit wir beurteilen können, gibt es keine mit Open Access verfügbaren Karten für Mitteleuropa, welche die unterschiedlichen historische Zeitstufen der Grenzen der weltlichen und kirchlichen Entitäten abbilden. Die meisten Studien nutzen entweder moderne Google Maps-Karten oder Scans von historischen Atlanten.;dataprocessing;datapublication;0;0;Geo-Referenzierung;historische Ortsnamen;digitale historische Karten;0;1;2;3;;;;https://4memory.de/problem-stories-overview/31-geo-referenzierung-von-orten-und-historischen-entitaten/;;Datentypen;;;;;Langzeitverfügbarkeit;;Mehrsprachigkeit;Methoden;;;;;Standards
32;Übersicht über ältere Familiendatenbanken aus der akademischen Forschung;Ich bin Vertreter eines überregionalen Arbeitskreises . Etliche unserer Mitglieder haben schon seit den 1970er Jahren mit personen-, haushalts- und familienbezogenen Mikrodaten geforscht. Die entsprechenden Daten liegen in unterschiedlichen Formaten vor, unter anderem in TUSTEP, Kleio, dBase, SPSS und Access. Der Arbeitskreis kann einerseits entsprechende Daten lokalisieren, andererseits auch Wissen darüber zusammentragen, wie die damaligen Projekte gearbeitet haben. Wer kann uns dabei helfen, diese Daten für die aktuelle Forschung nutzbar zu machen und dabei insbesondere mithilfe von Normdaten anschlussfähig für neue Datenbestände zu machen?;datareuse;0;0;0;Historische Demographie;personenbezogene Daten;0;0;;2;;4;;;https://4memory.de/problem-stories-overview/32-ubersicht-uber-altere-familiendatenbanken-aus-der-akademischen-forschung/;;;;;;;;Lizenzen;;Methoden;;;;;Standards
33;Thematische Portale und Materialsammlungen ohne institutionelle Anbindung bewahren;Viele ForscherInnen und Forscher betreiben Blogseiten oder thematische Portale, auf denen sie Material aus Ihrer Forschungsarbeit oder aus dem Kontext ihrer Qualifikationsarbeiten anbieten. Gerade in den Geisteswissenschaften sind häufige Standort- und Beschäftigungswechsel keine Seltenheit. Meist kümmern sich diese Personen in privater Initiative um die Forschungsdaten, Spezialbibliographien und thematischen Portale, da sie sich mit den Themen identifizieren und profilieren. Aber was passiert, wenn jemand aus Altersgründen oder Krankheit sich nicht mehr kümmern kann? Nicht alle wissenschaftlichen Blogseiten können und müssen aufbewahrt werden, aber viele der oben beschriebenen Ressourcen sind eine wichtige Quelle für weiterführende Arbeiten und können anderen ForscherInnen viel Arbeit und Zeit sparen, die sich mit verwandten Themen und Fragestellungen beschäftigen. Wer kümmert sich also um diese Portale und Materialsammlungen, die ohne direkte institutionelle Anbindung exisitieren und gepflegt werden? Wer entscheidet, was bewahrt und was gelöscht bzw. der Wayback Machine überlassen werden kann? Wie können wertvolle Ressourcen für die zukünftige Forschung bewahrt werden?;datapublication;datareuse;0;0;Wissenschaftliche Blogs;Thematische Portale;Forschungsdaten ohne Institutionen;0;1;;3;;;6?;https://4memory.de/problem-stories-overview/33-thematische-portale-und-materialsammlungen-ohne-institutionelle-anbindung-bewahren/;Nachhaltigkeit;;;;Kompetenzen;;;;;;;;;;
34;Arbeitsgeschichte: Prozess und Alltag in historischer Perspektive;Ein internationales Projekt mit starker außereuropäischer Beteiligung untersucht die Geschichte der Arbeit eines außereuropäischen Landes seit dem 20. Jahrhundert als Prozess- und Erfahrungsgeschichte. Zum einen beinhaltet dies die Untersuchung des Wandels von Arbeitsprozessen, Arbeitswissen und betrieblicher Arbeitsorganisation seit den Anfängen des industriellen Kapitalismus. Zum anderen liegt ein Forschungsschwerpunkt auf der Alltagsgeschichte der modernen Arbeit anhand oraler und schriftlicher Selbstzeugnisse. Da auch die Quellengrundlage auch auf vielen außereuropäischen, nichtlateinischen Sprachen basiert, entsteht im Rahmen des Projekts ein in seiner Art einzigartiger, vielsprachiger Archivbestand. Er soll nicht nur die Projektarbeit dokumentieren, sondern auch der wissenschaftlichen Öffentlichkeit als Ressource zu weiteren Forschungen Open Access zur Verfügung gestellt werden. Das wissenschaftliche Design des Projekts ist fixiert. Doch es gibt offene Fragen im Hinblick auf die Aufnahme, Erschließung und Bereitstellung des mehrsprachigen Archivbestands für eine frei verfügbare digitale Präsentation: • Welche technischen Werkzeuge sind für die Erstellung und Publikation der Daten notwendig? • Gibt es hierfür Standards und Formate, die sich besonders dafür eignen? • Wie kann das Projekt mit Fragen des Datenschutzes bei personenbezogenen Daten umgehen? Hat dies Auswirkungen auf die Lizenzierung, gerade weil eine freie Verfügbarkeit der Daten angestrebt wird? • Was muss man im Projekt beachten, damit die Daten für eine langfristige Zugänglichkeit und eine nachhaltige Speicherung aufbereitet werden?;dataprocessing;datacollection;0;0;Nicht lateinische Schriften;Datenschutz;Erschließung und Bereitstellung eines mehrsprachigen Archivbestands;0;1;;3;4;;;https://4memory.de/problem-stories-overview/34-arbeitsgeschichte-prozess-und-alltag-in-historischer-perspektive/;;Datentypen;;Internationalität;;Kuration;Langzeitverfügbarkeit;Lizenzen;Mehrsprachigkeit;;;;;Softwarepflege;Standards
35;Bildungs- und Armutsgeschichte im außereuropaeischen Raum;Die Erforschung der Geschichte des betreffenden Landes steht vor grundsätzlichen Problemen hinsichtlich der Quellenlage. Zu nennen ist hier eine langjährige Vernachlässigung der einschlägigen Archivbestände, dann eine unzureichende Finanzierunggrundlage für die Sammlung, sachgerechte Unterbringung und vor allem systematische Katalogisierung und archivarische Erschließung von Quellen. Diese Probleme haben der Geschichtsforschung zu diesem Land nicht nur in Deutschland, sondern weltweit erhebliche Schwierigkeiten bereitet. Um diesem unhaltbaren Zustand in ersten Schritten abzuhelfen, hat ein Pilotprojekt verschiedenes Material gesammelt und dabei einen thematischen Schwerpunkt auf die Bildungsgeschichte gelegt. Dieses Quellenmaterial wurde in einer Zotero basierten Datenbank erschlossen. Des Weiteren ist ein Korpus von Audiomaterial entstanden, das Oral History Interviews zusammenführt. Zu den Tonaufnahmen gibt es auch entsprechende Transkriptionen. Diese Bestände sind in einem Forschungsinstitut aufbewahrt, können dort auf Anfrage kostenlos benutzt werden, was auch regelmäßig und intensiv geschieht. Der Erfolg des Pilotprojekts, in dem wertvolle Datenbestände erschlossen wurden, zeigt sich nicht zuletzt in der intensiven Nachnutzung der erschlossenen Materialien. Daraus leiten sich allerdings weitere Fragen für die fortdauernde Verfügbarkeit der Daten für die Wissenschaft ab: • Wie können die Datenbestände angesichts der intensiven Nutzung besser aufbereitet werden? Und welche Vorkehrungen muss man treffen, um einen erweiterten Nutzerkreis sowohl in Deutschland als auch international zu erreichen? • Welche Maßnahmen sind für eine langfristige Verfügbarkeit und dauerhafte Bereitstellung der Bestände zu ergreifen? • Welche Datenformate kommen hierfür infrage? Müssen also die derzeit vorhandenen Daten nochmals bearbeitet, transformiert und migriert werden? Gibt es für ein solches Szenario musterhafte Workflows? Dies auch, da das Projekt abgeschlossen ist und keine weitere Finanzierung dafür in Aussicht steht?;datacollection;dataprocessing;datapublication;datareuse;Nicht lateinische Schriften;Datenschutz;Oral History;0;1;2;3;4;;;https://4memory.de/problem-stories-overview/35-bildungs-und-armutsgeschichte-im-ausereuropaeischen-raum/;;Datentypen;;Internationalität;;Kuration;Langzeitverfügbarkeit;Lizenzen;Mehrsprachigkeit;;;;Ressourcen;;
36;perspectivia.net;Ein Nachwuchswissenschaftler möchte die gesammelten Beiträge einer von ihm organisierten internationalen Konferenz publizieren. Er hat leider keine finanziellen Mittel zur Verfügung, sodass er eine kostenfreie Lösung benötigt. Da die Beiträge von Forschenden aus vielen verschiedenen Ländern mit jeweils eigenen Publikationsmärkten stammen, strebt der Nachwuchswissenschaftler eine Veröffentlichung im Internet an. Diese Publikation soll weltweit kostenfrei zum Download verfügbar sein. Wichtig ist dem Forschenden auch eine redaktionelle Betreuung, da er darin ein Qualitätsmerkmal von Publikationen sieht, das seiner wissenschaftlichen Karriere zuträglich ist. Gleiches gilt für die regelkonforme Erschließung des Bandes nach den gängigen bibliothekarischen Standards und dessen langfristige Erreichbarkeit und Zitierbarkeit. Der Nachwuchswissenschaftler ist jedoch weder mit bibliothekarischen Standards, noch mit den unterschiedlichen Formaten von Veröffentlichungen und Wissenschaftskommunikation im Open Access vertraut. Aufgrund dessen wünscht sich der Nachwuchswissenschaftler eine Publikationsplattform, über die er die gesammelten Beiträge online im Open Access publizieren kann. Diese Plattform soll eine eigene Redaktion besitzen, und umfassende Metadaten aufweisen, die einsehbar und downloadbar sind. Die Redaktion soll den Nachwuchswissenschaftler außerdem zu den unterschiedlichen Formen wissenschaftlicher Dissemination und Publikation sowie den dazugehörigen technischen und informationswissenschaftlichen Hintergründen beraten. Jeder einzelne Beitrag des Sammelbandes soll durch persistente Identifikatoren dauerhaft zitierbar und durch backup-Systeme und digitale Langzeitarchivierung auch langfristig erreichbar sein.;dataprocessing;datacollection;datareuse;datapublication;Publikationsinfrastruktur;Open Access;Dissemination;0;1;;3;4;5;;https://4memory.de/problem-stories-overview/36-perspectivia-net/;;;;Internationalität;Kompetenzen;Kuration;Langzeitverfügbarkeit;;;;;Qualität;Ressourcen;Softwarepflege;Standards
37;OPERAS;Eine Wissenschaftlerin möchte ihre Forschungsergebnisse publizieren. Da Quellen aus unterschiedlichen Ländern in Europa und darüber hinaus Gegenstand ihrer Forschung sind, möchte die Forschende eine internationale Zielgruppe ansprechen. Zudem bietet ihre Forschung Anknüpfungspunkte für nicht historische Disziplinen, sodass sie auch für nicht historisch arbeitende Wissenschaften sichtbar sein soll. Die Publikation soll frei im Internet verfügbar sein. Gemeinsam mit ihrer Veröffentlichung möchte die Forscherin zudem einige von ihr transkribierte Quellen publizieren. Allerdings steht für die Forschende nur eine kostenlose Lösung zur Debatte, da ihr keine finanziellen Mittel für eine Publikation zur Verfügung stehen. Die Forscherin ist mit folgenden Problemen konfrontiert: • Der Wissenschaftlerin ist nicht bekannt, wie sie die gewünschte internationale und interdisziplinäre Sichtbarkeit ihrer Forschung erreichen kann. • Sie kennt das internationale Publikationswesen und die damit verbundenen Stakeholder und Communities kaum. • Auch mit den organisatorischen, technischen und informationswissenschaftlichen Hintergründen des Publizierens ist sie wenig vertraut. • Daher sind der Wissenschaftlerin weder die unterschiedlichen Formate des wissenschaftlichen Publizierens noch die dazugehörigen Standards bekannt. • Sie hat auch keine Idee, wie sich eine internationale und interdisziplinäre Sichtbarkeit ihrer Forschung sowohl organisatorisch als auch technisch umsetzten lässt. • All dies macht es der Forscherin unmöglich, eine zu ihren Anforderungen passende Publikationsstrategie zu entwickeln. Die Wissenschaftlerin wünscht sich deshalb eine zentrale Plattform, die ihr dabei hilft, eine bedarfsgerechte Veröffentlichungsstrategie zu entwickeln. Von dieser Infrastruktur wünscht sich die Forscherin nicht nur Beratung zu den verschiedenen Formen und Formaten der internationalen Wissenschaftskommunikation, sondern auch zu den organisatorischen, technischen und informationswissenschaftlichen Werkzeugen, um ihre Forschung international und interdisziplinär sichtbar zu machen. Die Wissenschaftlerin wünscht sich des Weiteren, dass die Infrastruktur ihr nationale und internationale Kontakte vermittelt, die ihr beim Erreichen ihres Zieles behilflich sein können.;datacollection;dataprocessing;datapublication;datareuse;Publikationsinfrastruktur;Internationale Vernetzung;Open Access;0;1;;3;4;5;;https://4memory.de/problem-stories-overview/37-operas/;;;Interdisziplinarität;Internationalität;Kompetenzen;;Langzeitverfügbarkeit;;;;;;Ressourcen;Softwarepflege;Standards
38;Integration von verschiedenen Datensets mit externen Werkzeugen;"Forscher_innen aus den Bereichen Geowissenschaften, Biodiversität, Archäologie, Soziologie und Geschichte befassen sich mit der Landschaftsgeschichte des Libanon über einen langen Zeitraum hinweg. Dafür möchten diese Forscher_innen ein gemeinsames Geografisches Informationssystem (GIS) aufbauen und sowohl mit Geodaten, Shapefiles als auch anderen Datenbanken als Forschungstool nutzen. Da es die für GIS notwendigen geographische Lexika (Gazetteer), die Orte mit Namen, Verwaltungseinheiten und, im besten Fall, Geodaten, für den Nahen Osten nur sehr eingeschränkt gibt, funktioniert automatisches geo-referencing häufig nicht, und Toponyme werden nur unzureichend gefunden. Die Forscher_innen aus verschiedenen Disziplinen können die überwiegende Mehrheit aller Entities von internationalen Normdatensätzen nicht gebrauchen und müssen diese erst als Grundlage definieren. Notwendig wäre daher, dass • Server-basierte Plattformen zur allgemeinen Nutzung durch Forschende zur Verfügung gestellt werden; • die erlaubten Standards nicht vordefinieren, sondern volle Anpassung an die Bedürfnisse der Nutzer_innen bei gleichzeitiger Validierung der Daten erlauben; • bei der Entwicklung und Aushandlung von Standards (in der Form von z.B. Community Standards oder Best Practices) Hilfe geboten wird.";datareuse;datapublication;dataprocessing;datacollection;Geografisches Informationssystem (GIS);Geodaten;Interdisziplinarität;0;1;2;;;;;https://4memory.de/problem-stories-overview/38-integration-von-verschiedenen-datensets-mit-externen-werkzeugen/;;Datentypen;Interdisziplinarität;Internationalität;;;Langzeitverfügbarkeit;;;;;;;Softwarepflege;Standards
39;Wissen entgrenzen;Mehrere Forschende arbeiten über verschiedene Standorte international verteilt an ihren Projekten, die einem gemeinsamen Metathema verpflichtet sind. Der Austausch mit den Projektbeteiligten an den anderen Standorten ist von zentraler Bedeutung. Ungeachtet der räumlichen, sprachlichen und fachdisziplinären Diversität benötigen alle eine gemeinsame Infrastruktur, mit der sie untereinander kommunizieren, Befunde teilen und gemeinsame Ergebnisse präsentieren können. Dazu soll auch eine multimediale Datenbank in verschiedenen Sprachen (Arabisch, Persisch und Russisch) gehören. Die Forschenden stehen vor folgenden Problemen: • Die Beteiligten der Projektgruppen sind sich unsicher, welche Kommunikationskanäle ihnen stabile Nutzungsbedingungen bieten können, zumal sie in Regionen mit unterschiedlichen, vor allem aber schwachen technischen Standards arbeiten. • Unklar ist für sie ebenso, wie sie bei der Nutzung dieser Services vor dem Verlust von Forschungsdaten gefeit sind. • Erst recht gilt dies für den Datenschutz, auf den einige von ihnen aufgrund ihrer Forschungsarbeit in politisch brisanten Regionen besonders angewiesen sind. Die Gruppe wünscht sich daher eine Forschungsumgebung, die ausfallsichere Kommunikationswege aufweist. Wichtig ist für sie die Möglichkeit, erhobene Forschungsdaten und Forschungsergebnisse ausfallsicher hinterlegen und auch untereinander austauschen zu können. Zu den Anforderungen an das Speichersystem gehört auch, dass multilinguale Texte und verschiedene Dateiformate sicher hinterlegt werden können, von Textdateien über Bildformate bis hin zu Audio- und Videomaterial. Die Gewährleistung der Datenschutzanforderungen verschiedener Jurisdiktionen ist eine besondere Anforderung.;datapublication;datareuse;datacollection;dataprocessing;Transregionale Forschung;Nicht lateinische Schriften;Internationalität/Mehrsprachigkeit;0;1;;3;4;5;6?;https://4memory.de/problem-stories-overview/39-wissen-entgrenzen/;Rechte;Datentypen;;Internationalität;Kompetenzen;;;Lizenzen;Mehrsprachigkeit;;;;;;Standards
40;Software und Datenmodelle;Ich befasse mich mit den kulturellen Artefakten außereuropäischer Gesellschaften und benötige dafür digitale Werkzeuge, die nicht schon bei der Erfassung der Daten erfordern, diese mit Modellen des Globalen Nordens im frühen 21. Jahrhundert zu beschreiben. Zur Beschreibung meines Forschungsgegenstands muss die Möglichkeit der Vielsprachigkeit und Vielschriftlichkeit gegeben sein, ohne dass eine der Sprachen Präzedenz über die anderen hat. Voller Unicodesupport auf allen Ebenen der digitalen Datenverarbeitung ist hierbei notwendig, aber nicht ausreichend (und leider auch momentan keinesfalls gegeben). Personennamen müssen jenseits von Vor- und Nachnamen beschrieben werden können. Ereignisse müssen sich jenseits des gregorianischen Kalenders mit 24 equinoctalen Stunden und einem Tagesbeginn um Mitternacht in der Zeit verorten lassen. Normalisierung ist wichtig, kann aber nicht schon bei der Datenerfassung geleistet werden, da damit eine epistemische Gewalt einhergeht, deren Auswirkungen aus den Forschungsdaten selbst nicht mehr rekonstruiert werden können.;datacollection;dataprocessing;datapublication;datareuse;Datenmodelle;nicht lateinische Schriften und Sprachen;Variantensupport;0;1;2;3;;;;https://4memory.de/problem-stories-overview/40-software-und-datenmodelle/;;;;;Kompetenzen;;;;Mehrsprachigkeit;Methoden;Modellierung;;;Softwarepflege;
41;Erfassung kultureller Artefakte des Globalen Südens;Ich befasse mich mit der Geistesgeschichte des Nahen Ostens im langen 19. Jahrhundert. Dafür möchte ich den sprachlichen Wandel durch distant reading großer Korpora untersuchen. Weltweit ist eine große Anzahl von Bilddigitalisaten schriftlicher Quellen verfügbar. Allerdings ist die automatische Texterkennung auch bei sehr teuren kommerziellen Plattformen so schlecht, dass diese nicht für meine Zwecke benutzt werden können. Es gibt offene, auf maschinellem Lernen basierende und sprachagnostische Werkzeuge, wie z.B. Kraken und Tesseract, jedoch verfüge ich weder über den technischen Sachverstand noch die notwendige Rechenkapazität, um Modelle zu trainieren und dann auf potentiell hunderttausende Seiten Faksimiles anzuwenden.;datacollection;dataprocessing;datapublication;0;Volltexterkennung (OCR);nicht lateinische Schriften;Quantitative Textanalyse;0;;;3;4;;;https://4memory.de/problem-stories-overview/41-erfassung-kultureller-artefakte-des-globalen-sudens/;HPC;Datentypen;;;;;Langzeitverfügbarkeit;;Mehrsprachigkeit;Methoden;Modellierung;;;Softwarepflege;
42;Normdaten;Ich bin SozialhistorikerIn des spätosmanischen Nahen Ostens und habe in meinen Quellen eine große Anzahl Personen, Orte, und Institutionen identifiziert. Diese unter großem Zeitaufwand erstellten Rohdaten historischer Forschung möchte ich zur Nachnutzung als Linked Open Data im Semantic Web veröffentlichen. Existierende Normdatensätze und Plattformen zur deren Auffindung, wie z.B. Wikidata, VIAF, OCLC oder PeriodO decken mein Forschungsgebiet nur sehr mangelhaft ab, was auch daran liegt, dass die für mein Forschungsgebiet relevanten Sprachen (Arabisch, Persisch, Osmanisch) und Kalender (islamischer Mondkalender, julianischer Kalender, osmanischer Finanzkalender etc.) nur unzureichend oder gar nicht unterstützt werden. So lassen sich Namen z.B. nur in einer sehr spezifischen Transkription auffinden, aber nicht in der Schrift, Sprache und Form der Quellen. Gazeteers für das Georeferencing von Toponymen sind ebenso wie Shapefiles praktisch inexistent.;datacollection;dataprocessing;datapublication;datareuse;Historische Norm- und Geodaten;Karten;nicht lateinische Schrift (Arabisch);0;;2;;;;;https://4memory.de/problem-stories-overview/42-normdaten/;;Datentypen;;;Kompetenzen;Kuration;Langzeitverfügbarkeit;;Mehrsprachigkeit;Methoden;;;Ressourcen;Softwarepflege;Standards
43;Retrodigitalisierung und Volltexterkennung von Handschriften in nicht lateinischer Schrift;Ein Forschender möchte einige historische Handschriften in nicht lateinischer Schrift retrodigitalisieren und eine Volltexterkennung durchführen. Dabei steht er vor dem Problem, dass die ihm bekannten Tools zur Retrodigitalisierung auf lateinischschriftliche Druckschriften ausgelegt sind und deshalb entweder nicht funktionieren oder schlechte Ergebnisse liefern. Zudem sind die Handschriften an unterschiedlichen Orten zu finden, sodass eine zentral zu verwaltende, aber ortsverteilt durchführbare Lösung wünschenswert ist. Sowohl retrodigitalisierte Bilder als auch Texte sollen nachhaltig gesichert werden. Dem Forschenden stellen sich daher einige Fragen: • Welche Hard- und Software sind für die Retrodigitalisierung und Volltexterkennung von Handschriften in nicht lateinischer Schrift notwendig? • Welche Richtlinien und Standards sind bei der Digitalisierung und Volltexterkennung von handschriftlichen Dokumenten in nicht lateinischer Schrift zu beachten? • Wie lässt sich ein solcher Digitalisierungsprozess als Workflow ortsverteilt gestalten und koordinieren? • Was für Daten entstehen bei einem solchen Digitalisierungsprozess und wie können diese nachhaltig gesichert werden?;datacollection;dataprocessing;datareuse;datapublication;Volltexterkennung (OCR);nicht lateinische Schriften;Handschriften;0;1;2;3;;;;https://4memory.de/problem-stories-overview/43-retrodigitalisierung-und-volltexterkennung-von-handschriften-in-nicht-lateinischer-schrift/;;Datentypen;;;;;;;Mehrsprachigkeit;Methoden;;;;Softwarepflege;Standards
44;Netzwerkforschung aus prosopographischer Perspektive;"Eine Forschende möchte prosopographische Netzwerke in Europa ermitteln und veranschaulichen. Zu diesem Zweck muss sie Quellen in unterschiedlichen lateinischen und nicht lateinischen Schriften sammeln, erfassen und analysieren. Anschließend sollen die Daten interaktiv visualisiert werden. Die Forschende muss unter anderem die nachfolgenden Probleme bewältigen: • Die zu untersuchenden Quellen müssen gesammelt, zusammengeführt und in normierter Form erfasst werden. Dafür mangelt es an einer geeigneten technischen Lösung. Zudem ist unklar, welche Anforderungen notwendig sind, um ein solches System auszuwählen; ebenso, welche Arbeitsaufwände und Kosten es erzeugt. • Zudem herrscht Unklarheit hinsichtlich der Frage, wie man die in unterschiedlichen Sprachen und Schriften vorliegenden Quellen so erfassen und auswerten kann, dass man möglichst ohne großen Aufwand die gesuchten Netzwerke herausarbeiten und visualisieren kann. • Des Weiteren ist nicht klar, ob bzw. wie man digitale Methoden und Werkzeuge zur Netzwerkanalyse einsetzen kann bzw. wobei diese helfen können. Daher sind auch die mit derartigen Methoden verbundenen Standards nicht bewusst. • Schließlich ist unklar, wie Netzwerkanalysen angemessen präsentiert und publiziert werden können. Hierfür fehlt eine passende Publikationsumgebung. Außerdem ist nicht klar, wie die Netzwerkanalysen und Quellen langfristig gesichert werden können und was dafür erforderlich ist.";datacollection;dataprocessing;datapublication;datareuse;Netzwerkforschung;nicht lateinische Quellen;Prosopographie;0;1;2;3;4;;;https://4memory.de/problem-stories-overview/44-netzwerkforschung-aus-prosopographischer-perspektive/;;;;;;;Langzeitverfügbarkeit;;Mehrsprachigkeit;Methoden;;;Ressourcen;Softwarepflege;Standards
45;Städtetourismus aus historischer Perspektive;Ein Forschender möchte die Rolle des kommerziellen Städtetourismus für die historische Sinnbildung untersuchen. Zu diesem Zweck sollen einerseits städtetouristische Angebote erfasst sowie typologisiert und andererseits Interviews mit StadtführerInnen und ReiseveranstalterInnen in verschiedenen Sprachen durchgeführt werden. Das Material umfasst sowohl lateinischschriftliche als auch nicht lateinischschriftliche Quellen. Der Forschende ist dabei mit verschiedenen Problemen konfrontiert: • Er muss digitale und analog vorliegende Reiseangebote sammeln, zusammenführen und kategorisieren. Der Forschende weiß jedoch nicht, welche technischen Hilfsmittel sich dafür eignen und welche Standards und Richtlinien dafür notwendig und sinnvoll sind. • Weiterhin muss der Forschende eine technische Lösung finden, um die unterschiedlichen Arten der von ihm untersuchten Quellen (Texte und Bilder in gedruckter und digitaler Form, audiovisuelle Interviews und die dazugehörigen Transkriptionen) zu verwalten, zu publizieren und langfristig zu sichern. • Unklarheit besteht auch bezüglich datenschutzrechtlicher sowie persönlichkeitsrechtlicher Aspekte vor allem bei der Behandlung von Daten aus aktuellen kommerziellen Dienstleistungen (Städtereisen). Erschwerend kommt hinzu, dass einige der Quellen und Angebote aus dem Ausland stammen und somit möglicherweise nicht nach deutschem Recht lizenziert werden können.;datacollection;datapublication;dataprocessing;datareuse;Städtetourismus;Datenschutz;nicht lateinischschriftliche Quellen;0;1;;3;4;5;6?;https://4memory.de/problem-stories-overview/45-stadtetourismus-aus-historischer-perspektive/;Rechte;Datentypen;;;;;Langzeitverfügbarkeit;Lizenzen;Mehrsprachigkeit;;;;;;Standards
46;Adlige Identitäten und Repräsentationskulturen im Königlichen Preußen des 17. und 18. Jahrhunderts;Eine Forschende untersucht Regionalität und Regionsbildung aus interdisziplinärer (genauer gesagt historischer und kunsthistorischer) Perspektive mit Blick auf die Identitäten und Repräsentationskultur des Adels im 17. und 18. Jahrhundert. Zu diesem Zweck sind Werke der bildenden und angewandten Künste sowie der Architektur zu untersuchen. Hierzu zählen unter anderem Adelssitze mit ihrer künstlerischen Ausstattung, Kirchen, Grabmäler, Stiftungen, Sammlungen usw. Untersucht werden entweder die Objekte selbst oder – im Falle ihres Verlustes – die Spuren, die sie in Inventaren, Briefen, Beschreibungen etc. hinterlassen haben. Es sollen sowohl Digitalisate der untersuchten Quellen als auch die Ergebnisse der Forschung virtuell präsentiert und gesichert werden. Die Forschende stößt bei ihrem Forschungsvorhaben auf folgende Probleme: • Die für die Forschung relevanten Quellen sind örtlich stark verteilt und umfassen unterschiedliche Objekttypen, unter anderem Texte, Bildmaterial, Architektur, Objekte des Kunsthandwerks, etc. Dies erschwert die Schaffung eines einheitlichen Quellenkorpus. • Die Objekttypen weisen jeweils verschiedene mediale Charakteristika auf, die für ihre Erfassung und Beschreibung wichtig sind. Dies macht die Gestaltung einheitlicher Metadaten schwierig, auch weil die Forschende mit den unterschiedlichen Daten- und Metadatenstandards nicht vertraut ist. • Die Website soll eine virtuelle Ansicht der Digitalisate der Quellen erlauben. Dafür müssen die Quellen digitalisiert werden. Doch mit dem Prozess der digitalen Erfassung, insbesondere von Objekten, ist die Forschende nur rudimentär vertraut. • Dies alles führt zu Problemen bei der Auswahl eines geeigneten technischen Systems für die Internetpräsenz. • Auch die Frage, wie die langfristige Verfügbarkeit der Internetpräsenz und der darauf befindlichen Digitalisate gewährleistet werden kann, bereit der Forschenden Schwierigkeiten.;dataprocessing;datacollection;datapublication;datareuse;Retrodigitalisierung;Kunst;Adel;0;1;2;3;4;;;https://4memory.de/problem-stories-overview/46-adlige-identitaten-und-reprasentationskulturen-im-koniglichen-preusen-des-17-und-18-jahrhunderts/;;Datentypen;Interdisziplinarität;;;;Langzeitverfügbarkeit;;;Methoden;;;;;Standards
47;Kyrillisches Wiki mit historischen Informationen, Wörterbuch und Quellen zu Leben und Kultur des Adels;Ein Forschender möchte Informationen, ein einschlägiges Wörterbuch und historische Quellen (Bilder und Text) zu Leben und Kultur des Adels im Internet zugänglich zu machen. Sowohl die Quellen als auch die Präsentationsansicht sollen in kyrillischer Sprache sein. Der Forschende entscheidet sich für die technische Lösung des Wikis.Zur Umsetzung seines Forschungsvorhabens muss der Forschende einige problematische Aspekte klären: • Er muss zunächst einmal eine geeignete technische Plattform für das Wiki finden, die sowohl die kyrillische Schrift als auch die Bereitstellung eines Wörterbuchs unterstützt. • Zudem ist zu klären, was er für die Erstellung des Wikis tun muss und welche Kosten damit verbunden sind. • Schließlich möchte der Forschende dafür sorgen, dass das Wiki langfristig verfügbar ist. Hier stellt sich für ihn die Frage, wie dies sichergestellt werden kann.;datacollection;dataprocessing;datapublication;datareuse;Wiki;Kyrillische Schrift;Wörterbuch;0;;;3;;;6?;https://4memory.de/problem-stories-overview/47-kyrillisches-wiki-mit-historischen-informationen-worterbuch-und-quellen-zu-leben-und-kultur-des-adels/;Nachhaltigkeit, Finanzierung;Datentypen;;;Kompetenzen;;Langzeitverfügbarkeit;;Mehrsprachigkeit;;;;;Softwarepflege;
48;Korpus von historischen Übersetzungen zur ideen- und begriffsgeschichtlichen Forschung;Ein Forschender möchte in einem Projekt einen Korpus von Texten aus dem 18. Jahrhundert inklusive der dazugehörigen nicht lateinischschriftlichen Übersetzungen erstellen und im Internet verfügbar machen, um Wissens- und Sprachtransfer aus ideen- und begriffsgeschichtlicher Perspektive zu erforschen. Die Internetpräsenz soll es ermöglichen, das Korpus zu durchsuchen und die unterschiedlichen Texte inklusive der dazugehörigen Übersetzungen in einer kollationierten Ansicht anzeigen zu lassen. Durch Anklicken eines Schlüsselbegriffs sollen Textstellen in anderen Texten angezeigt werden können, in denen jener Ausdruck vorkommt. Einschlägige Informationsseiten zu jedem Text sowie ein Glossar wichtiger Begriffe soll es ebenfalls geben. Jeder einzelne Eintrag soll mit persistenten Identifikatoren referenziert und zitiert werden können. Ferner soll auch eine erweiterte Suche möglich sein. Der Forschende muss folgende Probleme lösen: • Zunächst muss der Forschende die Texte in verschiedene nicht lateinische Schriftsysteme transkribieren. Allerdings kennt er dafür weder die fachgerechten Standards, noch die notwendigen Tools. • Die für das Projekt relevanten digitalen Quellen (Übersetzungen) sind hinsichtlich der Referenzierbarkeit problematisch, da keine einheitliche Zitationskultur und -form dafür existiert. Ferner werden Onlinepublikationen solcher Quellen in den Universitäten vieler Länder nicht als wissenschaftliche Publikation anerkannt. Diese beiden Probleme scheinen miteinander verbunden zu sein: Das Fehlen einer formalisierten einheitlichen Zitierweise solcher Quellen einerseits und die fehlende Wertschätzung seitens wissenschaftlicher Institutionen andererseits bedingen sich gegenseitig. • Der Forschende muss die Texte zudem mit Informationen anreichern, unter anderem zu wichtigen Begriffen und Konzepten. Er fragt sich, wie er dies so bewerkstelligen kann, dass diese Informationen auf der Internetpräsenz auffindbar sind und bei der Recherche berücksichtigt werden. • Zudem stellt sich der Forschende die Frage, welche technische Plattform er für sein Vorhaben benötigt, welcher Arbeitsaufwand damit verbunden ist und welche Kosten sich daraus ergeben. • Außerdem ist ihm noch unklar, wie er eine langfristige Pflege und Wartung seiner Website sowie der auf ihr präsentierten Daten gewährleisten kann.;datacollection;datapublication;dataprocessing;datareuse;Textkorpus;nicht lateinsiche Schrift;0;0;1;2;3;;5;6?;https://4memory.de/problem-stories-overview/48-korpus-von-historischen-ubersetzungen-zur-ideen-und-begriffsgeschichtlichen-forschung/;Nachhaltigkeit;Datentypen;;;Kompetenzen;;Langzeitverfügbarkeit;;Mehrsprachigkeit;;;;Ressourcen;Softwarepflege;Standards
49;Digitale Quellenedition historischer Berichte;Ein Forschender möchte eine digitale Edition historischer Berichte aus dem 17. und 18. Jahrhunderts im Internet veröffentlichen. Die Dokumente liegen in unterschiedlichen Sprachen in lateinischer Schrift in verschiedenen europäischen Archiven vor. Die Edition soll ein Verzeichnis der Berichte und verschiedene Register umfassen. Es soll zudem Verknüpfungen mit unterschiedlichen Arten von Normdaten (unter anderem GND, VIAF) geben. Eine erweiterte Suche soll die Recherche im Dokumentenbestand erleichtern. So soll beispielsweise nach Fundort, Titel, Absender*in, Empfänger*in, Absendeort und Empfängerdatum gesucht werden können. Der Forschende muss für sein Projekt folgende Probleme lösen: • Zunächst müssen die in verschiedenen europäischen Archiven vorhandenenhistorischen Berichten transkribiert werden. Dem Forschenden sind mit Blick auf digitale Editionen jedoch weder einschlägige Standards noch Richtlinien bekannt. • Zudem fehlt es ihm an persönlichen Kontakten in den unterschiedlichen Archiven mit ihren jeweiligen Nationalsprachen. • Der Forschende ist ferner nur rudimentär mit digitalen Editionen vertraut und kennt deren editionswissenschaftliche Gepflogenheiten und Möglichkeiten nicht. • Obwohl er eine klare Vorstellung davon hat, welche Metadaten aus Perspektive der Geschichtswissenschaft relevant sind, weiß er nicht, ob diese für digitale historische Editionen ausreichend bzw. passend sind. • Darüber hinaus ist ihm nicht bekannt, welche technische Plattform man für ein solches Vorhaben benötigt und welche Kosten damit verbunden sind. • Des Weiteren weiß der Forschende nicht, ob bzw. wie seine Edition langfristig gesichert werden kann und was dafür zu tun ist.;datacollection;datareuse;datapublication;dataprocessing;Digitale Edition;Internationales Projekt;Normdaten;0;1;2;3;4;;;https://4memory.de/problem-stories-overview/49-digitale-quellenedition-historischer-berichte/;;Datentypen;;Internationalität;;;;;Mehrsprachigkeit;;;;;Softwarepflege;Standards
50;Dezentrale Digitalisierung und virtuelle Präsentation von historischen Interviews in nicht lateinischen Schriften;Im Zuge eines internationalen Projektes sollen mehrere hundert Interviews in nicht lateinischer Schrift digitalisiert, mit Metadaten versehen und im Internet präsentiert werden. Die Interviews wurden in der ersten Hälfte des 20. Jahrhunderts verschriftlicht und befinden sich in verschiedenen Archiven im nicht europäischen Ausland. Einige der Materialien wurden bereits retrodigitalisiert. Die Projektmitarbeiter*innen sind mit folgenden Problemen konfrontiert: • Rechtliche Unsicherheiten: Es herrschen urheber- und datenschutzrechtliche Unklarheiten, unter anderem hinsichtlich der möglichen Verarbeitung personenbezogener Daten. Daher stellt sich die Frage, welche Maßnahmen zum Schutz dieser Daten getroffen werden müssen und wie sie umgesetzt werden können. Hierzu zählen unter anderem Anonymisierungskonzepte und -standards, aber auch die Frage, ob und in welcher Form derartige Materialien veröffentlicht werden dürfen. • Metadaten: Unklar ist, welche Metadaten für das Projekt notwendig sind und inwiefern bereits in den Archiven vorhandene Metadaten nachnutzbar sind. Des Weiteren herrscht Unklarheit darüber, wie man die Metadaten so gestaltet, dass sie die historischen, bibliothekarischen und archivwissenschaftlichen Anforderungen in mehreren Sprachen erfüllen. • Standards für Textdaten: Es besteht Unklarheit, welche Standards für die Veröffentlichung von Textdaten existieren und welche in dem vorliegenden Fall wie anzuwenden sind. • Technische Plattform: Es wird eine technische Lösung gesucht, um die Metadaten dezentral in mehreren lateinischen und nicht lateinischen Schriften erfassen und präsentieren zu können. Darüber hinaus soll eine Volltextsuche in den Interviews möglich sein. Die Visualisierung von Standorten auf interaktiven Karten soll ebenfalls unterstützt werden. Die technische Lösung soll des Weiteren anschlussfähig für Systeme zur digitalen Langzeitarchivierung für die dauerhafte Speicherung sein. • Workflow: Es besteht die Schwierigkeit, einen Arbeitsablauf zu organisieren, der die unterschiedlichen dezentral stattfindenden Arbeitsschritte koordiniert und dokumentiert.;dataprocessing;datacollection;datapublication;datareuse;Interviews;Transkription nicht lateinischer Schriften;Datenschutz;0;1;2;3;4;;6?;https://4memory.de/problem-stories-overview/50-dezentrale-digitalisierung-und-virtuelle-prasentation-von-historischen-interviews-in-nicht-lateinischen-schriften/;Nachhaltigkeit;Datentypen;;Internationalität;;;Langzeitverfügbarkeit;Lizenzen;Mehrsprachigkeit;Methoden;;;;Softwarepflege;Standards
51;Ortsverteilte Digitalisierung und virtuelle Präsentation nicht lateinschriftlicher Archivakten;Im Zuge eines geförderten Projekts sollen mehrere Millionen Blatt Akten in lateinischer und nicht lateinischer Schrift aus der ersten Hälfte des 20. Jahrhunderts digitalisiert und im Internet mehrsprachig präsentiert werden. Die Aktenbestände befinden sich in unterschiedlichen Archiven im In- und Ausland und weisen unterschiedliche Arten sowie Grade der Erschließung auf. Die Projektmitarbeiter*innen stehen vor dem Problem, einen koordinierten, aber dezentral organisierten Workflow zur Retrodigitialisierung und Erschließung der Akten zu entwickeln. Hierbei stellt sich zunächst die organisatorische und gleichsam diplomatische Frage, wie man am besten mit den betreffenden Archiven in Kontakt treten und die Arbeiten organisieren kann. Dann bestehen urheber- und datenschutzrechtliche Zweifel, insbesondere vor dem Hintergrund, dass viele der Akten in Archiven außerhalb Europas aufbewahrt werden. Dazu zählen auch veröffentlichungsrechtliche Fragen, etwa, inwieweit und in welcher Form man digitalisiertes Schriftgut aus nicht deutschen Archiven überhaupt virtuell publizieren darf. Ferner besteht die Schwierigkeit, ein aussagekräftiges, aber nicht zu kompliziertes Metadatenschema in mehreren (auch nicht lateinischen) Schriften zu entwickeln, das sowohl historischen als auch archivwissenschaftlichen Ansprüchen genügt. Hierbei besteht zudem der Wunsch, bereits in den Archiven vorliegende Metadaten mit dem projekteigenen Metadatenset zu harmonisieren und somit für die Projektarbeit nachzunutzen. Schlussendlich stellt sich das Problem, eine passende technische Grundlage zu finden, um nicht nur den Projektworkflow zu unterstützen, sondern die digitalisierten und mit Metadaten angereicherten Akten auch in rechtlich zulässiger Form im Internet verfügbar zu machen.;datacollection;dataprocessing;datapublication;datareuse;Retrodigitalisierung;mehrsprachige Metadaten;Akten;0;1;;3;4;;;https://4memory.de/problem-stories-overview/51-ortsverteilte-digitalisierung-und-virtuelle-prasentation-nicht-lateinschriftlicher-archivakten/;;Datentypen;;;Kompetenzen;;Langzeitverfügbarkeit;Lizenzen;Mehrsprachigkeit;Methoden;;;;;Standards
52;Publikation von Forschungsdaten als Ergänzung eines Zeitschriftenaufsatzes;Als Redakteur einer geschichtswissenschaftlichen Zeitschrift will ich die Publikation von Forschungsdaten organisieren, um die in Aufsätzen publizierten Forschungsergebnisse anhand der verwendeten Daten (Quellen) nachvollziehbar bzw. reproduzierbar zu machen. Das Problem ist, dass aktuell noch Empfehlungen und Leitlinien für Autoren zur Veröffentlichung sowie zur Sicherung der Datenqualität und ein Metadatenschema zur adäquaten Beschreibung geschichtswissenschaftlicher Forschungsdaten mit Metadaten fehlen. Soll die Publikation von Forschungsdaten in einer Forschungsdaten-Policy für die Zeitschrift geregelt werden oder in einer eigenen Forschungsdaten-Policy der herausgebenden Körperschaft (Institut) festgelegt sein? In welchem Repositorium sollen die Forschungsdaten zur Verfügung gestellt werden? Reicht ggf. eine Veröffentlichung als Supplement auf der Website des Zeitschriftenverlags oder sollte besser ein fachspezisches bzw. das institutionelle Forschungsdatenrepositorium verwendet werden? Welche fachspezifischen methodischen Aspekte der Erstellung, Sammlung, Aufbereitung, Auswertung oder sonstigen Bearbeitung der Forschungsdaten müssen neben den administrativen, rechtlichen und natürlich technischen Aspekten in den Metadaten beschrieben werden?;datapublication;0;0;0;Publikation;Zeitschrift;Forschungsdaten-Policy;0;1;;;;5;;https://4memory.de/problem-stories-overview/52-publikation-von-forschungsdaten-als-erganzung-eines-zeitschriftenaufsatzes/;;;;;Kompetenzen;Kuration;Langzeitverfügbarkeit;;;Methoden;;;;;Standards
53;Datendokumentation zur Nachvollziehbarkeit der Aufbereitung von Forschungsdaten;Als Forschungsdatenmanager oder Forscher möchte ich den Entstehungsverlauf meiner Forschungsdaten im Forschungsprozess genau dokumentieren, um die Verarbeitungsschritte nachvollziehbar zu machen und die Arbeitsabläufe zur Erstellung und weiteren Verarbeitung darüber hinaus als Vorlage für spätere, ähnliche Projekte festzuhalten. Ein typischer Workflow ist beispielsweise die Annotation und Identifikation von in Textquellen genannten Entitäten (Personen, Organisationen, Orte, Ereignisse, Begriffe, usw.) mit Named Entity Recognition- und Named Entity Disambiguation-Werkzeugen oder insbesondere auch die Reconciliation von Entitäten in tabellarischen Daten (etwa zur Harmonisierung historischer Zensusdaten) – z.B. mit dem Tool OpenRefine. Wichtig dabei ist eine Dokumentation der Aufbereitung der Forschungsdaten möglichst schon während des Forschungsprozesses: Wer hat was mit welchem Werkzeug und mit welcher Zuverlässigkeit angereichert? Ideal wären dazu Plattformen, die eine Dokumentation der Arbeitsschritte zur Erstellung und Anreicherung der Forschungsdaten gemäß Datenmanagementplan (DMP) – d.h. Forschungsdatenmanagement-Workflows im “life cycle of historical information” (siehe dazu https://doi.org/10.3233/SW-140158) – unterstützt. Für eine spätere Nachnutzung der Daten ist eine ausführliche Datendokumentation wichtig zur Suche nach relevanten Forschungsdaten (z.B. anhand der verwendeten Datenmodelle und Standards wie SDMX, RDF Data Cube und SKOS für Kodierlisten in statistischen Daten) und zur Einschätzung der Qualität der angereicherten Daten (z.B. bei der Zusammenstellung und Integration von kodierten Daten zur statistischen Analyse).;dataprocessing;0;0;0;Datendokumentation;Forschungsdatenmanagement-Workflow;Datenmanagementplan;0;1;2;3;;;;https://4memory.de/problem-stories-overview/53-datendokumentation-zur-nachvollziehbarkeit-der-aufbereitung-von-forschungsdaten/;;Datentypen;;;Kompetenzen;Kuration;Langzeitverfügbarkeit;;;Methoden;Modellierung;Qualität;;Softwarepflege;Standards
54;Projektbezug und Zusammenhang mit anderen Ressourcen herstellen;Als Forschungsdatenkurator möchte ich ich Forschungsdatensätze und weitere Ressourcen miteinander verknüpfen, um den Entstehungszusammenhang und die Beziehungen zu weiterem Forschungsoutput sichtbarer zu machen. Eine Mindestanforderung ist dabei z.B. die Berücksichtigung der DataCite-Relationstypen IsReferencedBy, IsCitedBy und IsSupplementTo zur Verbindung von Forschungsdaten mit zugehörigen Forschungspublikationen, aber auch Relationen wie IsDerivedFrom, IsSourceOf und IsVersionOf, die den Entstehungszusammenhang zwischen Datensätzen beschreiben. Die Verknüpfung der Ressourcen würde idealerweise mit einem (auch für die datengebenden Fachwissenschaftler einfach zu benutzenden) graphischen Editor stattfinden. Die bisher einzige Open Source-Lösung dafür scheint allerdings die mittlerweile veraltete Erweiterung ckanext-lire (LInked RElationships) für CKAN zu sein (siehe auch zugehörigen Konferenzbeitrag). Wichtig für ein Werkzeug zur Kontextualisierung von Forschungsdatensätzen wäre auch die Einbindung von Forschungsinformationssystemen bzw. auch Bibliothekskatalogen. Insbesondere der Projektkontext könnte durch die Anbindung eines Forschungsinformationssystems hergestellt werden. In Bibliothekskatalogen erfasste Publikationen können über deren DOI oder auch ISBN bzw. den permanenten Links zu den entsprechenden Katalogeinträgen verlinkt werden. Idealweise wird die Verknüpfung von Datensätzen und Publikationen durch Linked Data unterstützt. Für den Projektkontext kommen dazu Ontologien wie PROV-O, FRAPO, VIVO-ISF oder auch die Scholarly Ontology in Frage.;datapublication;0;0;0;Forschungsinformation;Provenienzinformation;graphischer Editor;0;;2;3;;;;https://4memory.de/problem-stories-overview/54-projektbezug-und-zusammenhang-mit-anderen-ressourcen-herstellen/;;;;;Kompetenzen;Kuration;Langzeitverfügbarkeit;;;;;;;Softwarepflege;Standards
55;Digitale Textanalyse in internationalen historischen Zeitungen;Eine Gruppe von Forschenden möchte den sprachlichen Wandel rund um das Thema “Politikverdrossenheit” in internationalen historischen Zeitungen des 19. und 20. Jahrhunderts untersuchen. Die Zeitungen liegen in Teilen digitalisiert vor, allerdings auf unterschiedlichen, internationalen Plattformen. Nicht alle sind im Volltext erfasst. In Teilen gibt es sie nur gedruckt. Die Gruppe steht vor folgenden Problemen: • Wie kann sie die großen Mengen an Zeitungsartikeln unterschiedlicher Herkunft mit wenig Aufwand und unter Einhaltung des jeweiligen Urheberrechts zu einem Corpus zusammenfügen? • Wie kann sie das Corpus für die digitale Analyse vorbereiten und mit internationalen Normdaten anreichern? • Wie kann sie eine digitale Analyse des Corpus vornehmen? • Wo und wie können die Daten anschließend gespeichert werden, so dass die erarbeiteten Forschungsergebnisse nachvollziehbar sind?;datacollection;dataprocessing;datapublication;0;Digitale Textanalyse;Internationale Zeitungen;0;0;;2;3;4;;;https://4memory.de/problem-stories-overview/55-digitale-textanalyse-in-internationalen-historischen-zeitungen/;;;;Internationalität;;;;;Mehrsprachigkeit;Methoden;;;Ressourcen;Softwarepflege;Standards
56;Schulung und Beratung im Bereich Geoinformationssystem (GIS);Eine Forscherin möchte gerne Geodaten, die sie aus einem gedruckten Textkorpus extrahiert hat, auf einer interaktiven Karte visualisieren. Die Daten sollen anschließend als .csv für die Forschung zur Verfügung gestellt werden. Konkret steht sie vor der Frage, welche der zahlreichen angebotenen Tools für ihre Zwecke das Geeignetste ist oder ob etwas Eigenes programmiert werden muss. Wichtig ist ihr, die Geodaten auf einer historischen Karte zu zeigen, nicht auf einer aktuellen. Sie fragt sich auch, wie sie internationale Normdaten verwenden kann, welche internationalen Gazetteers/historische Ortslexika es bereits gibt und wie und wo die Webansicht sowie die Daten nachhaltig gespeichert werden können. Gerne würde sie sich von kompetenter Seite Rat holen und an einer Schulung zu GIS einerseits und einer Einführung in die Nutzung eines konkreten Tools - sofern für ihren spezifischen Zweck vorhanden - andererseits teilnehmen.;dataprocessing;datapublication;datareuse;datacollection;Geoinformationssystem;Karten;Normdaten;0;;2;3;4;;;https://4memory.de/problem-stories-overview/56-schulung-und-beratung-im-bereich-geoinformationssystem-gis/;;Datentypen;;Internationalität;Kompetenzen;;Langzeitverfügbarkeit;;;Methoden;;;;Softwarepflege;Standards
57;Virtuelle Veröffentlichung von Quellen und Forschungsergebnissen in einem Blog;Eine Gruppe von Forschenden der Geschichtswissenschaft möchte ihre Forschungsergebnisse sowie einige Quellen (Texte, Bildmaterial) veröffentlichen. Da für die Publikation keine Finanzmittel zur Verfügung stehen, suchen sie ein Publikationsmedium im Internet, das keine Kosten verursacht, aber dennoch gut und auch international sichtbar ist. Dabei ist ihnen wichtig, den Veröffentlichungsprozess zwar komplett ohne fremde Hilfe, zugleich aber zeitversetzt und kollaborativ durchführen zu können. Zudem sollen die Veröffentlichungen im Internet frei nutzbar und gut auffindbar sein. Auch eine Kommentarfunktion wäre hilfreich, um die wissenschaftliche Diskussion zu beflügeln. Da die Publikationen nur online erscheinen, ist den Forschenden eine nachhaltige Sicherung der veröffentlichten Inhalte wichtig. Nach reiflicher Überlegung entscheiden sich die Forschenden für einen wissenschaftlichen Blog. Die Forschenden stehen vor folgenden Problemen: • Sie haben nur eingeschränkte Kenntnisse von Websystemen bzw. Webentwicklung, allerdings auch keine finanziellen Mittel, um dies in Auftrag zu geben oder jemanden dafür einzustellen. • Die Forschenden wissen nicht genau, welche Kriterien bei der Auswahl solcher Systeme wichtig sind. Daher ist ihnen nicht klar, welches System sich für ihre Bedarfe eignet und dabei auch in der Handhabung einfach ist. • Die Forschenden haben die Befürchtung, dass ihre im Internet veröffentlichten Forschungsergebnisse und Quellen mangels finanzieller Mittel irgendwann verschwinden, unter anderem weil das System, in dem die Ergebnisse präsentiert werden, veralten könnte. Sie wissen jedoch nicht, wie sie dem vorbeugen können.;datacollection;datapublication;dataprocessing;datareuse;Blog;Online-Publikation;Open Acces;0;;;3;4;5;6?;https://4memory.de/problem-stories-overview/57-virtuelle-veroffentlichung-von-quellen-und-forschungsergebnissen-in-einem-blog/;Nachhaltigkeit;Datentypen;;Internationalität;;;Langzeitverfügbarkeit;;;;;;Ressourcen;Softwarepflege;
58;Einsatz von Normdaten und kontrolliertem Vokabulare zur fachspezifischen Beschreibung von Forschungsdaten;Als Forschungsdatenkurator möchte ich Normdaten und kontrollierte Vokabulare verwenden, um Forschungsdaten möglichst fachspezifisch und mit anderen Ressourcen integrierbar zu beschreiben. Normdaten wie insbesondere die GND wären für eine effiziente Erfassung von Autoren und Forschungseinrichtungen per Autovervollständigung sehr naheliegend. Leider fehlt dafür ebenso wie für den Einsatz kontrollierter Vokabulare oft eine Unterstützung durch die technischen Plattformen. So muss man z.B. im DataCite-Editor des DHVLab der LMU die GND-IDs umständlich über OGND heraussuchen und manuell in das Eingabeformular eintragen. Kontrollierte Vokabulare sollten möglichst im SKOS-Format eingebunden werden können, da viele relevante Klassifikationssysteme, Thesauri und Gazetteers in diesem Format vorliegen, wie etwa das für historische Forschung relevante HISCO oder ICONCLASS oder auch PeriodO als Verzeichnis historischer Perioden. Am ehesten scheint noch die Web Publishing-Plattform Omeka S mit dem Value Suggest-Modul diese Anforderungen zu erfüllen. Es wäre wünschenswert, wenn im Rahmen von 4Memory entsprechende Module für bestehende Systeme oder Eigenentwicklungen entstehen würden, die diese für die Metadatenkuration sehr naheliegenden Anforderungen erfüllen.;datapublication;0;0;0;Normdaten;kontrolliertes Vokabular;SKOS (Linked Data);0;;2;3;;;;https://4memory.de/problem-stories-overview/58-einsatz-von-normdaten-und-kontrolliertem-vokabulare-zur-fachspezifischen-beschreibung-von-forschungsdaten/;;;;;Kompetenzen;Kuration;;;;;;;;Softwarepflege;Standards
59;Sicherung der einheitlichen Erfassung von Metadaten für Forschungsdaten;Als Forschungsdatenkurator möchte ich die einheitliche Beschreibung von Forschungsdaten mit Metadaten durch die Forschenden kontrollieren und sichern, um die Forschungsdaten möglichst gut wiederauffindbar zu machen. Wie gewährleiste ich eine einheitliche Beschreibung von Forschungsdaten, die von verschiedenen Wissenschaftlern aus verschiedenen disziplinären aber auch interdisziplinären Arbeitsgruppen kommen? Eine brauchbare technische Plattform, die mich beim Einrichten von Workflows für Metadaten-Review bzw. Qualitätskontrolle der Daten und Metadaten unterstützt, scheint es derzeit noch nicht zu geben.;datapublication;0;0;0;Metadaten-Qualität;Forschungsdatenmanagement-Workflow;Metadaten-Review;0;1;;3;4;;;https://4memory.de/problem-stories-overview/59-sicherung-der-einheitlichen-erfassung-von-metadaten-fur-forschungsdaten/;;;Interdisziplinarität;;Kompetenzen;Kuration;Langzeitverfügbarkeit;;;;;Qualität;;Softwarepflege;Standards
60;Historische Grenzen und Raumordnungen;Unser Online-Quellenportal bietet neben Text- und Bildquellen auch eine Vielzahl von Karten, die die wechselnden Grenzen und politischen Einheiten des heutigen Deutschlands von der Frühen Neuzeit bis in die Gegenwart zeigen. Statt statischer Karten erwarten durch Google Maps und ähnliche Dienste geprägte Nutzer*innen von einem modernen Internet-Angebot zunehmend dynamische Karten, die das Heran- und Wegzoomen bestimmter Gegenden, dynamische Animationen von Grenzverschiebungen im zeitlichen Verlauf sowie die interaktive Einblendung von Zusatzinformationen wie etwa die Lebenswege bestimmter Personen unterstützen. Programmbibliotheken wie leaflet.js ermöglichen es, solche Funktionalitäten sowohl auf aktuellen Luftbildkarten als auch mit retro-digitalisierten historischen Karten im Hintergrund zu realisieren. Uns fehlt aber ein historisches Geoinformationssystem, das die häufig wechselnden Landes- und Gebietsgrenzen in Europa und insbesondere in Deutschland über die letzten Jahrhunderte (Altes Reich, Napoleonisches Zeitalter, Deutscher Bund, Reichsgründung, Weimarer Republik, Deutsche Teilung, Neue Bundesrepublik) mit den entsprechenden Territorien (Fürsten- und Herzogtümer, Königreiche, Bundesstaaten, (Bundes-)Länder und Bezirke) in passenden Formaten hinreichend exakt und unter einer freien Lizenz bereitstellt.;dataprocessing;datareuse;datapublication;datacollection;Historische Karten;Geoinformationssystem;0;0;;2;3;;;;https://4memory.de/problem-stories-overview/60-historische-grenzen-und-raumordnungen/;;Datentypen;;;Kompetenzen;;Langzeitverfügbarkeit;Lizenzen;;Methoden;;;;;
61;19th century German immigrant letters (GHI Washington, Simone Lässig and Universität Trier, Ursula Lehmkuhl);We are editing 19th century migrant letters that are physically located in German and American archives. In order to be able to reconstruct migration patterns and migrant networks, we would like to mark persons with a unique identifier. Since these are “ordinary people”, we do not find them in existing Authority Files such as GND, LoC or Wikidata. How should we reference the existing biographical information and which markup language should we use so that the biographical information that we retrieve from the letters and from archives can easily be enhanced by future biographical research? Should we transfer our data into the Integrated Authority File (GND) and if yes, how can we do this? Secondly, we would like to store and document all biographical details (baptism, marriage and death records, census records, pension records, emigration records, ship lists) as well as additional information gathered from the letters such as occupation, places of living and family events, contacts between migrants, their families, old and new neighbors, friends and acquaintances, in order to map and visualize the migration and mobility networks. Which service and platform should we use for cooperative research data management and the long-term preservation of our research data? Which digital tools should we use for GIS mapping and network visualization?;datacollection;dataprocessing;datapublication;datareuse;Digitale Edition;Normdaten;GIS-Mapping;0;;;;;;;;Doppelt s. Nr. 15;Datentypen;;;;;;;;Methoden;;;;Softwarepflege;Standards
62;Ortsverteilte Erfassung und virtuelle Präsentation nicht lateinschriftlicher Musikquellen + Digitale und analoge Edition;Eine Gruppe von Forschenden untersucht im Rahmen eines Drittmittelprojekts orientalische Musik des 19. Jahrhunderts. Die Musikstücke liegen in analoger Form in verschiedenen Handschriften und Drucken vor, wobei teilweise unterschiedliche Quellen für ein und dasselbe Werk existieren. Die Quellen befinden sich an verschiedenen Standorten im nicht europäischen Ausland. Das Material weicht sowohl von sprachlichen als auch musikalischen Standards ab: in den Handschriften und Drucken mischen sich unterschiedliche nicht lateinische Sprachen und Schriftzeichen (mit einigen historischen Sonderzeichen), die historische Musiknotation entspricht ebenfalls nicht dem westeuropäischen Notationsstandard. Die Forschenden möchten einen einschlägigen Quellenkatalog aufbauen und im Internet zugänglich machen. Dabei stehen sie vor dem Problem, ein geeignetes technisches System zu finden, das die spezifischen sprachlichen und musikwissenschaftlichen Anforderungen der Quellen erfüllt. Zudem fragen sie sich, welche Metadaten dafür notwendig sind und wie man diese standardisiert in mehreren Sprachen und Schriftsystemen ortsverteilt erfassen und darstellen kann. Ferner stellt sich die Frage, wie man den Quellenkatalog langfristig sichern und funktionsfähig halten kann. Darüber hinaus entscheiden sich die Forschenden dafür, die Handschriften und Drucke gedruckt und online zu veröffentlichen. Hierbei stehen sie zunächst vor dem Problem, den Quellenkatalog für diesen Zweck anpassen zu müssen, um die digitalen Editionen virtuell präsentieren zu können. Unklar ist, inwiefern eine Erweiterung des Quellenkatalogs genügt oder ob stattdessen ein neues System dafür notwendig ist. Zudem wissen die Projektbeteiligten nicht, welche Standards für historische Editionen gelten, insbesondere für historische Musikeditionen und welche Editionswerkzeuge und -systeme die spezifischen sprachlichen und musikwissenschaftlichen Anforderungen des Quellmaterials erfüllen können. Ferner fehlt im Projekt ein Workflow, um ausgehend von dem analog vorliegenden Quellenmaterial digitale und gedruckte Editionen zu erstellen. Schließlich ist den Forschenden nicht klar, wie eine langfristige Sicherung der digitalen musikhistorischen Editionen sichergestellt werden kann.;datacollection;datareuse;datapublication;dataprocessing;nicht lateinische Schriften;digitale Musikedition;digitale Textedition;0;;;3;4;;6?;https://4memory.de/problem-stories-overview/62-ortsverteilte-erfassung-und-virtuelle-prasentation-nicht-lateinschriftlicher-musikquellen-digitale-und-analoge-edition/;Nachhaltigkeit;Datentypen;;;;;Langzeitverfügbarkeit;;Mehrsprachigkeit;;;;;Softwarepflege;Standards
63;Forschungssoftware;Wesentlicher Kern der Digital Humanities ist die Entwicklung und Erforschung digitaler Methoden zur Beantwortung geisteswissenschaftlicher Fragestellungen. Softwareentwicklung stellt in diesem Zusammenhang einen zentralen Bestandteil der Forschungspraxis dar. Nicht selten ist dabei die Entwicklung eines Algorithmus, einer Schnittstelle oder eines Softwarepaketes die eigentliche wissenschaftliche Leistung. Forschungssoftware entsteht in einem komplexen, kreativen, kombinatorischen und oft kollaborativen Prozess, der durch zahlreiche Abhängigkeiten zu anderen Ressourcen und Softwarekomponenten gekennzeichnet ist. Im Gegensatz zu klassischen Forschungsdaten ist der Lebenszyklus von Forschungssoftware wesentlich kürzer und weitaus anfälliger für „äußere Einflüsse“. Zum einen wird Forschungssoftware häufig nur zur kurzfristigen Erzeugung oder Verifikation von Forschungsergebnissen erstellt, zum anderen leidet sie unter der oft begrenzten Förderdauer von Projekten. Themen wie das Überarbeiten von Quellcode, um eine bessere Wartbarkeit zu erzielen, oder das Erstellen von Dokumentationen und Tutorials werden aus Zeitgründen häufig nicht in ausreichendem Maße berücksichtigt. Zudem fallen bei Auslauf der Projektmittel die Softwareentwickler*innen als notwendige technische Expert*innen weg, so dass die Software nicht mehr gepflegt wird und schnell veraltet. Als spezielle Art von Forschungsdaten stellt Software besondere Herausforderungen an den Entwicklungsprozess und an ein nachhaltiges Datenmanagement. Die Anerkennung von Software als Forschungsergebnis sowie die Schaffung institutioneller Strukturen, die Softwareentwickler*innen verlässliche Karrierewege ermöglichen und nicht zuletzt die Integration von Software in nachhaltige Forschungsdateninfrastrukturen würden maßgeblich zu einer qualitativ besseren Forschungspraxis beitragen.;datacollection;dataprocessing;datapublication;datareuse;Softwareentwicklung;Forschungssoftware als wissenschaftliche Leistung;0;0;1;;;4;;;https://4memory.de/problem-stories-overview/63-forschungssoftware/;;;;;Kompetenzen;;;;;Methoden;Modellierung;Qualität;;Softwarepflege;
64;Big Data: digitalisierte Zeitungen;Ich möchte einen großen Datensatz von digitalisierten Zeitungen analysieren. Mein Forschungsvorhaben soll die Volltexte im Hinblick auf Veränderungen thematischer Schwerpunkte in der Berichterstattung untersuchen und darüber hinaus auch eine Analyse des verwendeten Bildmaterials beinhalten. Die Daten sollen von verschiedenen Archiv- und Bibliotheksservern aggregiert werden. Die Datenmenge ist für meinen lokalen Rechner zu groß, außerdem sind die Algorithmen aus dem Bereich des maschinellen Lernens, die ich für die Analyse verwenden möchte, sehr rechenintensiv. Wo finde ich eine Institution, die mein Vorhaben mit der notwendigen Hardwareausstattung und Rechenleistung unterstützen kann?;dataprocessing;0;0;0;digitale Text- und Bildanalyse;Maschinelles Lernen;Hardware/Rechenleistung;0;;;;;5;6?;https://4memory.de/problem-stories-overview/64-big-data-digitalisierte-zeitungen/;Nachhaltigkeit;Datentypen;;;Kompetenzen;;;;;Methoden;;;;;
65;Normdaten;Ich bin Mediävist*in und habe zahlreiche in meinen Quellen genannte Personen, Orte und Institutionen identifizieren können. Nun möchte ich diese Ergebnisse einem breiteren Fachpublikum zur Verfügung stellen und damit vermeiden, dass eine solche zeitintensive Forschungstätigkeit immer wieder neu betrieben werden muss. Für diesen speziellen Datenbestand decken die derzeitig einschlägigen Normdatenrepositorien und -services wie z.B. Wikidata jedoch nur einen Bruchteil meines Bedarfes ab. Nur die wenigsten Personen lassen sich z.B. über die GND identifizieren, kleinere Ortschaften tauchen in den Gazeteers kaum auf, zudem gibt es kein normiertes Vokabular mittelalterlicher Institutionen. Allgemein fehlt es an Normdatenlösungen für meinen Fachbereich und Möglichkeiten, die Daten im Sinne des Semantic Web auf entsprechenden Plattformen als Linked Open Data (LOD) veröffentlichen zu können.;dataprocessing;datapublication;0;0;Normdaten;Linked Open Data;0;0;;;3;;;6?;https://4memory.de/problem-stories-overview/65-normdaten/;Nachhaltigkeit;Datentypen;;;;Kuration;Langzeitverfügbarkeit;;;Methoden;;;;Softwarepflege;Standards
66;Nachwuchsförderung / Digitale Edition;Ich bin Nachwuchswissenschaftler*in und möchte das innerhalb meiner Qualifizierungsarbeit verwendete Quellenkorpus veröffentlichen. Die Daten liegen als TEI-XML vor. Neben der Veröffentlichung der Rohdaten soll aber auch eine Digitale Edition entstehen. Diese soll Basisfunktionen wie (parallele) Textansichten (Transkription, Kommentierter Text, Leseversion, Übersetzung, archivalische Vorlage in Form von Bilddigitalisaten) sowie die Erschließungen über Personen, Orte, Institutionen, Ereignisse und Schlagworte ermöglichen. Darüber hinaus möchte ich den im Datenkorpus auftretenden Personenkreis und seine Interaktionsnetzwerke grafisch visualisieren. Ich bin zwar technisch einigermaßen versiert, dennoch habe ich nicht das notwendige Knowhow, ein solches Projekt umzusetzen. Da ich weder fest an einer Forschungsinstitution angestellt bin noch über eine Drittmittelförderung verfüge, fehlen mir die Mittel für die technische Umsetzung wie auch für das anschließende langfristige Hosting der Edition.;dataprocessing;datapublication;datareuse;0;Digitale Editiom;XML-TEI;0;0;;2;;;;;https://4memory.de/problem-stories-overview/66-nachwuchsforderung-digitale-edition/;;Datentypen;;;;;Langzeitverfügbarkeit;;;Methoden;;;;;Standards
67;Nicht nur Daten, sondern auch Workflows;Bei der Aufbereitung, Auswertung und Publikation von Forschungsdaten gibt es wiederkehrende Bearbeitungsschritte, die im Detail aber auch immer wieder leicht variieren können. Beispiel: Ich möchte meine Daten mit Hilfe von Named-Entity Recognition (NER)-Methoden semantisch anreichern. Das in einer Onlinedokumentation beschriebene Verfahren lässt sich jedoch nicht auf die Sprache meiner Quellen oder den für mich relevanten historischen Kontext anwenden. Gibt es ein einfach zu bedienendes Repositorium, in dem Wissenschaftler*innen ihre beispielhaften use-cases und Lösungsvorschläge publizieren können, so dass sie von anderen Wissenschaftlern nachgenutzt und gegebenenfalls um alternative Vorgehensweisen ergänzt werden können?;datapublication;datareuse;dataprocessing;0;Workflow;Named-entity recognition (NER);Repositorium;0;;2;3;4;;6?;https://4memory.de/problem-stories-overview/67-nicht-nur-daten-sondern-auch-workflows/;Nachhaltigkeit;;;;Kompetenzen;Kuration;Langzeitverfügbarkeit;;Mehrsprachigkeit;Methoden;;;;;
68;Datenmigration;Ich bin Wissenschaftler*in und möchte einen aus unterschiedlichen Quellen aggregierten Datenbestand für Fragestellungen nutzen, die ich z.B. mit Hilfe von Methoden aus dem Bereich des Textmining oder der Netzwerkanalyse beantworten könnte. Anschließend möchte ich die Ergebnisse so publizieren, dass sie von anderen Wissenschaftler*innen nachvollzogen und reproduziert werden können. Die Ausgangsdaten liegen in unterschiedlichen, fachspezifischen (teils auch älteren, heute nicht mehr gebräuchlichen) Datenformaten/Versionen vor (Plaintext, Word, Indesign, Tustep, verschiedene XML-Notationen, etc.). Mir stellen sich folgende Fragen: Wie lassen sich die Daten in ein für meine Fragestellung geeignetes Format transformieren? Gibt es einen (Web)Service für so etwas? Welches ist ein geeignetes Format für die Publikation der Ergebnisse? Wie kann ich sicherstellen, dass die Werkzeuge und Algorithmen, die ich für die Analyse benutzt habe, auch für weitere Generationen von Forschenden noch auffindbar sind und meine Ergebnisse reproduziert werden können?;datapublication;datacollection;dataprocessing;datareuse;Aggregierter Datenbestand;Textmining;Netzwerkanalyse;0;;;;4;5;;https://4memory.de/problem-stories-overview/68-datenmigration/;;;;;;;Langzeitverfügbarkeit;;;Methoden;;;;Softwarepflege;Standards
69;Wie lassen sich die Bestände unseres Forschungsarchivs zeitgemäß erschließen?;Unser Spezialarchiv, das Teil einer außeruniversitären Forschungseinrichtung ist, befasst sich mit der Bewahrung historischen Materials institutioneller wie privater Herkunft und muss daher frühere Konzepte der Strukturierung physisch vorhandener Bestände und von Wissen (Behördenhierarchien etc.) nachvollziehen. Zugleich müssen wir bei der Erschließung und Digitalisierung versuchen vorwegzunehmen, was für künftige Nutzer*innen interessant sein wird, und eine entsprechende Aufbereitung des Vorhandenen ermöglichen oder zumindest nicht verhindern. Darüber hinaus befinden wir uns in einer größeren technischen und organisatorischen Umbruchphase und stehen dabei unter anderem vor der Frage, welche Erschließungsformen zukunftsträchtig und arbeitsökonomisch sind: freie Schlagworte oder kontrollierte Vokabulare? Hierarchien oder Ontologien/Wissensnetzwerke?;datareuse;datacollection;0;0;Bestandsstrukturen;Erschließungsweisen;0;0;1;;;;;6?;https://4memory.de/problem-stories-overview/69-wie-lassen-sich-die-bestande-unseres-forschungsarchivs-zeitgemas-erschliesen/;Nachhaltigkeit;;;;;Kuration;;;;Methoden;;;;;Standards
70;Sozialdaten als Quellen der Zeitgeschichte;"Im Rahmen eines geförderten Projekts beteiligt sich das DHI London daran, Richtlinien für eine von zeithistorischen ForscherInnen dringend benötigte Infrastruktur zur Erfassung, Langzeitarchivierung, Zugänglichkeit und Auswertung neuartiger Datenbestände (sogenannter „Sozialdaten“) aufzubauen. Bei Sozialdaten handelt es sich um die seit der 2. Hälfte des 20. Jahrhunderts zunehmend erzeugten Datensammlungen einerseits staatlicher Behörden, andererseits (im breitesten Sinne) sozialwissenschaftlicher Forschungen. Dies sind heterogene, oft fragmentarisch überlieferte, quantitative und qualitative Daten. Ziel der laufenden Machbarkeitsstudie ist, vorhandene Sozialdatenbestände zu evaluieren, die Bedarfe zeithistorischer Forschung zu erfassen und Umsetzungsmodelle für den Aufbau einer solchen Forschungsdateninfrastruktur herauszuarbeiten und in der Fachcommunity breit zu verankern. Die Forschungsinfrastruktur soll unter anderem zum Erreichen folgender Ziele beitragen: • Sozialdaten sollen als historische Quellen erschlossen und langzeitarchiviert werden können; • diese Datenbestände sollen für die historische Forschung sichtbar dokumentiert und zentral recherchierbar sein; • Metadatenformate zur Kontextualisierung sollen bereitgestellt werden; • es sollen fortlaufend Tools zur optimalen Nutzung der Sozialdaten gemäß den historischen Forschungsinteressen entwickelt und betreut werden; • Beratungs- und Schulungsangebote zu Sozialdaten sollen angeboten werden; • Bedingungen einer rechtskonformen Nachnutzung von Sozialdaten in Bezug auf Datenschutz, Nutzungsbedingungen und Eigentum an den Daten sollen erkundet werden; • Plattformen für die Kommunikation zwischen DatennutzerInnen und DatenhalterInnen sowie zwischen sozial- und geschichtswissenschaftlichen Forschenden sollen entstehen; • die Verknüpfung mit anderen nationalen und internationalen Infrastrukturen gleichen Typs soll hergestellt werden, um mittel- bzw. langfristig internationale Forschungsinfrastrukturen aufbauen zu können. Die Forschenden stoßen auf folgende Probleme: • stark fragmentierte Datenbestände; • Fehlen einer leicht auffindbaren und aussagekräftigen Dokumentation der Daten (beispielsweise zum Archivierungsort); • Fehlen einheitlicher Standards zum Kuratieren zeitgeschichtlicher Daten, etwa von Interviews; • rechtliche Unklarheiten, etwa zu Datenschutz, Urheberrecht, Anonymisierung; • hohe Hürden für HistorikerInnen zur Forschung mit Sozialdaten, da frei verfügbare Sozialdatenbestände fehlen und die statistischen Kenntnisse für deren Auswertung nicht in den historischen Curricula der Universitäten verankert sind; • Nichtberücksichtigung von Schnittstellen zu sozialwissenschaftlichen Infrastrukturen und Erschließungstechniken beim bisherigen Aufbau digitaler geisteswissenschaftlicher Forschungsinfrastrukturen.";dataprocessing;datapublication;datareuse;datacollection;Sozialdaten;Virtuelle Forschungsinfrastruktur;Interdisziplinarität;0;1;;3;4;5;6?;https://4memory.de/problem-stories-overview/70-sozialdaten-als-quellen-der-zeitgeschichte/;Nachhaltigkeit, Verbindung zu anderen NFDI;;Interdisziplinarität;Internationalität;Kompetenzen;;Langzeitverfügbarkeit;Lizenzen;;Methoden;;;;Softwarepflege;Standards
71;Grenzübergreifende Forschung;Story In einem gemeinsamen Projekt italienischer, französischer und deutscher Wissenschaftler*innen werden die Berichte, Korrespondenzen und Sachzeugnisse dreier Reisender auf ihrer Grand Tour erforscht. Die Quellen befinden sich in Archiven und Museen in Italien, Frankreich, Deutschland und in der Schweiz. Viele dieser Quellen sind nicht digitalisiert, sollen aber durch das Projekt digitalisiert werden. Von Beginn an möchte das Team, dass: • die Digitalisate anschließend übergreifend auffindbar und verwendbar sind, • die Daten zu den Stationen der Grand Tour in allen beteiligten Ländern einfach auffindbar sind, • die Daten und Digitalisate im Rahmen des Wissenstransfers frei und einfach genutzt werden können. Das Projektteam findet aber in jedem Land unterschiedliche Ansprechpartner*innen, zum Beispiel sind mal die Archive und mal Forschungsinstitute zuständig. Die Wissenschaftler*innen können bei den Auskünften nicht einschätzen, inwieweit die vorgeschlagenen Lösungen auch für das andere Land passend sind. Insgesamt fehlen Best Practices und Ansprechpartner*innen für den Umgang mit Forschungsdaten in grenzübergreifenden Projekten in der Geschichtswissenschaft. Potentielle Lösung Kompetenzbereich der Max Weber Stiftung: traditionsreiche bi- und multinationale Projektarbeit;dataprocessing;datacollection;datapublication;datareuse;Retrodigitalisierung;internationale Projektarbeit;Europa;0;;;3;4;;;https://4memory.de/problem-stories-overview/71-grenzubergreifende-forschung/;;;;Internationalität;Kompetenzen;;Langzeitverfügbarkeit;;;Methoden;;;;;
72;Interdisziplinäre Forschung;Story In einem gemeinsamen Projekt wollen Kunsthistoriker*innen, Historiker*innen und Musikwissenschaftler*innen die Geschichte, Rezeption und Präsentation eines epochalen Ereignisses erforschen. Sie suchen nun für die Entwicklung des Antrags und die Planung der Aufgaben Ansprechpartner*innen und Infrastruktureinrichtungen, die ihnen sagen können, wie sie mit den entstehenden Datenmengen (Bilddaten, digitale Editionen, Textdatenbanken, annotierte Digitalisate, etc.) umgehen sollen. Sie möchten z.B. wissen: • Was sind die besten Vorgehensweisen zur Benennung der Daten und ihrer Verwaltung? • Welche Datenformate sind besonders geeignet? • Wo können sie die Daten nach Abschluss des Projektes sichern? • Wie und wo sie können sie diese Daten für andere Wissenschaftler*innen ihrer Disziplinen gut auffindbar machen? Bei der Suche nach Informationen finden sie viele sehr allgemeine und wenige genauere Hinweise, die dann aber aus der Sicht nur einer der beteiligten Disziplinen verfasst sind. Das Team findet keine Best Practices und keine Beratungen, die auf die Herausforderungen interdisziplinärer Vorhaben in ihren Wissenschaften eingehen. Potentielle Lösung Arbeitskreis Digital Humanities als ein institutionalisiertes Gremium von Digital Humanists aus der Projektpraxis in den verschiedenen Geistes- und Sozialwissenschaften;datareuse;datapublication;dataprocessing;0;Rezeption;Interdisziplinarität;Digital Humanities;0;1;;3;4;5;;https://4memory.de/problem-stories-overview/72-interdisziplinare-forschung/;;Datentypen;Interdisziplinarität;;Kompetenzen;;Langzeitverfügbarkeit;;;;;;;;
73;How to avoid misrepresentations of data;I am Principal Investigator in a project (PENELOPE, funded by ERC, Deutsches Museum) where the key objective is to explore what is categorised as tacit knowledge, in (ancient) weaving. We make a claim that mathematical knowledge, was itself abstracted from weaving principles in Ancient Greece. In order to explicate such knowledge as being rational and technological, we show coding, algorithms, and numbers implicit in weaving practices. Our problem for data management is that, even though we developed a lot of experiments (live coded looms, robot swarms dancing around a maypole, documenting tacit technological conversations of weavers at looms), only the interaction of all of them can eventually be understood as the point we make for weaving knowledge. Once we move forward, the object cannot solve the problem, and when placed in the public domain can end up misrepresenting what the research outcomes are. How do we avoid this situation? In order to generate the necessary insights, we get users to experience the nature of this knowledge, creating analogies through different algorithmic practices – in music, in computers, on looms. We will set up a final workshop/exhibit and make videos of such experiments as documentation. However, the data processing when weaving becomes available only when the object is in motion, in use. The information is complete only when there is actual engagement with the material objects of our project. How do we save this experiential component, which is available in the project, as data structure? If we put this into a data storage facility, we fall into the trap of creating a new graveyard for weaving knowledge. How do we avoid this trap? How can we actually mark points of ‘missing’ data connections?;datareuse;0;0;0;implizites Wissen;Weberei;Algorithmen;interdisziplinär;1;;3;4;;;https://4memory.de/problem-stories-overview/73-how-to-avoid-misrepresentations-of-data/;;;Interdisziplinarität;;;;;;;;;;;;
74;Kontrollierte Vokabulare und proprietäre Softwares;Als Forschungseinrichtung müssen wir die Langzeitarchivierung der Forschungsdaten sichern aber sind von unseren proprietären Softwares auf verschiedenen Ebenen eingeschränkt. Zwar erlaubt unser Datenbanksystem die Daten laut verschiedenen Formaten (e.g. XML) und Schemata eines selben Formats (e.g. archivfachlichem XML-EAC) zu exportieren aber die innerhalb des Datenbanksystems bereits bestehenden Thesauri und Taxonomien können ohne (gebührenpflichtige) technische Betreuung nicht ausgeführt werden. Da die Migration aller Forschungsdaten zu einem neuen geeigneteren (Langzeitarchivierungs-)Gerät jedenfalls zeit-, arbeits- und kostenintensiv wäre, möchten wir dafür sorgen, dass nicht nur die Daten sondern auch die kontrollierten Vokabulare aufbewahrt werden sollen. Wie werden kontrollierte Vokabulare in den Geisteswissenschaften normgerecht freigemacht und langfristig archiviert?;datapublication;0;0;0;Vokabulare;Software;Datenexport;0;;2;3;;;;https://4memory.de/problem-stories-overview/74-kontrollierte-vokabulare-und-proprietare-softwares/;;;;;Kompetenzen;;Langzeitverfügbarkeit;;;;;;;Softwarepflege;Standards
75;Sicherung und Aktualisierung von „älteren“ Datenbanken;Vor gut 20 Jahren wurden in einem Forschungsprojekt sämtliche Vorstände und Aufsichtsräte deutscher Unternehmen der Jahre 1906, 1927, 1932, 1933 und 1954 in einer Datenbank erfasst. Das Ziel war es, wirtschaftliche und familiäre Vernetzung zu ermitteln und die Struktur der Wirtschaftselite in den Umbruchzeiten zu analysieren. Als Quelle standen die Handbücher der deutschen Aktiengesellschaften in mehreren Ausgaben zur Verfügung. Die Angaben wurden per Hand in eine „Filemaker“-Datenbank eingetragen. Im Laufe der Jahre musste die Datenbank mehrfach in gängigere Formate konvertiert werden, um sie les- und bearbeitbar zu halten. Im Zuge dessen ergaben sich entsprechende Übertragungsprobleme. In diesem Kontext ergeben sich folgende Fragen: a) Wir kann die dauerhafte Sicherung und Aktualisierung von älteren Datenbanken garantiert werden? Sollte es Software-Vorgaben bzw. Empfehlungen geben, um die Daten langfristig nutzbar zu halten? b) Bei der Eingabe der Daten wurden bestimmte Schlagwörter und Abkürzungen z.B. für Berufsbezeichnungen oder Titel vergeben. Es wäre sicher sinnvoll, solche Zuordnungen von Angaben zu Personen nach einem gemeinsamen Standard vorzunehmen, um die spätere Metasuche zu erleichtern. Wie kann dies gelingen?;datareuse;0;0;0;Softwareaktualität;Datenbankkonvertierung;Datensicherung;0;;2;3;;;6?;https://4memory.de/problem-stories-overview/75-sicherung-und-aktualisierung-von-alteren-datenbanken/;Nachhaltigkeit;;;;;;Langzeitverfügbarkeit;;;Methoden;;;;Softwarepflege;Standards
76;Bereitstellung von Daten - Daten aus einer Objektsammlung;Als Forscher wollte ich gern eine datengetriebene Analyse zur Verbreitung heraldischer Motive auf mittelalterlichen Objekten durchführen. Geeignete Daten schien es an einer großen Objektsammlung zu geben, die ihre Sammlung sehr ansprechend in einem online-Portal präsentiert. Hier konnte man facettiert die Suchmenge z.B. auf Mittelalter, Deutsches Reich, heraldisch eingrenzen. Die einzelnen Objekte sind zudem jeweils in LIDO-XML beschrieben, wobei die XML-Dateien zu den Objekten jeweils downloadbar sind. Um tatsächlich über den gesamten Bestand arbeiten zu können, hätte ich auch Zugang zu den Daten der Sammlung gebraucht. Eine Schnittstelle oder einen Data-Dump für die gesamte Sammlung und das Treffen einer entsprechenden Auswahl gab es nicht. Alles, was man herunterladen konnte, waren die LIDO-Files für die einzelnen Objekte, in denen die Informationen zu den heraldische Motiven nicht inkludiert waren.;0;0;0;0;0;0;0;0;;;3;;;;https://4memory.de/problem-stories-overview/76-bereitstellung-von-daten-daten-aus-einer-objektsammlung/;;;;;;;Langzeitverfügbarkeit;;;;;;;;Standards
77;Workshop Datenpublikation: Suche Syllabus!;Als verantwortliche Person an einer außeruniversitären Einrichtung möchte ich für die Forschenden in der Qualifizierungsphase Weiterbildungsformate im Bereich Forschungsdatenmanagement anbieten. Insbesondere die Publikation von Forschungsdaten soll gemäß der institutionellen Forschungsdatenleitlinie unterstützt werden. Ein eintägiger Workshop zu Möglichkeiten und Rahmenbedingungen von Datenpublikationen in den Geschichtswissenschaften soll für den Themenbereich sensibilisieren und konkrete Handlungsoptionen für die Forschenden bieten. Eine Konzeption der Veranstaltung von Null auf wäre zu aufwendig für die Einrichtung, so dass ich auf vorhandene Konzepte und Material zurückgreifen möchte und dieses über eine Internetrecherche auffindbar sein sollte. Das Material sollte einen vollständigen Syllabus und Foliensätze umfassen sowie idealerweise auch das Feedback von Teilnehmenden bereits realisierter Veranstaltungen enthalten. Die Recherche blieb jedoch erfolglos: Veranstaltungen zum Forschungsdatenmanagement in den historischen Wissenschaften finden sich insgesamt nur wenige, die recherchierbar und dokumentiert sind, darunter sind noch weniger als Fortbildungsveranstaltung für die Qualifizierungsphase konzipiert und nachnutzbares Lehrmaterial findet sich darunter nur in absoluten Ausnahmefällen, jedoch keines zum Thema Datenpublikation. Während für generische Themen des Forschungsdatenmanagements ausreichend Material zur Verfügung steht, fehlt es an den notwendigen fachspezifischen Adaptionen, besonders im Bereich der historischen Geisteswissenschaften.;0;0;0;0;0;0;0;0;;;;4;;;https://4memory.de/problem-stories-overview/77-workshop-datenpublikation-suche-syllabus/;;;;;Kompetenzen;;Langzeitverfügbarkeit;;;Methoden;;;;;Standards
78;Alle nutzen dann meine Daten – aber was habe ich davon?;Ich soll zukünftig meine Forschungsdaten unter einer offenen Lizenz publizieren und zur Nachnutzung zur Verfügung stellen. Prinzipiell habe ich da nichts dagegen, aber ich habe diese Daten schon seit zehn Jahren gesammelt, sehr viel Arbeit investiert und auch die Aufbereitung für die Publikation ist noch einmal aufwändig. Ich habe auch nocht nicht selbst alle Aspekte ausgewertet. Was habe ich als Forschende eigentlich davon? Bisher werden die Daten in der Geschichtswissenschaft maximal zitiert (wenn überhaupt) und das bringt mir kaum einen wissenschaftlichen Benefit. In den naturwissenschaftlichen Fächern werden die Produzenten von Daten bei Nachnutzung automatisch auch an den neu entstehenden Publikationen als Co-Autoren beteiligt. In der Geschichtswissenschaft ist davon noch nichts zu spüren, sondern man erfährt mit solchen Ansinnen eher Ablehnung. Ganz im Gegenteil: Wenn ich Paper mit mehreren Autoren einreiche, werden diese bei Qualifizierungsanerkennungen noch aussortiert, weil da mein eigener Beitrag nicht ausreichend erkennbar ist.;0;0;0;0;0;0;0;0;;;;;5;;https://4memory.de/problem-stories-overview/78-alle-nutzen-dann-meine-daten-aber-was-habe-ich-davon/;;;;;Kompetenzen;Kuration;Langzeitverfügbarkeit;Lizenzen;;;;;;;Standards
79;Nachtrag zum Thema Praxisempfehlung für den digitalen genealogischen Nachlass;Aus der Mitgliedschaft erreicht uns die Bitte, noch nachzutragen: Gibt es eine rechtssichere Möglichkeit, Daten so zu archivieren, die derzeit noch Sperrfristen (Archivrecht, Datenschutz, Urheberrecht ...) unterliegen, dass sie nach Ablauf der Beschränkungen zugänglich zu machen?;datapublication;0;0;0;Datenschutz;0;0;0;;;3;;;;https://4memory.de/problem-stories-overview/79-nachtrag-zum-thema-praxisempfehlung-fur-den-digitalen-genealogischen-nachlass/;;;;;;;Langzeitverfügbarkeit;Lizenzen;;;;;;;
80;Zusammenhang und Trennschärfe zwischen Forschungsdaten und Objektdigitalisaten in einer kulturhistorischen Sammlung;Unsere Einrichtung verfügt über eine große und thematisch breit gefächerte Sammlung historischer Objekte, die zugleich Grundlage der Forschungsarbeit unserer Wissenschaftler*innen ist. Die (z.T. dreidimensionale) Digitalisierung von Objekten zu Zwecken der Dokumentation, wissenschaftlichen Verfügbarmachung und nicht zuletzt auch zur Publikumsansprache gehört ebenso zu unserem wachsenden Aufgabenprofil wie diese objektbezogene Forschung. Dies wirft für mich, der ich den Aufbau entsprechender personeller und technischer Infrastrukturen betreue, Fragen danach auf, wo genau hier die Grenze des Begriffs ‚Forschungsdaten‘ zu ziehen ist: Sind z.B. die ‚bloßen‘ Digitalisate schon Forschungsdaten? Falls nicht, wie gehen wir mit dem Umstand um, dass die ‚tatsächlichen‘ Forschungsdaten sehr oft nur im direkten Zusammenhang mit den Digitalisaten interpretierbar sind? Hier sind technische Lösungen unabdingbar, die z.B. die Einbindung von (teils sehr großen) 3D-Modellen in digitale Forschungsumgebungen ermöglichen und die so m.E. nicht von Einzelinstitutionen entwickelt werden können.;datapublication;datareuse;0;0;Sammlungen;Digitalisate;0;0;;;3;;5;;https://4memory.de/problem-stories-overview/80-zusammenhang-und-trennscharfe-zwischen-forschungsdaten-und-objektdigitalisaten-in-einer-kulturhistorischen-sammlung/;;Datentypen;;;Kompetenzen;;Langzeitverfügbarkeit;;;Methoden;;;;;
81;Nachnutzung von zeitgeschichtlichen Interviews;Zu einem zeitgeschichtlichen Thema wurden in den letzten Jahrzehnten viele Interviews im Rahmen von wissenschaftlichen Arbeiten zum Thema geführt. Ich würde gerne diese Interviews mit dem heutigen zeitlichen Abstand darauf untersuchen, welchen Einfluss sie auf die allgemeine Wahrnehmung des Gegenstands ausgeübt haben und wie der jeweilige zeitgeschichtliche Kontext der Interviewsituation sich in dieser und den (nicht) gestellten Fragen niedergeschlagen hat. Leider gibt es keine zentrale Stelle, an der solche Interviews verzeichnet sind, geschweige denn ein zentrales oder auch virtuelles Archiv. Viele Interviews sind in privaten Regalen der Forschenden oder kaum erschlossen an den beteiligten Institutionen gelagert, andere finden sich verteilt über verschiedene Archive. Manche Originalaufnahmen sind nicht mehr existent. In den seltensten Fällen ist die Frage der Nachnutzung rechtlich eindeutig geklärt. Oft hängt die Möglichkeit der Nachnutzung an persönlichen oder institutionellen Beziehungen und dem Vertrauen der Urheber*innen in die Nachnutzenden. Um die Ausgangssituation für solche Fragestellungen zu verbessern, sehe ich verschiedene Ansatzpunkte: 1. Ein Archivübergreifendes digitales Verzeichnis von Interviews, das die Auffindbarkeit verbessert. Vorhaben wie das DFG Projekt „Oral History digital“ mit dem das ZZF kooperiert sollten deshalb unbedingt in den NFDI-Prozess einbezogen werden. 2. Ein vereinheitlichtes Set von Metadaten, um die Recherche über Archivgrenzen hinweg zu vereinfachen. 3. Archivierungsangebote für einzelne Forschende und kleinere Institutionen, die eine angemessene Archivierung inkl. Aufbereitung des Materials für die Archivierung nicht selber leisten können. 4. Vorlagen für rechtliche Erklärungen (Einverständniserklärung,…), die auch die Möglichkeit der Nachnutzung einbeziehen und für alle Seiten transparent und praktikabel regeln. 5. Eine Debatte um den Wert von Interviews über den eigenen Forschungskontext hinaus als originäre Forschungsdaten. 6. Die Entwicklung einer Wissenschaftskultur der verantwortlichen Nachnutzung, die berücksichtigt, dass a) ein Interview nur auf Grundlage einer Vertrauensbeziehung zwischen Interviewenden und Interviewten entstanden ist und dieses Vertrauen nicht einfach übertragbar ist. b) ein Interview auch viel über den/die Forschende verrät und damit verletzbar/angreifbar macht.;datacollection;dataprocessing;datapublication;datareuse;oral history;Interviews;Zeitgeschichte;0;1;;3;4;5;6?;https://4memory.de/problem-stories-overview/81-nachnutzung-von-zeitgeschichtlichen-interviews/;Rechte;Datentypen;;;Kompetenzen;Kuration;Langzeitverfügbarkeit;;;;;;;;Standards
82;Interviews aus Forschungsprojekt als Forschungsdaten archivieren;Als verantwortlicher Datenkurator bin ich in einem zeithistorischen Forschungsprojekts dafür verantwortlich die im Rahmen der Einzelstudien entstehenden Interviews zu archivieren und nach Möglichkeit digital für die Nachnutzung bereitzustellen. Im Bereich der Geschichtswissenschaft ist die Nachnutzung von Interviews eher ungewöhnlich. Einerseits ist vielen schwer vorstellbar, dass Interviews außerhalb des eigenen Forschungskontext bzw. der ursprünglichen Forschungsfrage einen wissenschaftlichen Wert besitzen. Andererseits besteht die Befürchtung, die Nachnutzung den Interviewten und dem zu ihnen entwickelten Vertrauensverhältnis nicht gerecht wird. Schließlich gibt es die durchaus berechtigte Sorge, durch das Offenlegen des gesamten Interviews inkl. der eigenen vielleicht auch naiven oder ungelenken Fragen, angreifbar zu werden. Diese Vorstellungen und Vorbehalte äußern sich auf verschiedenen Ebenen: 1. Massive Befürchtungen, dass die Interviewten gar nicht mehr zum Interview bereit sind, wenn man auch die Möglichkeit der Nachnutzung mit anspricht. 2. Vorbehalte durch eine entsprechende Lizenzierung die gemachten Interviews nach der Veröffentlichung der eigenen Studie zugänglich zu machen. 3. Die mit einer Archivierung verbundenen Anforderungen werden als Mehrarbeit/-belastung wahrgenommen, von der der/die jeweilige Forschende nichts hat. 4. Jenseits von technischen, Orts- und Zeitangaben nur wenige Standardvokabularien für zeithistorische Themen vorhanden. Um diesen und anderen Vorbehalten zu begegnen sehe ich verschiedene Ansatzpunkte: 1. Eine Wissensplattform auf der technische und methodische Hinweise sowie best-practice Erfahrungsberichte für zeitgeschichtliche Interviews und deren Nachnutzung gebündelt sind. 2. Die Weiterentwicklung der Wissenschaftskultur einer verantwortungsvollen Nachnutzung von zeithistorischen Interviews. 3. Idealerweise die für eine Langzeitarchivierung nötige Erfassung und Aufbereitung von Metadaten und Ton-/Bildaufnahmen auf einer Online-Plattform so implementieren, dass dieser Schritt auch für das eigene Forschungsvorhaben und die eigene Transkription/Annotation des Materials hilfreich ist. Die Mehrarbeit also durch einen sofortigen Mehrwert aufgewogen wird. Die zunächst nur im Forschungskontext sichtbaren Materialien könnten dann später leicht öffentlich zugänglich gemacht werden.;datareuse;0;0;0;Forschungsdatenarchivierung;Nachnutzung;0;0;;2;;;5;;https://4memory.de/problem-stories-overview/82-interviews-aus-forschungsprojekt-als-forschungsdaten-archivieren/;;Datentypen;;;Kompetenzen;Kuration;Langzeitverfügbarkeit;Lizenzen;;;;;;Softwarepflege;Standards
83;Forschungsdatenmnagement als Support für Forschungsprojekte;Als IT-Verantwortlicher an einer außeruniversitären Forschungseinrichtung möchte ich ein Forschungsdaten-Management-Verfahren einrichten. Ich erhalte Informationen über beginnende und laufende Projekte bzw. Ansprechpartner*innen aus der Verwaltung und führe Gespräche mit einzelnen Wissenschaftler*innen. Gleichzeitig beginnt das Institut mit der Aufarbeitung am Haus überlieferter Datensammlungen. So nimmt die Menge der anfallenden Projektinformationen aktuell stark zu, so dass ich ein eigenes Verwaltungssystem (interne Datenbank) angelegt habe. Ich erkenne die Notwendigkeit, von diesem System aus Schnittstellen zu unserem Forschungsinformationssystem wie auch zu anderen öffentlichen Online-Katalogen des Instituts herzustellen. Allerdings würde eine solche Erweiterung des Systems derzeit mehr Ressourcen kosten als mir auch mittelfristig für das Forschungsdatenmanagement zur Verfügung stehen. Auch erscheint mir die Entwicklung solcher Insellösungen pro Einrichtung nicht sehr effektiv. Konkret fehlen m.E. Data-Services, die Metadaten bzw. Formate für die Projektdaten-Beschreibung definieren und für eigene Bedürfnisse zu erweitern wären. Dies würde mehr Zeit für die Betreuung der einzelnen Forscher*innen und Projekte eröffnen.;datacollection;0;0;0;Metadaten;Data-Services;0;0;1;;3;;5;6?;https://4memory.de/problem-stories-overview/83-forschungsdatenmnagement-als-support-fur-forschungsprojekte/;"Projektmanagement, FDM-Strategie
";;;;Kompetenzen;;Langzeitverfügbarkeit;;;;;;Ressourcen;;Standards
84;Forschungsdaten als Vertrauenssache;"Als Leiter des Programmbereichs Forschungsinfrastrukturen an einem zeithistorischen Forschungsinstitut bin ich auf verschiedenen Ebenen mit den Bedürfnissen der Forschenden hinsichtlich Archivierung, Erschließung und Bereitstellung, der von ihnen produzierten Forschungsdaten, aber auch gleichzeitig auch mit einer ganzen Reihe von Unsicherheiten und Befürchtungen konfrontiert. Beim Aufbau eines institutsweiten Verfahrens und Regelsystem für den Umgang mit Forschungsdaten haben sich folgende Probleme gezeigt, die für den Aufbau übergreifender Infrastrukturen von Bedeutung sind: 1. Forschungsdaten sind eine ""Vertrauenssache"" und ein Feld von hoher Sensibilität für die Forschenden. Gegenüber forschungsfernen zentralen Infrastrukturen gibt es daher zahlreiche Vorbehalte, die durch intermediäre Strukturen des Datenmanagements aufgefangen werden müssen 2. Forschungsdatenmanagement setzt einen Kulturwandel in der Disziplin voraus. Wer seine Daten erschließt, archiviert und zur Nachnutzung bereitstellt muss daraus fachlichen Reputationsgewinn ziehen können. 3. Als Praxis muss Forschungsdatenmanagement bereits von Anfang an in den Prozess der Projektbearbeitung implementiert werden. Entsprechende Infrastrukturen sollten als Arbeitsumgebung funktionieren und Werkzeuge für die Bearbeitung der Daten bereitstellen. 4. Es müssen fachliche Standards für die Qualität von Forschungsdatensammlungen etabliert werden und ein Instrumentarium für die fachliche Kritik solcher Ergebnisformen etabliert werden (""H-Soz-Kult für Forschungsdaten"") 5. Bislang fehlt es in den meisten Einrichtungen an Personal und Ressourcen für das Forschungsdatenmanagement. Neben dem Aufbau einer nationalen Infrastruktur muss diese Aufgaben in den Bereichen vor Ort als Feld fachlicher Wertschätzung und strategische Aufgabe etabliert werden, wofür entsprechende Ressourcen bereitgestellt werden. 6. Um eine Kultur im Umgang mit Forschungsdaten zu etablieren braucht es neben der zentralen Infrastruktur fachdisziplinbezogenen Wissensplattformen mit Tutorials, Ratgebern, Musterverträgen und Best-Practice Beispielen. Dazu sollten die etablierten Plattformen der Fachinformation und -Kommunikation weiterentwickelt werden 7. Es bedarf einer Aufklärungskampagne über Fragen des Datenschutzes bei Forschungsdaten, die Rechtssicherheit etablieren hilft. Auch dies eine Aufgabe für Data Culture";datacollection;dataprocessing;datapublication;datareuse;Vertrauen;Forschungsnähe;Kulturwandel;0;1;2;;4;5;6?;https://4memory.de/problem-stories-overview/84-forschungsdaten-als-vertrauenssache/;Ressourcen;Datentypen;;;Kompetenzen;Kuration;Langzeitverfügbarkeit;Lizenzen;;Methoden;Modellierung;Qualität;Ressourcen;Softwarepflege;Standards
85;Integration und Veröffentlichung von örtlichen Forschungen zur Familiengeschichte auf regionaler Ebene;Im Rahmen der Familienforschung werden seit mehr als 80 Jahren u.a. von der Upstalsboom – Gesellschaft für historische Personenforschung und Bevölkerungsgeschichte in Ostfriesland e. V. (UG) Ortssippenbücher und Ortsfamilienbücher erstellt. Sie enthalten die Daten der Familienstammbäume der jeweiligen Kirchengemeinden einzelner Orte oder Familien. Diese werden mit Hilfe von Kirchenbüchern, standesamtlichen Unterlagen oder ähnlichen Primärquellen erstellt. Zurzeit sind von der UG 106 Ortssippenbücher, vier Familienbücher sowie dreiundzwanzig Bücher zur Familienkunde erstellt worden. Pro Jahr kommen drei bis fünf neue hinzu. Auch andere genealogische Vereinigungen erstellen Ortssippenbücher und Ortsfamilienbücher. Seit mehreren Jahren werden auch viele Informationssammlungen im Internet von vielen Autoren bereitgestellt. Diese stehen jede für sich und die Validität ist meist nicht zu beurteilen. Daher bleibt die klassische Suche in Archiven nach Primärdokumenten. Um eine Abstimmung von Personendaten zu erreichen, sollten die Forschungsdaten, versehen mit Referenzen auf Primärdokumente, untereinander vernetzt im Internet zu Verfügung werden. Beispiel hierfür wäre „WieWasWie-Everyone has a history“ (https://www.wiewaswie.nl). Hierzu wäre eine koordinierende und administrierende Person als Ansprechpartner sehr wichtig, ergänzt um FAQs im Internet. Den Autoren sollten Werkzeuge zur Unterstützung der Integration bereitgestellt werden. Diese Integration bedarf einer ständigen Überwachung sowie einer Dokumentation, die z. B. tote Punkte der jeweiligen Person, unscharfe Dokumentationen sowie Randunterschärfe der Datenwolke festhält. Weiter wäre es sinnvoll, Unterstützung bereit zu stellen, um vorhandene Primärdokumente, wie z.B. Archivmaterialien, Ortssippenbücher und Ortsfamilienbücher, zu digitalisieren und mit den anderen Daten validiert zu integrieren.;datapublication;datareuse;0;0;Integration Forschungsergebnisse;Veröffentlichung Forschungsergebnissse Familiengeschichte;0;0;1;2;3;;;;https://4memory.de/problem-stories-overview/85-integration-und-veroffentlichung-von-ortlichen-forschungen-zur-familiengeschichte-auf-regionaler-ebene/;;Datentypen;;;Kompetenzen;;Langzeitverfügbarkeit;;;Methoden;;;;Softwarepflege;Standards
86;Probleme ohne Datenmanagementplan;Ich koordiniere ein anderthalbjähriges audiovisuelles Zeitzeugenprojekt, angesiedelt an der Sächsischen Akademie der Wissenschaften, in Kooperation mit der Humboldt Universität zu Berlin. Das Projekt wird durch Bund und Länder gefördert: Thüringen, Sachsen und die Wismut GmbH, die ihre Gelder durch das BMWi erhält. Laut Antrag beinhaltet das Vorhaben, 50 Zeitzeugeninterviews zu führen, diese filmisch zu dokumentieren, anschließend zu transkribieren, zu verschlagworten und sowohl für eine (Langzeit)archivierung bereitzustellen als auch in eine noch aufzubauende Datenbank zu integrieren. Ein Zeitzeugenprojekt mit diesem Umfang benötigt ein Team, um es im Rahmen der vorgegebenen Zeit umzusetzen. Bisher besteht unsere Projektgruppe lediglich aus zwei Mitarbeitern. Diese „dünne Personaldecke“ ist dem Umstand geschuldet, dass wir als Projektgruppe seit sechs Monaten die Zusicherung der Förderung des BMWi zwar haben, aber bis heute kein Geld geflossen ist. Zudem erwartet das BMWi, die Zahl der zu führenden Interviews auf eine unbestimmte Zahl zu erhöhen. Es sind kaum 50 qualitative Interviews in einem Jahr schaffbar, geschweige denn die erweiterte. Der Aufbau der Datenbank, das Frontend, und die Langzeitarchivierung der großen Datenmenge sollten über die Sächsische Akademie (SAW) organisiert werden, um die Nachhaltigkeit des Projektes zu sichern. Erst nach Beginn des Projekts wurde deutlich, dass die SAW keine Kapazitäten dafür hat. Wir einigten uns auf einen Prototyp der Datenbank mit einem entsprechenden Frontend, das in Folgeprojekte münden und ausgearbeitet werden soll. Doch bleibt die Befürchtung, dass wir Daten produzieren, die in Vergessenheit geraten. Bei einem Projekt, in das mehrere erfahrene Institutionen involviert sind, hätte ich mehr Kommunikation und Unterstützung, zum Beispiel im Vorfeld für das Erstellen eines Datenmanagementplanes erwartet, das uns sicher vor einigen Problemen bewahrt hätte. Beispielsweise hätten wir mit einem DMP die juristische Komplexität, sowie die logistische und finanzielle Herausforderung einer Langzeitarchivierung erkennen und klären können. Wir stehen nun vor der Aufgabe, uns zusätzlich in neue Themenfelder einzuarbeiten, obwohl unsere finanziellen und personellen Kapazitäten dafür nicht vorhanden sind.;datacollection;datapublication;0;0;DMP;Zeitzeugeninterview;0;0;1;;;4;5;6?;https://4memory.de/problem-stories-overview/86-probleme-ohne-datenmanagementplan/;Projektmanagement;Datentypen;;;Kompetenzen;;Langzeitverfügbarkeit;;;Methoden;Modellierung;;Ressourcen;;
87;Probleme bei Erfassung und Verarbeitung historischer Datumsangaben;"Das Entstehungsdatum einer Quelle anzugeben, ist nicht einfach, denn es ist nicht immer direkt auf Quellen verzeichnet. So hat man ggf. kein exaktes Tagesdatum, kann dieses nur aus Kontexten erschließen (z.B. aus Ereignis- oder Feiertagsangaben) oder nur anmerken, dass es um, vor oder nach einem anderen Datum entstanden ist. So können manchmal nur Jahreszahlen oder Monate angeben werden, ggf. mit einer zusätzlichen Angabe wie Anfang, Mitte oder Ende des Zeitraums, den man erschlossen hat. Datenbanken auf der anderen Seite erfordern ein exaktes Datum in der Form JJJJ-MM-TT. Nur dann können diese Daten weiterverarbeitet und z.B. für Suchzugriffe oder Sortieralgorithmen genutzt werden. Ein weiteres Problem ist, dass Standardisierungen nicht auf historische Belange angepasst sind. Die Unixzeit, die jedes Datum in Sekunden ab dem 1. Januar 1970 umrechnet, wird von vielen Computerprogrammen zur Datumsberechnungen verwendet. In der Microsoft-Welt werden alle Daten ab dem 1. Januar 1900 unterstützt. Die Norm ISO 8601 gilt nur für Daten ab 15. Oktober 1582. Für Daten davor müssen die Austauschpartner weitere Vereinbarung untereinander treffen (z.B. für v.Chr. ein Minus vor der Jahreszahl). Die Problematik des Jahres Null stellt für Computerverarbeitung ein weiteres Hürde dar. Die Eingabe ungenauer oder erschlossener Daten ist eigentlich nicht vorgesehen. Meistens wird es durch die Eingabe mehrerer Daten (z.B. weiteres Feld für Sortierdatum oder Angabe eines Zeitraums) und weiterer Felder, mit denen man die Art bzw. Qualität der Daten angibt (erschlossen, wahrscheinlich, etc.), umgangen. Dies ist aber individuell in Softwaren oder durch Datenmodelle festgelegt und kann dann nur schwer und nicht ohne weitere Absprache/Anpassungen in der digitalen Welt ausgetauscht werden. Auch besteht die Gefahr, dass das maschinenlesbare Datum, das nur aus Sortier- oder Verarbeitungszweck dem Digitalisat mitgegeben wurde, zum ""eigentlichen"" Datum der Quelle mutiert, da dieses Datum digital gelesen und verarbeitet werden kann.";datacollection;dataprocessing;datapublication;datareuse;historisches Datum;Standardisierung;Datenformate;Datumsverarbeitung;1;;;;;;https://4memory.de/problem-stories-overview/87-probleme-bei-erfassung-und-verarbeitung-historischer-datumsangaben/;;;;;;Kuration;;;;Methoden;;Qualität;;Softwarepflege;Standards
88;Erfassung, digitale und analoge Edition sowie virtuelle Präsentation historischer Musikquellen in nichtlateinischen Schriften;Im Rahmen eines DFG-Langzeitprojektes behandelt eine Gruppe von Forschenden, die an verschiedenen Standorten arbeiten, Werke der orientalischen Musik des 19. Jahrhunderts. Die Musikstücke liegen in analoger Form in verschiedenen Handschriften und Drucken vor, wobei teilweise unterschiedliche Quellen für ein und dasselbe Werk existieren. Die Quellen befinden sich an verschiedenen Standorten im nichteuropäischen Ausland. Das Material weicht sowohl von sprachlichen als auch musikalischen Standards europäischer Musik ab: in den Handschriften und Drucken mischen sich unterschiedliche nichteuropäische Sprachen (osmanisch, armenisch, griechisch, arabisch) und nicht-lateinische Schriften (mit einigen historischen Sonderzeichen), die historische Musiknotation entspricht ebenfalls nicht dem westeuropäischen Notationsstandard. Die Forschenden bauen einen Quellenkatalog auf und beabsichtigen, diesen im Internet zugänglich machen. Dabei stehen sie vor dem Problem, ein geeignetes technisches System zu finden, das die spezifischen sprachlichen und musikwissenschaftlichen Anforderungen der Quellen erfüllt. Zudem fragen sie sich, welche Metadaten dafür notwendig sind und wie man diese standardisiert in mehreren Sprachen und Schriftsystemen erfassen und darstellen kann. Ferner stellt sich die Frage, wie man den Quellenkatalog langfristig sichern und funktionsfähig halten kann. Darüber hinaus wollen die Forschenden die erfassten Handschriften und Drucke als Printout und elektronische Ressource veröffentlichen. Hierbei ergeben sich folgende Fragen: • Wie muss der Quellenkatalog angepasst werden, um eine digitale Edition realisieren zu können? • Genügt eine Erweiterung des Quellenkatalogs oder ist stattdessen ein neues System notwendig? • Welche länderspezifischen bzw. disziplinspezifischen Standards historischer Editionen sollen zur Anwendung kommen? • Welche Editionswerkzeuge und -systeme eignen sich, um die spezifischen sprachlichen und musikwissenschaftlichen Spezifika des Quellmaterials wiederzugeben? • Wie kann eine langfristige Sicherung der digitalen musikhistorischen Editionen sichergestellt werden?;datacollection;dataprocessing;datapublication;datareuse;nicht-lateinische Schriften;außereuropäische Notationssysteme;digitale Musikedition;digitale Textedition;;;;;;;;Doppelt siehe Nr. 62;Datentypen;;;;;Langzeitverfügbarkeit;;Mehrsprachigkeit;;;;;Softwarepflege;Standards
89;Thesaurus für ein Digitalisierungsprojekt;Ein Digitalisierungsprojekt aus dem Bereich deutsch-jüdische Geschichte möchte die von ihm erschlossenen Quellen nicht nur chronologisch (Entstehungsdatum) und räumlich (Entstehungsort) sondern über die darin erwähnten Personen und Geografika hinaus auch thematisch einordnen. Dabei stellt sich die Frage nach einer passenden Systematik. Universalklassifikationen wie etwa die Dewey Decimal Classification erweisen sich als zu grob, um wichtige Themen im Quellenbestand wie z.B. die Hachschara (Vorbereitung auf die Auswanderung nach Palästina) zu erfassen. Solch passgenauen Sachbegriffe bietet umgekehrt die GND, allerdings nicht in Form eines hierarchischen Thesaurus. Für ein Online-Angebot bietet sich aber eine Baumstruktur an, da diese im Gegensatz zu einer flachen Verschlagwortung auch das hierarchische Browsing der Inhalte bzw. die schrittweise Facettierung von Suchergebnissen unterstützt. Für die erfolgreiche Projektdurchführung mit einer geeigneten Nutzerführung, zur Vermeidung von Doppelspurigkeiten und im Rahmen einer späterere Integration unserer Projektergebnisse in größere Quellenportale wie etwa die DDB oder die Europeana bräuchten wir Unterstützung bei den folgenden Fragen: • Gibt es evtl. Vorarbeiten von anderen Institutionen, an die wir anknüpfen können? Wie können wir umgekehrt unsere Klassifikationen zur Weiternutzung anbieten? • Wie strukturen wir unsere Metadaten, damit die von uns vergebenen Klassifikatoren ohne aufwändiges Mapping in bestehende oder neue Verbundangebote integriert werden können? • Wie gehen wir mit fehlenden Begriffen um? Wie kann sichergestellt werden, dass diese in bestehende Normdatenbestände wie die GND einfließen können? • Könnte ein Projekt aus dem Museumsbereich wie digiCULT x-tree (https://www.digicult-verbund.de/de/digicultxtree) mit dem bestehenden Vokabular in einer Datenbank zusammengeführt werden, ein Vorbild sein oder gar eine Ausgangsbasis bilden?;datareuse;datapublication;0;0;Jüdische Geschichte;Klassifikation;Normdaten;0;;2;;;;;https://4memory.de/problem-stories-overview/89-thesaurus-fur-ein-digitalisierungsprojekt/;;Datentypen;;;Kompetenzen;;;;;Methoden;;;;;Standards
90;Grenzen des Machbaren;"WissenschaftlerInnen kennen das Problem, nicht aufhören zu können, aus vielen Bereichen: Wann ist ein Buch abgeschlossen? Wann ist genügend Literatur recherchiert? Wann ist der letzte Wörterbuchbeleg gefunden? Beim Aufbau digitaler Ressourcen stellt sich dieses Problem nicht anders, aber besonders. Ich arbeite in einem Projekt, das kodikologische Basisdaten sammelt. Doch was sind Basisdaten? Gehören Wasserzeichen, Provenienz, Illustrationsbeschreibungen dazu? Die potentielle Menge des Verzettelbaren ist scheinbar unbegrenzt. Dass damit weder dem Projekt noch den Benutzern ein Gefallen getan ist, weiß man zwar, doch die reine Möglichkeit verleiht den Handlungsdruck, immer weitere Daten aufzunehmen. TEI-BenutzerInnen werden das Problem ebenso kennen: Wie tief findet die Auszeichnung statt? Die Möglichkeit gewinnt den Charakter eines Wettlaufs von Hase und Igel. Man kommt nie hinterher, egal wie sehr man sich bemüht. Handelt es sich nur um ein psychisches Problem (der ""geile Drang auf große Ganze"", wie Benjamin sagte) oder um ein systembedingtes, dem auch mit klareren Prozessen beizukommen wäre?";datacollection;0;0;0;Datentiefe;Prokrastination;Ziel;0;1;;;;5;;https://4memory.de/problem-stories-overview/90-grenzen-des-machbaren/;;;;;;;;;;;;;;;Standards
91;Im Forschungsverbund – Der steinige Weg zum Geodaten-Repositorium;Als An-Institut einer Universität sind wir Akteur in einem langhin etablierten Verbund unabhängiger Projekte der Grundlagenforschung, die zum Nutzen der interdisziplinären Städteforschung historisches Kartenmaterial edieren. Nach wie vor sind Printprodukte der traditionelle Output. Inzwischen aber haben sich Geoinformationssysteme (GIS) in den benachbarten Arbeitsbereichen Geografie und Archäologie so weit durchgesetzt, dass die Umstellung der Projektarbeiten von konventioneller Zeichensoftware hin zu GIS der nächste logische Schritt war, zumal dies auch eine Ausgangsbasis dafür bot, online die Verbreitung der Arbeitsergebnisse aus den Projekten zu verbessern. Bei der Koordinierung dieses Übergangsprozesses innerhalb des Forschungsverbundes, die bei uns im Haus erfolgt, treten für die internationale Scientific Community vielfältige Herausforderungen zutage. Während verschiedene Projekte in experimentellen Schritten die Datenproduktion erfolgreich auf Geodaten umgestellt und in Workshops ihre Ergebnisse verglichen haben, ist deutlich geworden, dass die anfänglichen ‚handwerklichen‘ Startschwierigkeiten (Knowhow, User Skills) tieferliegende, wissenschaftliche Probleme überdeckten. Unser Ziel der Schaffung eines domänenspezifischen (aber disziplinenübergreifenden) Forschungsdaten-Repositoriums für die Dissemination der Projektgeodaten, verstärkt dies noch. Einerseits ist der Schritt hin zu einem ‚Forschungsdatenbewusstsein‘ in der Scientific Community und zu einer Kultur, die neben der Datenproduktion auch die Bereitstellung der Basisdaten für die interdisziplinäre, länderübergreifende und vergleichende Forschung mitplant, größer als gedacht. Andererseits macht sich der Mangel an Standards für die Produktion und Verwendung von Geodaten in den Geschichtswissenschaften bemerkbar. Auch in diesem ‚Digital Turn‘, der primär die Historischen Grundwissenschaften Kartografie und Geografie tangiert, mündet die Quellenproblematik (Uneinheitlichkeit der Quellenüberlieferung, Uneindeutigkeit der Quellenbefunde) direkt in eine Datenproblematik. Etablierte Metadatenstandards müssen zudem für Geodaten mit historischem Bezug angepasst werden. Die Schaffung einer gemeinsamen Ontologie in einem angeschlossenen Forschungsprojekt steht vor eigenen inhaltlichen Herausforderungen. Letztlich wird ihre Verwendung im Repositorium dabei helfen, die Vergleichbarkeit der Daten über Disziplinen- und Ländergrenzen hinweg herzustellen, jedoch ist ihre Berücksichtigung im Workflow der Datenproduktion innerhalb der einzelnen Projekte eine weitere Hürde.;datareuse;0;0;0;Geodaten;Repositorium;Digitaledition;0;1;2;;4;5;;https://4memory.de/problem-stories-overview/91-im-forschungsverbund-der-steinige-weg-zum-geodaten-repositorium/;;Datentypen;Interdisziplinarität;Internationalität;Kompetenzen;;Langzeitverfügbarkeit;;;;;;;;Standards
92;Metadaten aus Forschungsprojekten: Singuläres vs. Standardisierung. Zum Problem der kategorialen Erschließung von Daten;"Auch im Bereich der philosophiehistorischen Grundlagenforschung wird zunehmend die Digitalisierung von Daten (Editionen, Zeitschriften, Kompendien, Archive) vorangetrieben. Dabei stellt sich die Frage, wie die entstehenden Datenmengen auszuwerten sind. Neben der Überlegung zu den technischen Möglichkeiten tritt auch ein hermeneutisches Problem: Wie ist ein sinnvoller kategorialer Zugriff auf die Daten möglich? Die klassischen Werkzeuge sind: Kategorien, Termini, Begriffe usw., aber auch Textsorten (Monographie, Zeitschriftenbeitrag, Nachlassmaterial usw.). Neue Werkzeuge des distant readings treten hinzu, bspw. die Makroanalyse, die computerbasierte Formanalyse von Textualität usw. In diesem Zusammenhang fehlt es bisher an einem Forum für eine vorgeschaltete Methodenreflexion. Es scheint kein guter Rat zu sein, ein Maximum an Werkzeugen in der Analyse der Datenmengen anzuwenden, oder sich ohne weiteres gegen die alten und für die neuen Werkzeuge zu entscheiden. Ein Vorteil der qualitativen Datenanalyse war und ist, dass singuläre Einheiten (Episoden) der Philosophiegeschichte bewahrt werden konnten; ein Nachteil der quantitativen Analyse könnte sein, dass im Verfahren der Standardisierung die Möglichkeit qualitativer Differenzierung von Episodischen und Generalisierendem verloren geht. Darüberhinaus besteht auch die Gefahr, dass durch die Erfassung der Daten im Prozess der Digitalisierung die alten Wissensspeicher - wie bspw. Lexika der Wörter, Begriffe, Metaphern, Kompendien systematischer und historischer Fragen an die Philosophiegeschichte - für obsolet erklärt werden und die Suggestion der für sich selbst sprechenden Daten (der alte ""Mythos der Gegebenheit"") sich festsetzt. Um hier Klarheit zu schaffen, sollte es als eine dringliche Aufgabe markiert werden, einen Weg zu finden, die alten und die neuen Werkzeuge zu kombinieren und andere Methoden, eventuell verscuhsweise Hybrid-Methoden zu entwickeln. So ist davon auszugehen, dass bspw. ein Historisches Wörterbuch der Philosophie (Erstauflage in den 1970er Jahren) für eine Neubearbeitung seinen Werkzeugkasten neu bestücken wird. Was das heißt und wie unsere Forschung als historisch arbeitende Geisteswissenschaftler*innen nicht nur in der Philosophie, sondern auch in den benachbarten Wissensdisziplinen aussehen wird, vor welchen Herausforderungen/ Möglichkeiten wir stehen und wie ein angemessener hermeneutischer Zugriff auf die digitalisierten Datenmengen (for Memory!) aussehen kann, darüber sollte eine Debatte stattfinden.";dataprocessing;datacollection;0;0;Metadaten;Standardisierung;Methodenreflexion;0;;;;4;5;;https://4memory.de/problem-stories-overview/92-metadaten-aus-forschungsprojekten-singulares-vs-standardisierung-zum-problem-der-kategorialen-erschliesung-von-daten/;;Datentypen;;;;;;;;Methoden;;Qualität;;Softwarepflege;Standards
93;Wikidata-Abgleich;Ein außeruniversitäres, landesfinanziertes Forschungsinstitut, dessen geschichtswissenschaftlichen Bereich ich leite, betreibt ein regionales Online-Datenportal mit mehreren thematischen Angeboten. Dazu gehört auch eine ortsgeschichtliche Datenbank, die ca. 6000 Siedlungen der Referenzregion mit thematisch geordneten Kerndaten ihrer Geschichte vom Mittelalter bis zu Gegenwart umfasst. Der in diesem digitalen historischen Ortsverzeichnis benutzte Code wurde mittlerweile als Eigenschaft in Wikidata angelegt und wird bei vielen Orten auch bereits benutzt. Wir unterstützen diese Verlinkung mit Wikidata und arbeiten aktiv daran mit, weil wir der Ansicht sind, dass Wikidata bei der digitalen Datenverwaltung weltweit eine Schlüsselposition gewonnen hat und, was von zunehmender Bedeutung ist, den automatischen Datenaustausch zwischen Datenbanken enorm erleichtert. Um gleichwohl auch einen von Wikidata unabhängigen Qualitätsmaßstab der eigenständig erhobenen Forschungsdaten zu wahren, halten wir es für sehr wichtig, ein Abgleichs-Tool zwischen den eigenen Daten und den Wikidata-Daten zur Verfügung zu haben und zu nutzen. Über unser eigenes Projekt hinaus entspricht ein solches Tool aus unserer Sicht den allgemeinen Zielen einer nationalen Dateninfrastruktur. Unsere Suche nach geeigneten Tools war bisher ergebnislos (Blocker). Wir haben die Hoffnung, dass die NFDI-Initiative mit ihrer Koordinations-Aufgabe bei der Etablierung von Standards in diesem Bereich eine zentrale Rolle spielen könnte.;dataprocessing;0;0;0;Verlinkung von Daten;Ortsdaten;Abgleichstool;0;;2;3;;;;https://4memory.de/problem-stories-overview/93-wikidata-abgleich/;;Datentypen;;;Kompetenzen;Kuration;Langzeitverfügbarkeit;;;;;Qualität;;Softwarepflege;Standards
94;Tiefenerschließung von digitalisierten Urkundenbüchern;In einem Regional-Portal, das von einem Institut betrieben ist, dessen historischen Bereich ich leite, ist unter anderem ein landesgeschichtliches Urkundenbuch eingestellt. Es besteht aus derzeit 27 gedruckten Bänden, deren Volltext-Urkunden in digitalisierter Form bandweise und innerhalb dessen nach Urkundennummern abrufbar sind. Die gedruckten Register sind beigegeben, doch gibt es keine elektronische Verknüpfung der Registereinträge mit dem Textteil. Suchmöglichkeiten in den Daten bestehen derzeit nicht. Um die Nutzbarkeit des Urkundenbuchs in zeitgemäßer Weise zu erhöhen, bieten sich zwei Wege an: 1) Der Aufbau einer bandübergreifenden Volltextsuche – idealerweise mit Booleschen Operatoren, schreibweisentolerant und mit Umgebungs- und Phrasensuchmöglichkeit etwa nach den Vorbildern der »Library of Latin Texts« oder der »Migne«-Datenbanken. Doch wären in diesem Fall sehr hohe Investitionen in die notwendige IT erforderlich. Zudem zielt das landesgeschichtliche Interesse auch weniger auf die Durchsuchung des Wortschatzes als auf die enthaltenen historischen Orte und Personen. An dieser Stelle bieten sich – Weg 2) – die gedruckten Register an, in denen ein beachtlicher Teil der historisch-kritischen Arbeit der Herausgeber überliefert ist, die nun auch für die Online-Fassung des Urkundenbuches genutzt werden könnte. Dazu müssten allerdings – so stellt sich das Problem derzeit für uns dar – die Orts- und Personennamensregister jedes der 27 Bände händisch in eine datenbanktaugliche Form (Excel-Dateien) überführt werden. Anschließend würden die erfassten Registereinträge mit den bereits vorhandenen, online gestellten Bilddateien der Urkunden verlinkt. Schließlich könnten die digitalisierten und verlinkten Registereinträge der einzelnen Bände zu einer Gesamt-Datenbank verbunden werden. NutzerInnen könnten dann bandübergreifend von lediglich einem einzigen Suchportal aus nach Orts- und Personennamen recherchieren und die Suchergebnisse gesammelt abrufen. Bei Weg 2) fielen allerdings ähnlich wie bei Weg 1) hohe Kosten an –vor allem aufgrund der benötigten Arbeitszeit, was die Erreichung des Ziels auch hier in Frage stellt (Blocker: Ressourcenaufwand). Mögliche technische Lösungen: Gibt es beispielweise OCR-Technik für die Aufschlüsselung von komplex strukturierten Registern und für die Verknüpfung der dort genannten Nummern mit den zugehörigen Textdokumenten?;datapublication;dataprocessing;0;0;Texterkennung;Volltextsuche;Durchsuchbarkeit nach Namen;0;;;3;4;;6?;https://4memory.de/problem-stories-overview/94-tiefenerschliesung-von-digitalisierten-urkundenbuchern/;Ressourcen;Datentypen;;;;Kuration;;;;Methoden;;;Ressourcen;;
95;Suchen von digitalisierten Zeitungen und Zeitschriften;Ich beschäftige mich mit Schriftstellerinnen um 1820 und recherchiere nach Artikeln dieser Frauen in Zeitungen und Zeitschriften. Bibliotheken bieten ihre digitalisierten Bestände auf eigenen Plattformen an. Als Bibliothekarin verstehe ich die Angebote, als Forschende habe ich jedoch eine andere Sicht. Bibliothekssicht: Wir bieten eine einfache Suche und eine erweiterte Suche auf unserer Plattform. Forschende: Ich suche eher bei https://de.wikisource.org, welches Heft, welche Ausgabe digitalisiert vorliegt. Dann erst betrete ich das digitale Angebot einer Bibliothek. Der Ansatz von Bibliotheken nun häuserübergreifende digitale Plattformen für Zeitungen und Zeitschriften aufzubauen, scheint seltsam, da es dieses Angebot mit wikisource eigentlich bereits gibt. Hilfreich wäre es, sie würden ihre Daten dort einpflegen.;datacollection;dataprocessing;datapublication;datareuse;Bibliotheken;Plattformen;Wikisource;0;;2;3;;;;https://4memory.de/problem-stories-overview/95-suchen-von-digitalisierten-zeitungen-und-zeitschriften/;;;;;;;;;;Methoden;;;;Softwarepflege;
;;;;;;;;;;;;;;;;24;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
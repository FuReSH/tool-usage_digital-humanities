

Introduction 


It wasn't until I taught an Introduction to Digital Media course that, ironically, I began questioning my policy on laptops in the classroom. Since my first experience as a teaching assistant in graduate school, I've allowed and even embraced them. During the inevitable conversation on laptops among colleagues, I was always the person arguing that students use these machines to write, read, and think for the vast majority of their academic activities. To exclude laptops from the classroom, a space in which students learn how to write, read, and think, would be disingenuous. Given my training in media theory and digital humanities, terms like "distraction "and "attention "in this context evoked a faintly naive technological determinism, as if the cognitive abilities of our students could be single-handedly warped by machines. Even the most influential quantitative studies — such as The Laptop and the Lecture or The Pen is Mightier than the Keyboard — left me unconvinced, largely because they assumed an analytic framework absent historical background, medium specificity, and cultural context, in which the presence of "the laptop "in a single Ivy League lecture course is made to speak for all possible learning situations. Historians and theorists of media technologies have provided depth and nuance to figurations like these for decades. 

While I maintain my skepticism of broad generalizations about the laptop as a unitary technology and "the student "as a fixed cognitive quantity, the experience of teaching a course that took digital media as both its object and method of inquiry forced me to rethink my assumptions about the presence of laptops and other screens in class. Much of our energy was devoted to figuring out how we might embrace the laptops glowing before us at the same time as we explored the history, culture, and politics of the information coursing through them. And yet we still experienced the inevitable draining of our attention, the sense that the laptop was becoming something more than simply a handy object lesson for our topic of discussion. Of course, attention, energies, and enthusiasms wax and wane with any semester. As we approach summer, laptops seem to follow an ecliptic plane as they gradually move from the polite position off to one side (as recommended in the syllabus section on screen etiquette) to the rather less polite one directly in front of us. And with them come the glazed-over eyes, the suspiciously busy keystrokes, the stifled grins apropos of nothing that anyone else can see. But where I would normally write off this change as simply part of the academic year's circadian rhythms, something about this course made me think a little differently about it. 

Digital media, our object of study, had gone from being a means of reflexive pedagogy to a noticeable drain on the flow of the course. In previous years, I had wonderful results using laptops for exercises in textual analysis and collaborative annotation, as well as the occasional fact check or live event look-in. The events of this particular semester, however, led me to wonder: at what point does our attention to digital media shift from an attitude of analysis to one of distraction? After all, distraction is a specific form of attention to something. As Paul North writes, "Distraction is diversion, and diversion is a version of attention ". But distraction is a version of attention that is no longer directed by volition, discipline, or desire. When we are distracted by something, we feel the direction of our conscious minds pulled by something outside of ourselves. In taking digital media as an object and means of study, what then marks the transition from attention guided by disciplinary frameworks and measured contemplation to attention dispersed and unsynchronized, diluted by the sheer depth and variety of interesting things to give our attentions to? 

The natural fear on my part as an educator was that this gradual shift was the product of boredom. I thought back to my previous classes and initial instincts about allowing laptops in the classroom. Of course, I can justify the decision based on my theoretical commitments as a scholar of digital media. But what if I was simply afraid of ever risking the presence of classroom boredom in the first place? What if allowing laptops and their periodic distractions was just a means of taking a measure of pressure off myself, someone who not only has an obligation to keep students fully engaged and present, but also feels often like a performer in front of all those eyes? 

In this essay, I examine boredom from two angles: as a mood currently undergoing uniquely historical transformations, and as a potentially useful pedagogical technique. When someone becomes bored, their natural response is to find an object, idea, or activity to latch on to, a distraction to pass the time. We distract ourselves from the discomfort of boredom. Now that we can carry around an incredibly powerful little computer in our pockets or bring a lightweight laptop to class, boredom is a feeling that we almost never have to face anymore. We instantly alleviate the slightest hint of impatience or aimlessness with a single glance at our screens. Teaching an Introduction to Digital Media left me wondering what would happen if, rather than tolerating or even embracing the distraction that laptops can bring to the classroom, I simply let myself let my students feel bored. Boredom today is like a disease on the verge of eradication that we would be woefully unprepared to deal with were it ever to return. But what introspective capacities do we neglect when we reflexively give ourselves over to the distractions of the outside world? What might dwelling with our boredom open up to students? 

I begin with the example of my digital media course, which attracted majors from across the disciplines, including a majority contingent of computer science students. In order to bridge the many different forms of expertise and associations surrounding digital media that were brought to the table, we drew on a conversation format used at the historic Macy conferences on cybernetics. In their final project, students were encouraged to examine their daily habits as users of digital devices. Drawing on these experiences, I describe how a humanistic approach to digital media provides STEM students in particular with a means of contextualizing technical detail within larger sociopolitical systems, and how a focus on individual habits of attention can provide an important hinge between the granular and the global. Next, I reflect on the pressures produced by the very devices we studied on the classroom environment and frame our experiences within some of the most influential writings on boredom as a historically and technologically conditioned mood. I then conclude with some speculations on planning for boredom within a laptop policy that is capable of accounting for a range of learning styles. 


# Disciplinary Attention 


Over the past decade, the increasing presence of digital media has made strange the very fabric of our conversations, movements, aesthetic experiences, and political consciousness. These changes were prepared for by information theorists in the 1940s, cyberneticians in the 1950s, and the architects of networked computation in the 1960s. But only now have we begun to live out the futures that were dreamed of by these technologists. Today with our digital devices, we experience their dreams as beliefs, daily routines, and compulsions. 

Intro to Digital Media was a class that began by examining the historical roots of information as both a technology and a concept. We then proceeded down a stack of topics in digital culture: code, interface, device, infrastructure, and power. Each of these topics was explored through a comparative framework, using hands-on exercises and readings from across the disciplines, including the philosophy of computation, history of technology, cultural studies, literary criticism, science fiction, and media theory. Students were encouraged to think historically (how have media been experienced as new at different moments in time?), theoretically (how exactly do we address "medium "as an object of study), and tactically (how can we use our local experience of digital devices as a framework for thinking global networks?). Throughout the semester, in-class exercises linked the theory we encountered in our readings to everyday practice, including a [data detox ](https://myshadow.org/detox)designed by the Tactical Technology Collective, FemTechNet's collection of resources for [Locking Down Your Digital Identity ](http://femtechnet.org/csov/lock-down-your-digital-identity/), and encryption for messaging and data transfer using Pretty Good Privacy (PGP) with [Keybase ](https://keybase.io/). 

The exact direction our conversations took was determined by the makeup of the class: roughly half of the students who registered were computer science majors, with the remainder coming from various humanities programs. This made for an interesting experiment in cross-disciplinary communication at the undergraduate level that, for me, opened up questions about the specific kind of expertise that a humanities education offers. What practices should we model in the context of classes on digital media, especially when many students already enter with a high degree of technical literacy? What values can a humanities education impart for the kinds of careers that STEM students will be entering into? My students had acquired very different forms of expertise over their respective programs of university study. And so making our ideas clear didn't just entail clarifying the individual frameworks we used when thinking about technology, but also our various styles of attention toward technology as an object of study. Our disciplines are, after all, specific forms of attention, as Paul North argues. A discipline is "a Wissenschaft, a methodical, repeated relation to sanctioned objects, an institutionalized attention ". 

One of our inspirations in speaking from individualized sets of experience and expertise was the conversation format for the famous 1950s Macy Conferences on cybernetics. These conferences featured presentations from engineers, biologists, social scientists and humanists all interested in new theories of communication, the boundaries between human and machine, and the question as to whether the operation of new computers could help us understand the inner workings of the brain. The proceedings read like a who's who of mid-century intellectual history, with Norbert Wiener, Claude Shannon, Gregory Bateson, Margaret Mead, and John Von Neumann all sharing often highly technical research from the cutting edge of their respective disciplines. During each of the two-day conferences, held once or twice a year from 1946-1953, participants were given the opportunity to deliver a formal paper. But if at any time during that presentation there were another participant who didn't understand a particular term or concept, that person would interrupt the speaker and ask for clarification. Either an explanation would be given and the presentation would continue, or a larger conversation would emerge from that point of clarification until it eventually arced back into the main presentation. 

This format was incredibly useful to us. Then, as now, the concept of the digital required a great deal of explication, especially among people of such different backgrounds. For example, during the seventh Macy Conference in March 1950, the neuroscientist Ralph Gerard presented on Some Problems Concerning Digital Notions of the Central Nervous System. When posing the question of whether the electrical activity between the brain and the nervous system should be understood as analog or digital signals, Gregory Bateson interrupts Gerard and says, "I am a little disoriented by the opposition between analogical and digital, "wondering if all involved could "tidy up our vocabulary. "John Von Neumann, the mathematician and pioneering figure in the history of computing, jumps in to admit, "It is very difficult to give precise definitions . . . although it has been tried repeatedly. Present use of the words "analogical "and "digital "in science is not completely uniform. "J.C.R. Licklider, a psychologist known for his work on the perception of sound, complicates the situation further when he asks what intuitive sense a non-specialist would make of these terms: "To a lay man analogical and digital are not opposites and any very clear sense. "The conversation spins out, until finally Licklider returns to the original subject of Gerard’s presentation, adding, "I am afraid we have disturbed the course of things about this too much. . . . We will use the words as best we can. "

Not only were these researchers hammering out a scientific consensus on emerging models for the body and on new computing machines, but they also were debating the specific words that should be used to communicate these concepts across academic disciplines and to the public. It's as if they understood that public discourse about these new technologies could determine their eventual future. Then, as now, the distinctions we make between analog and digital, information and data, are not hard and fixed. These aren't entities with necessary and sufficient technical conditions. They are instead a matter of perception, of ontologies, of culture. The refractory manner in which each of my students used these terms in conversation reflects that diversity. But it also required negotiating the various forms of disciplinary attention that each student brought to digital media, whether they were inclined to understand them primarily as aesthetic experiences or political realities, as legal entities or financial propositions. Our terms often slipped out of alignment and that was okay. The challenge was to make sure that all of the different forms of attention these students had been trained in were synchronized rather than working at cross purposes. 

For their final project, students were asked to direct these different forms of disciplinary attention to a single digital device that was particularly resonant in their daily lives. If we find ourselves ceaselessly distracted by the devices we use to read and communicate every day, this project was an experiment in rerouting those distractions through a deep material literacy regarding where our devices come from and how they are made. Students selected a specific digital device and traced the lifecycle of its manufacture, use, re-use, and disposal. Doing so is a very big task. A single smartphone, for instance, contains over two hundred chemical compounds, and the scale of its production is truly global: from rare-earth metal mines in Baotou to data centers in Iowa, from grey markets in Jakarta to electronics scrap yards in Delhi. But even though smartphones allow their users to inhabit countless social worlds simultaneously, the material world of the smartphone itself remains invisible to its users. 

So, students were presented with many different methods for going about their research, and there were many different pieces of the puzzle they could choose to focus on. It was understood that no two final projects would look alike. The project consisted of two components. First, students produced some form of conceptual model of their artifact, using a map, icons, matrices, or 3D modeling. Some decided to create supply chain maps of their artifact using [Sourcemap ](http://www.sourcemap.com/), which allows anyone to create a map annotated with text, images, and videos of the locations of a device's material inputs, manufacturing, and shipping. Other students expressed the composition of their artifact using symbol systems like [Isotype ](http://www.gerdarntz.org/isotype)(International System Of Typographic Picture Education), created by Otto Neurath and Gerd Arntz in the 1920s and 30s. Isotype — as well as similar symbol systems like the Pictorial Communication Language ( [PICOL ](http://picol.org/picol_icon_font)), [The Noun Project ](https://thenounproject.com/), and [font awesome icons ](http://fontawesome.io/icons/)— provided a means of schematizing the various components of each device. Students then wrote reflective papers that situated their artifacts within the historical and conceptual frameworks we explored in class. 

Some traced a single rare-earth element in order to understand the entirety of their device, like the cobalt used in keyboards or the tantalum used in iPhones. Others took an infrastructural approach, tracing the environmental impact of streaming a single film on Netflix, or of running Wikipedia's data centers. A few conducted comprehensive tear downs of popular gadgets like the Amazon Echo or Fitbit activity trackers. Exploring the material specificities of their devices gave students a means of better understanding what Bruce Sterling calls the "cognitive load "of each device: their capacity for attention and distraction . Much like scholars of book history who challenge their students to assemble a codex from scratch to better appreciate the technology of the book, my aim was to have students use this much more granular understanding of their devices’ construction in everyday practice. 


# Boring Ourselves 


What I didn't anticipate in planning this course was the way that its subject matter would inflect the format and flow of our work. Digital media ended up being more than just our object of study. Its presence in the classroom put pressure on our attempts to synchronize the different disciplinary frameworks and kinds of attention that students had been familiarized with by their majors. And so I began turning to theorists of older, early-twentieth-century media — cinema and radio — for some of the most influential writing on the relationship between attention, distraction, and boredom. If boredom was the impulse driving us to check our screens, then maybe these writings could help us imagine the ways that boredom might be redirected toward different pedagogical ends. 

An interval of pause in the mechanical rhythms that structure labor and leisure, boredom has a history mirroring that of modernity . In the 1920s, Siegfried Kracauer identified boredom and distraction as moods central to understanding an emerging white-collar or salaried class in Weimar Germany. As the Berlin correspondent for the Frankfurter Zeitung feuilleton — Walter Benjamin celebrated Kracauer's appointment to the post by writing, "It is good for the city to have its enemy within its walls "— Kracauer described offices and spaces of entertainment as complex expressions of this white collar culture. Urban audiences in Weimar Germany flocked to massive cinema palaces designed by modern architects. Unlike earlier forms of programming, in which multiple short films were shown together as part of a single admission, cinema palaces featured one film as the culmination of a revue containing dancers, special effects, and musicians entertaining the audience before the film began. Kracauer described the experience of attending these cinemas as "the total artwork of effects ": "Spotlights shower their beams into the auditorium, sprinkling across festive drapes or rippling through colorful, organic looking glass fixtures. The orchestra asserts itself as an independent power, its acoustic production buttressed by the responsory of the lighting. Every emotion is accorded its own acoustic expression and its color value in the spectrum — a visual and acoustic kaleidoscope that provides the setting for the physical activity on stage: pantomime and ballet. Until finally the white surface descends and the events of the three-dimensional stage blend imperceptibly into two-dimensional illusions. "

Where others saw these films as trivial diversions, Kracauer sensed something genuinely new in the diversity of their audience. Unlike the more class-segregated populations of rural towns, four million Berliners meant by sheer necessity that all kinds of people circulated through the same cinemas, "a process that creates the homogenous cosmopolitan audience in which everyone has the same responses, from the bank director to the sales clerk, from the diva to the stenographer ". And while other cultural critics chided Berliners for their addiction to these entertainments, Kracauer argued that the rhythm of cinema's distractions corresponded to the intensity of modern industrial labor. One thinks of the famous scene in Chaplin's Modern Times (1936) in which the Tramp is ingested by the assembly line he finds impossible to keep pace with. The repetitive drudgery of that labor is doubled by the audience's response to its representation in the cinema, where "The stimulations of the senses succeed one another with such rapidity that there is no room left between them for even the slightest contemplation ". The forms of labor to which the audience was submitted outside the cinema found a kind of catharsis in the collective emotional shocks produced by film, like convulsive laughter or screams of surprise. Which meant for Kracauer that distraction had become newly elevated "to the level of culture ". 

Cinematic distraction signified for Kracauer a unique political potential because it was experienced across class divisions. Distraction allowed individual spectators within the mass audience to perceive themselves as a collective whole. In the cinema, "the audience encounters itself; its own reality is revealed in the fragmented sequence of splendid sense impressions. Were this reality to remain hidden from the viewers, they could neither attack nor change it; its disclosure in distraction is therefore of moral significance ". In its ability to enable new forms of cohesion, solidarity, and self-awareness, distraction thus served for Kracauer as cinema's "aesthetic vocation. "

We might wonder whether there can be an "aesthetic vocation "for digital media in the same way as Kracauer described it for the cinema. When we allow ourselves to be distracted by a laptop, do we experience the shared sensation of a mass or a public as John Dewey and later Jürgen Habermas described it ? Is there an intentionality behind that desire to become conscious of some community or collective whole outside of ourselves, and can we characterize that drive toward distraction as a desire? In a remarkable book on social media and distraction, Dominic Pettman suggests to the contrary that distraction has become less a means of experiencing the hidden truth of our collective existence and more of a dispersal of any shared focus as we all see completely different things at different moments in our social media feeds. Distraction today "is composed of millions of tiny moments of engineered attention (or vice versa) "that have the effect of scattering the public focus "so that we never feel the same way as other potential allies and affinities at the same moment ". 

Boredom, as Kracauer described it in another essay of 1924, has since undergone similar transformations . While distraction was a collective experience of the masses coming to understand their coexistence, Kracauer saw boredom as the solitary mood of an individual having an experience of the self. Distraction found its true "aesthetic vocation "in the cinema, an art form that synchronized the sensoriums of crowded rooms of people from across class divisions. But Kracauer understood boredom as an individual capacity that was taken away by the live broadcast medium of radio. "Since many people feel compelled to broadcast, one finds oneself in a state of permanent receptivity, constantly pregnant with London, the Eiffel Tower, and Berlin. Who would want to resist the invitation of those dainty headphones? . . . Silent and lifeless, people sit side by side as if their souls were wandering far away ". In giving us over to the flow of other minds on the airwaves, radio sets "allow oneself to be chased away. "But what do we lose in that escape? The experience of boredom makes us confront ourselves, whether it be in a state of isolation, expectation, or repetition. For Kracauer, boredom "provides a kind of guarantee that one is, so to speak, still in control of one's own existence ". Distraction is a state we experience together. Boredom is a feeling we face alone. 


# Mindfulness the Hard Way 


The loneliness of boredom means, of course, that boredom can manifest in many different ways, as Adam Phillips writes: "Clearly, we should speak not of boredom, but of boredoms, because the notion itself includes a multiplicity of moods and feelings that resist analysis ". Martin Doehlemann (cited in ) distinguishes between at least four different types of boredom, including situative boredom (when we wait for something or someone in particular: a flight to arrive, a lecture to end), the boredom of satiety (when we have had so much of something that it becomes impossible to appreciate any more of the same), existential boredom (when we desire or await not something in particular but the very feeling of desire or expectation itself), and creative boredom (when we are forced to go through the motions of a tedious, repetitive task with no hope for spontaneity or variation). And yet for all the forms that boredom can take, Kracauer's description of an emerging medium like radio having a decisive effect on the way we experience boredom feels especially meaningful today. While the collectivizing effects of cinematic distraction have evolved into a much more atomized experience of scattered attention with digital media, the essential crowding out of boredom by broadcast radio finds an analogue in the way we look to our screens today. But what kinds of boredom are specifically foreclosed by those distractions? And what would happen if we openly encouraged our students to be bored in the classroom? 

Adam Phillips notes that "boredom is akin to free-floating attention. "When we are bored we are "waiting, unconsciously, for an experience of anticipation ". Walter Benjamin writes in The Arcades Project convolute titled Boredom, Eternal Return : "We are bored when we don’t know what we are waiting for. That we do know or think we know is nearly always the expression of our superficiality or inattention. Boredom is the threshold of great deeds ". Awaiting stimulus, purpose, any object at all on which to fix our attention, boredom challenges us to confront the expansiveness of an interminable present. When we push aside this feeling with a glance at our screens, we open ourselves up to an entire world of information that ends up crowding out the possibility of dwelling with one's own discomfort and uncertainty. But we can learn from the challenge that boredom presents to us. 

Inviting boredom in the classroom of course means letting go of the fear of being boring. While we very rarely have occasion to be bored today, boredom remains a state that we can clearly convey to others by telegraphing our indulgence in distraction, intentionally or otherwise. It is too simple to say, for instance, that we constantly give ourselves over to distraction either for the sake of itself or out of some instinctual avoidance of boredom. Staring at a laptop or glancing at a phone: not only do these gestures encompass a number of activities (paying a bill, taking a note, finding a street), they are also gestures that signify distinct things in different social contexts. Sometimes we want to appear busy even when we're not (waiting for a friend at a bar), and sometimes we're rude when we don't mean to be (waiting for an important message). So, one pedagogical challenge is to think about how we want our students to perform boredom differently in the classroom. If we agree that being bored is a worthwhile pursuit, how then do we foster moments of boredom for our students, as well as model that practice outside of the classroom? 

By encouraging boredom, I don't mean to suggest that we have students concentrate harder no matter the cost or encourage them to fix their attention in any particular way, as so many self-help books and corporate seminars now preach under the banner of "mindfulness. "Boredom instead means roaming within boundaries predetermined by our own interiorities rather than by digital distractions: the harshly-lit space of the classroom, the text under discussion as it's half-heard and floating in and out of conscious attention, the echoes of a motorcycle some distance from campus, the argument we had that morning, and so on. The discomfort of boredom, of free-floating attention as we search for something to latch on to, creates a montage of attentional objects. Boredom is mindfulness the hard way. 

Nor do I mean to suggest that we ban laptops altogether, a clumsy approach that in fact privileges a single, idealized body and mind. The laptop ban is based on the ableist assumption that these devices serve the same function in the way that every student learns. Further, allowing laptops in the classroom only for those students who struggle with learning issues like dysgraphia or dyspraxia effectively outs their disability among their peers. This is what some pedagogy researchers refer to as an accommodationist approach: accommodating deviations from an assumed ideal to suit the needs of students who don't fit that normative paradigm, rather than planning for accessibility in advance . The laptop policy should be viewed instead, as James Lang suggests, as an instrument to be calibrated throughout a single class: for instance, laptops closed during the opening ten minutes for group discussion, then open again for a writing assignment or lecture portion, inviting laptop use so long as we are transparent with our students about how and why we want them to be used . This approach has the benefit of inviting a range of learning styles throughout the class session. And it opens up the possibility for strategically encouraging boredom during moments when we could all benefit from a measure of cognitive wandering. 

I write this, for instance, on a new, still unfamiliar laptop and find myself missing the small moments of lag time on the aging, six-year-old computer that it replaced. Previously, all I could do was wait and watch the spinning icon as a website slowly loaded, or when switching between applications. Now, programs load the instant they are invoked, as if the machine had anticipated my desires. I have become acutely aware of how the rhythms of my work have changed as a result. These moments of lag time with my old laptop allowed on the one hand for the contemplation of the unseen, inner workings of the system. Why is this taking so long? Has the program crashed? Can I free up any memory to make things run faster? And on the other hand, these moments inadvertently allowed for a brief meditative pause in which the slight interruption of my machine's slowness punctuated a train of thought or a task I was working at. They were like little micro-doses of boredom, the only time in my day that truly allowed for boredom as such. 

Encouraging similar moments of meditative pause in the classroom, for instance by resisting the urge to fill the silence during a gap in conversation, might invite students to be bored in a structured way. While distraction is attention without direction, boredom is attention without object. The longer we delay the resolution of a boredom that we have introduced into the classroom, the greater the variety of objects and associations students are encouraged to bring to the table. Making space for boredom gives us a way to forestall and frame our urge for digital distractions without pretending like it's possible or even desirable ever to be fully beyond their reach. 


# notes

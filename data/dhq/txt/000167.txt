
Are we currently confusing being connected with communicating - and does the sort of communication people are typically engaging in on the Internet, in social media and when they use their mobile phones merely lead to superficial rather than meaningful dialogue? If this is the case, it ought to concern Digital Humanities (DH) scholars, many of whom continue to be more interested in how we connect than in the substance and dialogue of that very connectedness. I would like to argue for a better balance between the how and the what of DH - for a qualitative turn of sorts away from an interest in gaining and making accessible more information only , to an interest in also making sense of and understanding that information. For such a turn, computer scientists need input from the humanities whose specialty has always been to turn information into knowledge by means of critical interpretation and contextualization. 

The arguments made by Anne Burdick, Johanna Drucker, Peter Lunenfeld, Todd Presner and Jeffrey Schnapp in Digital_Humanities (2012) may serve as an illustration. For these authors, the core human values of DH are the digital enfranchisement of the public and the promotion of a core curriculum for undergraduates that will make them active participants and stakeholders in the creation and preservation of cultural materials. In terms of humanities scholarship Burdick, et al. hope that the constant spread of information and knowledge across networks may give rise to a state of ubiquitous scholarship, of ever-more interconnected, publicly engaged, participant citizens. Again, the idea is to democratize, to reach out to broader publics and to have the university scholar work together with the citizen or amateur scholar. The read-only ethos of the old humanities should be replaced with a read/write/rewrite ethos rooted in making - highlighting the processes of design and the creation of the experiential, the social, and the communal. Indeed, authorship is design and design is authorship. The kind of scholarship that this results in is by definition, applied. It is scholarship that values the how over the what and that is much closer to what the Greek poet Archilochus, and later also Isaiah Berlin, referred to as fox knowledge rather than hedgehog knowledge. 

It is not, the authors of Digital_Humanities assure us, that deep, specialized knowledge of the kind that humanities scholars used to be fond of and excel at - hedgehog knowledge - is useless. It is just that there can be little doubt that the technologies that give rise to the Digital Humanities push us - scholars, students, and citizens alike - into the fox family. The nature of discourse and debate in networks, the reality of study in multimedia environments, and the inexorable splintering of attention that multiple windows and channels afford lead to pursuing many ends . If at all possible, we should not give up - at least not yet and not entirely - on that inner hedgehog but instead try to create hedgefoxes : hybrid creatures who combine the hedgehog’s ability to go deep with the fox’s wide-ranging curiosity. 

Toward the very end of Digital_Humanities , however, we are told that: The prevailing research culture of the Digital Humanities will become entrepreneurial, much like design or certain areas of contemporary engineering and the sciences are… The digital humanist’s sense of identity will be less anchored in a discipline or disciplinary specialty than in a sense of belonging to a community of practice within which tools and methods are primary and objects of study are secondary considerations . (my emphasis) 

This sounds very much like a dismissal of the possibility described earlier of creating hedgefoxes - of somehow also cherishing that part of humanities scholarship which is based on the hedgehog’s ability to work long and hard and with intense rigor on one particular topic. Are Burdick, et al. telling us, we cannot help wondering at this point, that humanities scholarship will only be concerned with process, form, design - in short, the how - after all? What happened to the what - and what happened to those very central questions asked a few pages earlier: How can the Digital Humanities keep the ways of the hedgehog alive in the era of the fox’s ascendance? How do we inject deep digs into the free-ranging ways of networked scholarship? 

To this reader, these last two questions posed by Burdick, et al. are the very questions that Digital Humanities (DH) scholars ought to become more interested in answering at the present moment. If none of the willingness to discuss the what and to encourage hedgehog competences survives, then the humanities and its scholars will stand in danger of losing core competences such as engaging with questions of value and interpretation, with the realms of rhetoric as well as logic, with subjective judgment alongside attention to verifiable truths. Seeking to be like the social sciences and the natural sciences by appropriating quantifying methods and approaches will not make the humanities less, but more obsolete. 

In the following, it is the what that concerns me rather than the how - scholarly arguments rather than concrete DH practices. Though teaching and core curricula are - and should be - related to scholarship in obvious ways, the pursuit of basic knowledge and cognition in humanities research merits our attention in and of itself, it seems to me. The more widespread the use of digital technology becomes, and the more humanities scholars start working through as opposed to merely with computers, the more important it becomes for us to look at the ways in which digital technologies transform knowledge production and scholarly research. 

Arguing for the need to find a better balance between the how of the new digital methods and technologies and the what of older, more traditional humanities methods, my article will be divided into three parts. I will start by discussing the wish, expressed by some DH scholars, for a new, digital Bildung . What does this Bildung consist of, how will it be propagated and what role will it conceivably play in rethinking the humanities? The second part of the article discusses the encounter between what C.P. Snow once called the Two Cultures : the arts and humanities on the one hand, and the natural and technological sciences on the other. DH is one hybrid meeting point between the two cultures and it is no coincidence that the two cultures debate has since come to be echoed in various DH connections. Part three concerns what Arthur Schlesinger Jr. in 1962 referred to as the mystique of quantitative research: the hegemonic drive of the quantitative approach. Questioning, a mere six months after F.R. Leavis had delivered a vicious response to Snow’s Two Cultures lecture, the assumption that quantitative research can handle everything, Schlesinger essentially repeated Leavis’ main arguments. 

Leavis and Schlesinger were right, I conclude, in pointing to the problems inherent in the wish to quantify humanities teaching and scholarship - a wish that is today often repeated by DH scholars. 


# I. The background: DH, digital Bildung and the future of the humanities 


As David M. Berry sees it, the time has now come for a third-wave Digital Humanities. Neither the first- nor the second-wave DH, as they have been described by e.g. Todd Presner and Jeffrey Schnapp in their Digital Humanities Manifesto 2.0 from 2009, squarely confronts the core expectations and views typically held by humanities scholars - those unspoken assumptions and ontological foundations which support the normal research that humanities scholars undertake on an everyday basis, according to Berry. 

At the very center of Berry’s third-wave Digital Humanities is the notion of a digital Bildung or computational literacy . This is a literacy which responds to what many have described as the current computational turn and which not only understands culture through digital technology, but also wishes to explore the cultural dimension of computation. The classical kind of Bildung - the one we know from German Enlightenment thought which involved the regulating force of philosophy and rational thinking in some form, and which promised help in finding order and meaning in the shape of the professor who tells you what you should be looking up and the three arguments in favour of it and the three arguments against it , as Berry puts it - is no longer sufficient. In order to cope with the digital onslaught of data and information to which we are subjected on a daily basis today, we need a different kind of rationality: a computational rationality which is directed toward neither the past nor the future, but instead toward the here and now in an attempt to Jetztzeit -mediate, Berry writes, using a term from Walter Benjamin. 

What we are potentially looking at here, according to Berry, is nothing short of a Kuhnian paradigm shift - a moment of revolutionary science, in the Kuhnian sense, during which a new normal science will emerge. Computer science and the reading and writing of computer code play an especially poignant role in this paradigm shift, he speculates - though not in the sense that the existing methods and practices of computer science become hegemonic , but rather in the sense that a humanistic understanding of technology could be developed, which also involves an urgent inquiry into what is human about the computational humanities or social sciences. This is all the more urgent as it will most likely become more and more difficult to tell the difference between man and machine - to identify the requirement for what makes something human as opposed to mechanical. If humanities scholars want the humanities to play any kind of role in the new normal science currently emerging, this is the very moment to become involved. 

Berry’s recommendation that a humanistic approach concerning the reading and writing of computer code be promoted is one that is shared by other DH scholars. In Digital_Humanities , Anne Burdick, Johann Drucker, Peter Lunenfeld, Todd Presner and Jeffrey Schnapp promote what they refer to as Generative Humanities. Though they do not play with a possible third-wave DH, but more or less stay within the framework suggested by the Digital Humanities Manifesto 2.0 , their stated goals are rather similar to Berry’s. Topping that list of goals is the creation of a core curriculum for undergraduates that is built around fundamental activities such as curation, analysis, editing, and modeling. It is one that emphasizes design, multimediality and the experiential, encourages process rather than finished product, and views the creation of works of art as a communal process, encompassing the combined efforts of authors, printers, typographers, layout artists, and designers, among others. 

The humanist spirit that will hopefully be the outcome of teaching future humanities undergraduates to think with imagination and to then translate that imagination into creative and innovative action is intimately connected to approaches that tolerate relativism and diversity in thinking, orders of experience, and, yes, fundamental values , according to Burdick, et al. Among these fundamental values is the digital enfranchisement of the public - a wish to at least posit, if not fully enable, a future in which participation is possible for everyone, anywhere, anytime. It would be as if it were possible to bring about a public sphere in which no one was excluded. This is the core human value of the Digital Humanities. The authors openly acknowledge this wish as a utopian element or utopian impulse - one that seems similar to the old Enlightenment dream of access to knowledge and education for everyone which inspired Robert Darnton and others to work over the past few years toward the establishment of the Digital Public Library of America. 

One important part of this visionary digital enfranchisement discourse is its association with technology and the digital more generally. In an article published in the American Historical Review in 1998, U.S. Historian Roy Rosenzweig maintained, for example, that the two most important contextual frames into which to put the rise of digital computing were the Establishment 1960s of the Vietnam War and the Cold War, and the 1960s as counter-culture and antiwar movement. Both the closed world discourse of the Cold War and the open-world discourse of the counterculture had to be taken into account as discourses that helped shape the internet. Understanding these dual origins would make it possible, also, to better understand current controversies over whether the Internet will be open or closed , Rosenzweig argued. 

Time has proven Rosenzweig right. Those controversies over the internet are still very much with us; indeed, they have in some ways become more bitter as a result of what has come to be known as the copyright wars - the pitched battles over new technology, business models and consumers, between those attempting to expand copyright protection and those trying to circumvent it. But this only goes to show the importance of the internet and of digital communication, and several historians have followed Rosenzweig’s invitation to historicize and contextualize both. Some have been especially interested in the closed world discourse while others have focused more on the open world discourse. 

Historians focusing on the open world discourse have shown how the computer quickly came to be considered a tool for global learning and thereby helped shape the process of globalization and a growing consciousness of the processes of global integration. One example is Project Gutenberg, founded in 1971, which was and still is powered by ideas, ideals, and by idealism , as its founder Michael Hart once put it; we want to provide as many eBooks in as many formats as possible for the entire world to read in as many languages as possible. Another is Logo , the first programming language written especially for children, introduced by Seymour Papert as early as 1967. Logo became the start of the program One Laptop Per Child whose Mission Statement reads: To create educational opportunities for the world’s poorest children by providing each child with a rugged, low-cost, low-power, connected laptop with content and software designed for collaborative, joyful, self-empowered learning. When children have access to this type of tool they get engaged in their own education. They learn, share, create, and collaborate. They become connected to each other, to the world and to a brighter future. 

More recently, DH scholar Patrik Svensson has also emphasized the link between visionary thinking and technological development (Svensson 2012, 65). Remarking how the constant challenges waged at core approaches and methods add to the sense of a field that is dynamic and constantly changing, he sees the truly interdisciplinary nature of DH and the way in which it potentially operates across all humanities disciplines as a big advantage when it comes to applying for funding, national as well as international, where there may be a need for Big Humanities to match Big Science projects. 

Key words - for Svensson as for Burdick, et al., Berry and many other DH scholars - are urgency and change; the need for rethinking and pushing against the boundaries of existing and established structures and ways of thinking. Because most of the work done within DH is collaborative and project-based and its concrete outcome often is digital publications that do not fit easily into traditional academic patterns of reward and support, moreover, many within the DH community press for changes to accommodate their work. When we add to this the sense that many humanities scholars have of competing for funding, recognition and the place of their respective disciplines within higher education, it is easy to understand how DH could become a platform or means for rethinking the humanities and higher education and a way of channeling transformative sentiment that often goes far beyond the digital humanities proper. 

There is indeed much at stake for the humanities and for its students and scholars, as Kathleen Fitzpatrick sums it up in Planned Obsolescence: Publishing, Technology, and the Future of the Academy (2011): Whether or not we believe in those beautiful visions for a transformative discourse in relation to DH, humanities scholars have to embrace a new digital Bildung at this point. Otherwise, our disciplines will simply cease to be relevant. The economic crisis has given urgency to debates about the role of the humanities – again and again. From fights over academic publishing to debates about what form academic writing should take in the digital age, humanities scholars are faced with major challenges. And the only thing that is certain, Fitzpatrick argues, is that if we hide our heads in the sand and refuse to engage with the new media, we will lose. 


# II. Bridging the gap between the two cultures ? 


It is interesting that at the core of the wish for digital enfranchisement of the public we find a somewhat traditional (American) multicultural argument. As the authors of Digital_Humanities see it, today’s humanities curricula suffer from a gap between traditional methods of pedagogy focusing on linear text and those of the multidimensional world of the Web and the mediated culture in which we live today. Directed as they were at inherited curricula, which were rightly seen as constrained by issues of race, class, gender, and first-world biases rooted in Eurocentric traditions , the culture wars and canon debates of the past thirty years were an attempt to bridge that gap - an attempt that has unfortunately not been entirely successful. The result has been that the humanities have come to be seen today as out of touch with life outside the walls of the university. This has in turn led to an attempt to move more students into vocational training in order that higher education may be reserved for more elitist-minded students (Burdick, et al. 2012, 23). 

It was a different, though related, kind of gap that inspired F.R. Leavis to engage in fierce dialogue with his Cambridge colleague C.P. Snow in the early 1960s: that between what the latter termed the Two Cultures , the technological and natural sciences on the one hand and the arts and humanities on the other. The interest in higher education was one that Leavis shared with Burdick, et al. and other DH scholars, though - at bottom, the famous Two Cultures debate had everything to do with what ought to be the core curriculum of the humanities. It is therefore perhaps no coincidence that echoes of the old debate have found their way into the DH community. Indeed, from the very beginning, Susan Hockey tells us in The History of Humanities Computing , humanities computing has had to embrace the two cultures , to bring the rigor and systematic unambiguous procedural methodologies characteristic of the sciences to address problems within the humanities that had hitherto been most often treated in a serendipitous fashion [my emphasis]. 

Humanities computing, which later developed into DH, has always been a visionary discourse, as we saw. One such visionary attempt to use the digital as a means of renegotiating the humanities and to rely on digital networks to further interdisciplinary work is the Humanities, Arts, Science, and Technology Advanced Collaboratory. More commonly known as HASTAC, it describes itself as, A network of individuals and institutions inspired the possibilities that new technologies offer us for shaping how we learn, teach, communicate, create, and organize our local and global communities.  We are motivated by the conviction that the digital era provides rich opportunities for informal and formal learning and for collaborative, networked research that extends across traditional disciplines, across the boundaries of academe and community, across the the two cultures of humanism and technology, across the divide of thinking versus making, and across social strata and national borders. [My emphasis] 

HASTAC wishes to provide a forum for, and thereby further, the interconnected and interactive global nature of knowledge today – a forum that will blur sharp distinctions between research, education and other activities and that will extend DH beyond the humanities themselves to industry, cultural institutions and the art world. The ultimate vision, though, is finding a way of bridging the two cultures – defined here as not only those of the humanities and the sciences/technology, but also those of theory versus practice. What is interesting about the HASTAC statement is the way in which it also includes a vision of bridging social divisions as well as national borders digitally. Many of these elements were present in the debate on the two cultures between C.P. Snow and F.R. Leavis. 

Sir Charles Percy Snow did a Ph.D. in Chemistry at the University of Cambridge, but it was as a novelist and government official that he became a well-known figure to the English public. Between 1940 and 1970, he published eleven novels that became known collectively as Strangers and Brothers . These novels were very successful; they sold widely and were translated into many different languages. Frank Raymond Leavis was less of a public figure. Within the academic community, though, he was recognized as one of the most influential figures in twentieth-century English literary criticism. He did a Ph.D. in English at the University of Cambridge where he taught for many years and was well known for his decisive and often provocative judgments. 

The Two Cultures and the Scientific Revolution was the Sir Robert Rede Lecture at Cambridge of 1959. In it Snow brought to public attention what he considered to be a dangerous divide between the ethos and practices of the sciences and those of the old humanities (especially Latin and Greek). The British educational system had over-rewarded the latter at the expense of scientific and engineering education with the result that people in politics, administration, and industry were ill-equipped to manage the modern scientific world. Snow’s lecture started a debate about the relative importance for British culture and for the British educational system of the two cultures - a debate to which Leavis contributed with his Richmond Lecture, entitled Two Cultures? The Significance of C.P. Snow and delivered in Downing College, Cambridge, in February 1962. 

It is Leavis’ reaction to Snow’s lecture that concerns me here. Elsewhere, I have written at greater length about both Snow’s and Leavis’ points of view - arguing for a better balance between the how and the what of DH, as I am in this particular context, it is especially Leavis’ view of things that is relevant because it was precisely the what that also concerned Leavis, and that he kept defending vis-à-vis Snow’s Technologico-Benthamite view of the world. In and of himself, Snow did not matter to Leavis; it is what he represented that was the problem. With all his clichés, repetitions and sentimental banalities, Snow was too obvious, too lacking in depth in the sense of questioning the received truths of the Zeitgeist , material but especially spiritual, Leavis thought. Snow could not stop talking about social hope and he preached a way of salvation that entailed welfare for all in terms of material standards of living, advantages of technology and scientific hygiene. 

The dimension that Leavis most of all found lacking in Snow was the individual, the human one. Though all human beings share certain common features - hunger and thirst, for example, and the fact that we all have eyes, noses, legs and arms - individual lives cannot be aggregated or equated or dealt with quantitatively in any way. Spiritually, we are all different and it counts - or ought to count - how each individual human being thinks and feels. Snow’s social hope did not catch that inward quality of individual life, that kind of existential thought and experience which might ultimately lead to something as old-fashioned as wisdom. At one level, what was at stake was what the Germans would call Weltschmerz - the tragic feeling and creative probing into the big questions about life and death which may at its best produce great art and literature: In coming to terms with great literature we discover what at bottom we really believe. What for - what ultimately for? What do men live by - the questions work and tell at what I can only call a religious depth of thought and feeling. 

At another level, the issue, as Leavis saw it, was the pace of life that modern science and technology seemed to result in. Snow had kept stressing, in his Rede Lecture, the urgency of his concerns, the speed with which today turns into tomorrow - we have very little time. So little I dare not guess at it - but he hadn’t really paused to consider the deeper implications of this. Brakes must be applied sometimes, Leavis thought. It was not that Snow was wrong in advocating improvements in scientific education and in living standards for everyone; it was more that such concern is not enough - disastrously not enough. Things were changing so rapidly, and critical reflection was urgently needed to help make sense of it all - and to prevent the worst scientific blunders which, in the atomic day and age, could have fatal results. Moreover, important ethical issues could well be at stake - issues that perhaps scientists themselves would not be aware of: The advance of science and technology means a human future of change so rapid and of such kinds, of tests and challenges so unprecedented, of decisions and possible non-decisions so momentous and insidious in their consequences, that mankind - this is surely clear - will need to be in full intelligent possession of its full humanity (and ‘possession’ here means, not confident ownership of that which belongs to us - our property, but a basic living deference towards that to which, opening as it does into the unknown and itself unmeasurable, we know we belong). I haven’t chosen to say that mankind will need all its traditional wisdom; that might suggest a kind of conservatism that, so far as I am concerned, is the enemy. What we need, and shall continue to need not less, is something with the livingness of the deepest vital instinct; as intelligence, a power - rooted, strong in experience, and supremely human - of creative response to the new challenges of time; something that is alien to either of Snow’s cultures. 

Intellectual depth and complexity along with a both critical and creative response to change - or life , an essential concept to Leavis because it was right at the core of what it means to be human - this is what humanities scholars such as Leavis himself could help preserve. Without the creation of the human world, including language, he argued, the triumphant erection of the scientific edifice would not have been possible. The word language is crucial here. To Leavis, language was not just a means of communication; it was through language that meaning was created - meaning which was then transmitted through literature as a cultural community or consciousness. The place where this cultural consciousness might be sustained was the university, and because language was central to thought and thought, past as well as present, would be communicated via literature, the center of the university ought to be vital English School, Leavis maintained: Like Snow I look to the university. Unlike Snow, I am concerned to make it really a university, something (that is) more than a collocation of specialist departments - to make it a centre of human consciousness: perception, knowledge, judgment and responsibility. And perhaps I have sufficiently indicated on what lines I would justify my seeing the centre of a university in a vital English School. 

Throughout his lecture, Leavis anxiously claimed that he was not himself a Luddite, but that he would be dismissed by Snow and his cohort as being one, the moment he pointed to the complexity of current technical and intellectual developments. Any criticism voiced would be seen as inevitably highbrow - a negative term wielded against anyone who attempted to work toward qualitative, rather than quantitative goals: The upshot is that if you insist on the need for any other kind of concern, entailing forethought, action and provision, about the human future - any other kind of misgiving - than that which talks in terms of productivity, material standards of living, hygienic and technological progress, then you are a Luddite. 

Just as Snow personified for Leavis everything that was currently wrong, so Leavis was for Snow in the end just another Luddite. Today, the name of each is very much associated with the two cultures debate of which they were the main protagonists. As we find ourselves in the middle of another technological revolution - this time a digital one - we are once more very concerned with what the implications will be for our research and our way of thinking and writing. To what extent will the technologically savvy, already as fully converted to the digital cause as Snow was to the scientific revolution, carry the day - and on what terms? And to what extent will those of us who care about the humanities be allowed to fret about the present state and future of our disciplines in the same way that Leavis wondered about what can and should be done, without being considered highbrow, elitist snobs? 


# III. The mystique of quantitative research 


Snow’s lecture got an immediate response, both positive and negative, and he later thought that this must be because he had touched on something which was already in the air : It was clear that many people had been thinking on this assembly of topics. The ideas were in the air… any of us could have produced a hubbub. Apart from the fact that these ideas were not all that original to him, what could be inferred from this, Snow claimed, was that there must be something in them. 

Snow had a point. Whether or not people agreed with him - and Leavis and many others obviously did not - he was on to something that greatly interested people. In fact, there was a similar debate going on at the University of Oxford. Here, Isaiah Berlin took the leading part in building a new graduate college, Wolfson College, which would promote the powerful scientific and technological developments of the time. And across the Atlantic, famous historian and special assistant to President Kennedy between 1961 to 1963 Arthur Schlesinger, Jr. gave a talk to the American Sociological Association at its fifty-seventh annual meeting in August 1962 (a mere six months after Leavis had reacted so strongly to Snow) in which he discussed what he considered to be the hegemonic drive of the quantitative approach. This particular annual meeting of the ASA being in honor of Paul Lazarsfeld, who was considered by many to be one of the founders of modern empirical sociology, Schlesinger had called his talk The Humanist Looks at Empirical Social Research . 

Schlesinger started out with a cri de coeur : Insofar as empirical social research can drive historians to criticize their assumptions, to expose their premises, to tighten their logic, to pursue and respect their facts, to restrain their rhetoric - in short, insofar as it gives them an acute sense of the extraordinary precariousness of the historical enterprise - it administers a wholly salutary shock to a somewhat uncritical and even complacent discipline. 

Having thus demonstrated that he had absolutely no quarrel with empirical social research per se and that, as a historian, he felt indebted to sociologists such as Lazarsfeld, Schlesinger then went on to clarify that the problem he wanted to address concerned the way in which many sociologists had come to consider empirical social research not one of several paths to social wisdom, but the central and in-fallible path. Having fallen under the spell of what Schlesinger thought could only be called the mystique of empirical social research, these sociologists had increasingly come to understand empirical social research as above all, quantitative research - that is, research which deals in quantifiable problems and yields numerical or quasi-numerical conclusions. He stressed once again that he did not wish to be misunderstood; no historian could possibly deny that quantitative research, complete with IBM cards and computers, can make an important contribution to historical understanding. What he questioned was the assumption that such quantitative research can handle everything which the humanist must take into account. And perhaps worst of all, Schlesinger argued, was the dismissal of everything non-quantifiable as being irrelevant and un-important. What quantitative methods are not very good at handling can in fact well be the things that matter most, he speculated - and then ended by going beyond his own discipline to conclude with a couple of paragraphs that concerned the humanities as a whole: There is much, I would add, which we must leave, whether we like it or not, not just to historians but to poets, novelists, painters, musicians, philosophers, theologians, even politicians, even saints - in short, to one form or another of humanist. For an indefinite future, I suspect, humanism will continue to yield truths about both individual and social experience which quantitative social research by itself could never reach. Whether these truths are inherently or merely temporarily inaccessible to the quantitative method is a question which only experience can answer. 
In the meantime, this humanist is bound to say that, as an aid to the understanding of society and men, quantitative social research is admirable and indispensable. As a guide to the significance of problems, it is misleading when it exudes the assumption that only problems susceptible to quantitative solutions are important. As a means of explaining human or social behavior, it is powerful but profoundly incomplete. As the source of a theory of human nature and of the universe, it is but a new formulation of an ancient romantic myth. 


Leavis would have agreed wholeheartedly. As Guy Ortolano has shown, it was not the importance of science and technology that Leavis questioned, but rather the complete endorsement by modern civilization of ideals such as description, logic and clarity - to the exclusion of older, more qualitative ideals. For neither Leavis nor Schlesinger, that is, was it ever a question of science/technology versus the arts and humanities - but instead a question of finding the right balance between quantifying and qualitative ways of thinking. Both are important - and both offer us something that we cannot do without. 

It is precisely this insight - that we are not talking about an either/or, and that we are and should not be engaged in trench warfare - which makes it worthwhile to look at the old ‘two cultures’ debate. In its modern DH version, I would suggest, this means realizing that both qualitative and quantitative ways of doing research are needed - and that the furthering of a ‘humanist spirit’ or new digital Bildung leads to our not letting ourselves be pushed completely into quantitative ways of thinking by the technologies that give rise to the DH. Instead, we should work toward developing a humanistic understanding of technology, along the lines of what Berry suggests. 


# IV. Concluding remarks 


Viewed in an optimistic light, Bernhard Rieder and Theo Röhle correctly point out, the great interest among humanities scholars for the digital media looks like the emergence of a new and genuine trans-disciplinarity: Digital humanities - an endeavor at the forefront of crossing boundaries and research traditions - would seem to bridge the gap between the two cultures (Snow 1959), between the quantitative orientation of the natural sciences and critical cultural discourses in the humanities [my emphasis]. 

If we look more closely, however, we risk finding a wish to compete with the natural sciences on their own turf by doing objective research, with the help of machines, which aims to reduce as far as possible any kind of human, subjective bias and/or emotion. Reminding us how, in the nineteenth century, the drive for objectivity led to the belief in mechanical objectivity, and how this very belief was fought tooth and nail up through the twentieth century by humanists who wanted the role of human interpretation to be recognized, Rieder and Röhle warn about what they call the lure of objectivity and, in relation to that, the quest for universalism. To the lure of objectivity must be added the power of visual evidence. While having previously often questioned scientific images by raising the issue of representation and referentiality, humanities scholars now increasingly use images in their own research - seemingly furthering the view that numerical and visual reasoning is much more easily acceptable as evidence than is textual rhetoric which is considered by most scientists to be argumentation only . 

Rieder and Röhle have no clear-cut answer to the challenges to what they, too, consider to be a Kuhnian paradigm shift in favor of computer-based approaches. Could computerized research make more traditional scholarship (look) obsolete, they ask; is there a danger of catering too much to short attention spans while at the same time cruising on technology’s aura of objectivity? Being themselves all in favor of computer-based approaches, they do advocate that humanities scholars get involved with and try out the new computer-based methods. But they conclude their article by insisting on a thoughtful and critical approach - one that raises inopportune questions when the need arises: In order to develop a sensibility for the wider repercussions of methodological innovation, it is crucial that we understand not only the potential but also the limits of these new methods. Obviously, building research tools is not an end in itself and in many areas there is an argument to be made for the confident defense of methods that are based on principles other than persistent plotting. 

Like Rieder and Röhle, I think - and have in this article argued - that the many new developments within DH must be discussed with a view not only to their potential, but also to their limits. Whether or not it may properly be classified as a Kuhnian paradigm shift - and the vote is still out on this - the digital turn and the involvement with computer-based approaches will cause substantial changes for both the teaching and the research in the humanities. A number of humanities scholars have not yet understood the importance or, indeed, the enormity of this turn - especially when it comes to their way of doing basic research. Whereas a lot has been written on the impact on our teaching and dissemination of knowledge in the humanities, not that many scholars have tried to grapple with the impact on humanities research and recognition - with the epistemological consequences of working through computers. 

We are repeatedly told, by politicians, funding agencies and colleagues in other parts of Academia, that if we want to stay vital, interesting and relevant we need to reformat ourselves in the humanities. In the late 1950s and early 1960s, F.R. Leavis and Arthur Schlesinger, Jr. perceived their core humanities disciplines - literature and history, respectively - to be under duress by the hegemonic drive of the quantitative approach, so highly recommended by people such as C.P. Snow and Paul Lazarsfeld. This made them take up and rephrase for their own time the age-old debate about the two cultures. Perhaps we should do something similar today, as computer-based approaches force us to reexamine the relationships of the what to the how within the humanities. DH is one hybrid, contemporary meeting point between the two cultures. In the DH, the two cultures literally overlap, thereby providing an excellent case study for the future of the humanities. 


# notes

[^1]: The original Digital Humanities Manifesto was authored by Todd
                        Presner (UCLA) and Jeffrey Schnapp (Harvard University), for the Mellon
                        Seminars in Digital Humanities at UCLA. The 26 statements of the original
                        Digital Humanities Manifesto then evolved into the 50 positions of Version
                        2.0 from 2009 which is available at http://www.humanitiesblast.com/manifesto/Manifesto_V2.pdf (last
                        accessed on February 28, 2013). The quotations used in this paper are from
                        this document. 
[^2]: In short, Bildung is still a key idea in the digital university,
                                not as a subject trained in a vocational fashion to perform
                                instrumental labour, nor as a subject skilled in a national literary
                                culture, but rather as a subject which can unify the information
                                that society is now producing at increasing rates, and which
                                understands new methods and practices of critical reading (code,
                                data visualisation, patterns, narrative) and is open to new methods
                                of pedagogy to facilitate it.
[^3]:  In How We Think: Digital Media and Contemporary
                            Technogenesis, N. Katherine Hayles also speculates about a
                        paradigm shift from linear temporal causality
                                to spatialized grids extending in all directions and incorporating
                                rich connections within themselves as well as cross-connections with
                                other grids.
[^4]: 
                        See http://dp.la/. For a longer discussion
                        on this, please see . 
[^5]:  A number of
                        scholars have attempted to draw our attention to the fact that human beings
                        have always accumulated technology because it increases our opportunities,
                        individually as well as collectively. For some, this imposes a moral duty on
                        us to further technological development because we thereby increase the
                        options and opportunities for people around the world. See . 
[^6]: 
                        As historians concentrating on the closed world
                        discourse have pointed out, it was U.S. Cold War spending on military
                        projects that originally funded many of the most important post-World War
                        Two technological discoveries. With both an economic crisis going on and
                        support for deregulation growing, public funding for science and technology
                        started to drop in the late 1970s, though. One result was that the internet
                        was privatized and computers became a private, individual and commercial
                        project. See e.g. . 
[^7]:  See e.g. . 
[^8]:  One Laptop per Child, Mission Statement – available at http://laptop.org/en/vision/
                        (last accessed on March 13, 2013). 
[^9]:  HASTAC – available at http://hastac.org/about-hastac. 
[^10]:  My
                        interest in the Snow-Leavis debate was raised while I was working on DH as
                        an Arcadia Fellow at the University of Cambridge in the fall of 2011. The
                        article that was my output as an Arcadia Fellow is available at http://arcadiaproject.lib.cam.ac.uk/docs/DigitalHumanities.pdf.
                        The following paragraphs build on this article. 
[^11]:  See . 